{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"\u00b6","title":"Home"},{"location":"#_1","text":"","title":""},{"location":"about/","text":"Just a regular dude from Norway that recently got into servers. I create how-to's and guides mainly around using Unraid but most of it can be applied to any server running docker ect :) If you have a request or issue you can contact me here: [eckosc_button title=\"Email\" icon=\"\" size=\"standard\" position=\"inline\" color=\"#000000\" rounded=\"true\" url=\"mailto: contact@technicalramblings.com \" blank=\"true\"] [eckosc_button title=\"Discord\" icon=\"\" size=\"standard\" position=\"inline\" color=\"#000000\" rounded=\"true\" url=\" https://organizr.app/discord \" blank=\"true\"]","title":"About"},{"location":"blog/","text":"Blog \u00b6","title":"Blog"},{"location":"blog/#blog","text":"","title":"Blog"},{"location":"blog/adding-ban-unban-notifications-from-fail2ban-to-discord/","text":"Adding ban/unban notifications from Fail2Ban to Discord! \u00b6 I thought I would follow up on the Fail2Ban Pushover post with a Fail2Ban Discord post! eckosc\\_status\\_message title=\"Docker Mods\" icon=\"\" type=\"info\" message=\"If you use the linuxserver/letsencrypt container, scroll down to the bottom for a short tutorial on how to use that instead. \" eckosc\\_status\\_message title=\"Docker Mods\" icon=\"\" type=\"info\" message=\"If you use the linuxserver/letsencrypt container, scroll down to the bottom for a short tutorial on how to use that instead. \" Creating the Webhook \u00b6 In this guide you will be using a Discord webhook to post Fail2Ban notifications to the server of your choice. If you don't have a discord server yet you need to create one. Head over to the Server Settings and select Webhooks . Click on Create Webhook and add the name and channel you want the webhook to post to. At the bottom you will find the webhook url, save that for later. Adding the Discord action \u00b6 Head over to your Fail2Ban action.d folder and create a file called discord_notifications.conf and add the following: # Author: Gilbn from https://technicalramblings.com # Adapted Source: https://gist.github.com/sander1/075736a42db2c66bc6ce0fab159ca683 # Create the Discord Webhook in: Server settings -> Webhooks -> Create Webhooks [Definition] # Notify on Startup actionstart = curl -X POST \"<webhook>\" \\ -H \"Content-Type: application/json\" \\ -d '{\"username\": \"Fail2Ban\", \"content\":\":white_check_mark: The **[<name>]** jail has started\"}' # Notify on Shutdown actionstop = curl -X POST \"<webhook>\" \\ -H \"Content-Type: application/json\" \\ -d '{\"username\": \"Fail2Ban\", \"content\":\":no_entry: The **[<name>]** jail has been stopped\"}' # actioncheck = # Notify on Banned actionban = curl -X POST \"<webhook>\" \\ -H \"Content-Type: application/json\" \\ -d '{\"username\":\"Fail2Ban\", \"content\":\":bell: Hey <discord_userid>! **[<name>]** :hammer:**BANNED**:hammer: IP: `<ip>` for <bantime> hours after **<failures>** failure(s). Here is some info about the IP: https://db-ip.com/<ip>\"}' curl -X POST \"<webhook>\" \\ -H \"Content-Type: application/json\" \\ -d '{\"username\":\"Fail2Ban\", \"content\":\"If you want to unban the IP run: `fail2ban-client unban <ip>`\"}' # Notify on Unbanned actionunban = curl -X POST \"<webhook>\" \\ -H \"Content-Type: application/json\" \\ -d '{\"username\":\"Fail2Ban\", \"content\":\":bell: **[<name>]** **UNBANNED** IP: [<ip>](https://db-ip.com/<ip>)\"}' [Init] # Name of the jail in your jail.local file. default = [your-jail-name] name = default # Discord Webhook URL webhook = https://discordapp.com/api/webhooks/XXXXXXXXXXXXXXX/XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX Replace the webhook URL with the one from your webhook [eckosc_quote quote=\"If you dont want it to notify you on startup/shutdown/unban you can just comment that line with a #.\" source=\"\" url=\"\" pull=\"false\"] Like so: #actionstart = curl -X POST \"<webhook>\" \\ # -H \"Content-Type: application/json\" \\ # -d '{\"username\": \"Fail2Ban\", \"content\":\":white_check_mark: The **[<name>]** jail has started\"}' Updating jail.local \u00b6 Next edit you jail.local file and add the action. You will have to add to all the jails you want notifications on or you can add it below the [DEFAULT] line . Since I use Cloudflare and already have an action in all my jails, I've added it on the line below. If you don't have another action there already you can just add the line action = discord_notifications eckosc\\_status\\_message title=\"Default action!\" icon=\"\" type=\"error\" message=\"If you only have the **discord** action in the jail it will not update the iptables as it replaces the default action. You can add the action **iptables-allports**and it will then run both actions when banning\" eckosc\\_status\\_message title=\"Default action!\" icon=\"\" type=\"error\" message=\"If you only have the **discord** action in the jail it will not update the iptables as it replaces the default action. You can add the action **iptables-allports**and it will then run both actions when banning\" Example: \u00b6 [nginx-http-auth] enabled = true filter = nginx-http-auth action = cloudflare-apiv4 discord_notifications[bantime=24, discord_userid=<@!xxxxxxxxxxxxxxxxxxxx>] iptables-allports port = http,https logpath = /config/log/nginx/error.log ignoreip = 192.168.1.0/24 Note:**The **[bantime=24]** is just a tag that the action uses. It does not control how long the ban lasts. I default all bans to 24 hours. **Note2: The discord_userid=<@!USER-ID-NUMBER> is for mentioning yourself in the server so you can get a ping. To find your user ID-number just type **@<username>** or @<role> , like so @GilbN#1337 Don't forget the ! after @ when adding it to the action tag in the jail. The result should look like this: If you want to ping a role you need to edit the tag to say <@&ROLE-ID-NUMBER> instead. Note3:**The ignore IP is so that fail2ban won't ban your local IP. Check out https://www.aelius.com/njh/subnet_sheet.html if you are wondering what your ** CIDRnotation is. Most often it will be /24 (netmask 255.255.255.0) To find your netmask run **ipconfig /all** on windows or** ifconfig | grep netmask ** on linux. After you have added the action to all your jails you need to restart fail2ban. For me that will be to restart the letsencrypt container as I'm using Docker. Discord \u00b6 The notifications will look like this: You can change the text by editing the discord_notifications.conf file Docker Mods \u00b6 If you use the linuxserver/letsencrypt container, Roxedus has made a docker mod that will send pretty embedded notifications to discord on bans! https://github.com/linuxserver/docker-mods/tree/swag-f2bdiscord Simply add these environment variables to the container, and update the jail.local file. -e DOCKER_MODS=linuxserver/mods:swag-f2bdiscord -e DISC_HOOK=40832456738934/7DcEpWr5V24OIEIELjg-KkHky86SrOgTqA This is the last two parts of the webhook url. Scroll up to see how to create a webhook. -e DISC_ME=120970603556503552 This is the userID that will get mentions on the server. Scroll up for how to find your userid. Add this in your action: discordEmbed[bantime=24] ,bantime(hour) is optional, but defaults to 24 when not set. Just reflects in the message, does not change the ban time action = cloudflare-apiv4 **discordEmbed** iptables-allports For any questions you can find me here: \u00b6 \u00b6","title":"Adding ban/unban notifications from Fail2Ban to Discord!"},{"location":"blog/adding-ban-unban-notifications-from-fail2ban-to-discord/#adding-banunban-notifications-from-fail2ban-to-discord","text":"I thought I would follow up on the Fail2Ban Pushover post with a Fail2Ban Discord post! eckosc\\_status\\_message title=\"Docker Mods\" icon=\"\" type=\"info\" message=\"If you use the linuxserver/letsencrypt container, scroll down to the bottom for a short tutorial on how to use that instead. \" eckosc\\_status\\_message title=\"Docker Mods\" icon=\"\" type=\"info\" message=\"If you use the linuxserver/letsencrypt container, scroll down to the bottom for a short tutorial on how to use that instead. \"","title":"Adding ban/unban notifications from Fail2Ban to Discord!"},{"location":"blog/adding-ban-unban-notifications-from-fail2ban-to-discord/#creating-the-webhook","text":"In this guide you will be using a Discord webhook to post Fail2Ban notifications to the server of your choice. If you don't have a discord server yet you need to create one. Head over to the Server Settings and select Webhooks . Click on Create Webhook and add the name and channel you want the webhook to post to. At the bottom you will find the webhook url, save that for later.","title":"Creating the Webhook"},{"location":"blog/adding-ban-unban-notifications-from-fail2ban-to-discord/#adding-the-discord-action","text":"Head over to your Fail2Ban action.d folder and create a file called discord_notifications.conf and add the following: # Author: Gilbn from https://technicalramblings.com # Adapted Source: https://gist.github.com/sander1/075736a42db2c66bc6ce0fab159ca683 # Create the Discord Webhook in: Server settings -> Webhooks -> Create Webhooks [Definition] # Notify on Startup actionstart = curl -X POST \"<webhook>\" \\ -H \"Content-Type: application/json\" \\ -d '{\"username\": \"Fail2Ban\", \"content\":\":white_check_mark: The **[<name>]** jail has started\"}' # Notify on Shutdown actionstop = curl -X POST \"<webhook>\" \\ -H \"Content-Type: application/json\" \\ -d '{\"username\": \"Fail2Ban\", \"content\":\":no_entry: The **[<name>]** jail has been stopped\"}' # actioncheck = # Notify on Banned actionban = curl -X POST \"<webhook>\" \\ -H \"Content-Type: application/json\" \\ -d '{\"username\":\"Fail2Ban\", \"content\":\":bell: Hey <discord_userid>! **[<name>]** :hammer:**BANNED**:hammer: IP: `<ip>` for <bantime> hours after **<failures>** failure(s). Here is some info about the IP: https://db-ip.com/<ip>\"}' curl -X POST \"<webhook>\" \\ -H \"Content-Type: application/json\" \\ -d '{\"username\":\"Fail2Ban\", \"content\":\"If you want to unban the IP run: `fail2ban-client unban <ip>`\"}' # Notify on Unbanned actionunban = curl -X POST \"<webhook>\" \\ -H \"Content-Type: application/json\" \\ -d '{\"username\":\"Fail2Ban\", \"content\":\":bell: **[<name>]** **UNBANNED** IP: [<ip>](https://db-ip.com/<ip>)\"}' [Init] # Name of the jail in your jail.local file. default = [your-jail-name] name = default # Discord Webhook URL webhook = https://discordapp.com/api/webhooks/XXXXXXXXXXXXXXX/XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX Replace the webhook URL with the one from your webhook [eckosc_quote quote=\"If you dont want it to notify you on startup/shutdown/unban you can just comment that line with a #.\" source=\"\" url=\"\" pull=\"false\"] Like so: #actionstart = curl -X POST \"<webhook>\" \\ # -H \"Content-Type: application/json\" \\ # -d '{\"username\": \"Fail2Ban\", \"content\":\":white_check_mark: The **[<name>]** jail has started\"}'","title":"Adding the Discord action"},{"location":"blog/adding-ban-unban-notifications-from-fail2ban-to-discord/#updating-jaillocal","text":"Next edit you jail.local file and add the action. You will have to add to all the jails you want notifications on or you can add it below the [DEFAULT] line . Since I use Cloudflare and already have an action in all my jails, I've added it on the line below. If you don't have another action there already you can just add the line action = discord_notifications eckosc\\_status\\_message title=\"Default action!\" icon=\"\" type=\"error\" message=\"If you only have the **discord** action in the jail it will not update the iptables as it replaces the default action. You can add the action **iptables-allports**and it will then run both actions when banning\" eckosc\\_status\\_message title=\"Default action!\" icon=\"\" type=\"error\" message=\"If you only have the **discord** action in the jail it will not update the iptables as it replaces the default action. You can add the action **iptables-allports**and it will then run both actions when banning\"","title":"Updating jail.local"},{"location":"blog/adding-ban-unban-notifications-from-fail2ban-to-discord/#example","text":"[nginx-http-auth] enabled = true filter = nginx-http-auth action = cloudflare-apiv4 discord_notifications[bantime=24, discord_userid=<@!xxxxxxxxxxxxxxxxxxxx>] iptables-allports port = http,https logpath = /config/log/nginx/error.log ignoreip = 192.168.1.0/24 Note:**The **[bantime=24]** is just a tag that the action uses. It does not control how long the ban lasts. I default all bans to 24 hours. **Note2: The discord_userid=<@!USER-ID-NUMBER> is for mentioning yourself in the server so you can get a ping. To find your user ID-number just type **@<username>** or @<role> , like so @GilbN#1337 Don't forget the ! after @ when adding it to the action tag in the jail. The result should look like this: If you want to ping a role you need to edit the tag to say <@&ROLE-ID-NUMBER> instead. Note3:**The ignore IP is so that fail2ban won't ban your local IP. Check out https://www.aelius.com/njh/subnet_sheet.html if you are wondering what your ** CIDRnotation is. Most often it will be /24 (netmask 255.255.255.0) To find your netmask run **ipconfig /all** on windows or** ifconfig | grep netmask ** on linux. After you have added the action to all your jails you need to restart fail2ban. For me that will be to restart the letsencrypt container as I'm using Docker.","title":"Example:"},{"location":"blog/adding-ban-unban-notifications-from-fail2ban-to-discord/#discord","text":"The notifications will look like this: You can change the text by editing the discord_notifications.conf file","title":"Discord"},{"location":"blog/adding-ban-unban-notifications-from-fail2ban-to-discord/#docker-mods","text":"If you use the linuxserver/letsencrypt container, Roxedus has made a docker mod that will send pretty embedded notifications to discord on bans! https://github.com/linuxserver/docker-mods/tree/swag-f2bdiscord Simply add these environment variables to the container, and update the jail.local file. -e DOCKER_MODS=linuxserver/mods:swag-f2bdiscord -e DISC_HOOK=40832456738934/7DcEpWr5V24OIEIELjg-KkHky86SrOgTqA This is the last two parts of the webhook url. Scroll up to see how to create a webhook. -e DISC_ME=120970603556503552 This is the userID that will get mentions on the server. Scroll up for how to find your userid. Add this in your action: discordEmbed[bantime=24] ,bantime(hour) is optional, but defaults to 24 when not set. Just reflects in the message, does not change the ban time action = cloudflare-apiv4 **discordEmbed** iptables-allports","title":"Docker Mods"},{"location":"blog/adding-ban-unban-notifications-from-fail2ban-to-discord/#for-any-questions-you-can-find-me-here","text":"","title":"For any questions you can find me here:"},{"location":"blog/adding-ban-unban-notifications-from-fail2ban-to-discord/#_1","text":"","title":""},{"location":"blog/adding-ban-unban-notifications-from-fail2ban-with-pushover/","text":"Adding ban/unban notifications from Fail2Ban to Pushover! \u00b6 If you're like me and think Fail2Ban is an awesome tool for intrusion protection, getting a notification when someone has been banned is the bee's knees! And using Pushover makes it very simple! Setting up Pushover \u00b6 Head over to https://pushover.net/ and create a user account and add the devices you want to receive notifications. I'm using the iOS app, and that works great for me. The app has a 7 day trail period that lets you try it out without paying for it. On your user page you will see you user key . Save that as we will need that for later. At the bottom you can add your new Fail2Ban application. After you've added the new application it will display it's API token. Save that as we will use that for later. You can also test Pushover by sending a notification manually on the user page. Adding the Pushover action \u00b6 Head over to your Fail2Ban action.d folder and create a file called pushover.local and add the following # Fail2Ban Pushover configuration file # Adapted Source: https://gist.github.com/sander1/075736a42db2c66bc6ce0fab159ca683 [Definition] # Notify on Startup actionstart = /usr/bin/curl -s -F \"token=<token>\" -F \"user=<user>\" -F \"title=[Fail2Ban] <name>\" -F \"message=Jail <name> has been started successfully.\" https://api.pushover.net/1/messages # Notify on Shutdown actionstop = /usr/bin/curl -s -F \"token=<token>\" -F \"user=<user>\" -F \"title=[Fail2Ban] <name>\" -F \"message=Jail <name> has been stopped.\" https://api.pushover.net/1/messages # actioncheck = # Notify on Banned actionban = /usr/bin/curl -s -F \"token=<token>\" -F \"user=<user>\" -F \"title=[Fail2Ban] <name>\" -F \"message=Banned IP: <ip> Lines containing IP: `grep '<ip>' <logpath>`\" https://api.pushover.net/1/messages # Notify on Unbanned actionunban = /usr/bin/curl -s -F \"token=<token>\" -F \"user=<user>\" -F \"title=[Fail2Ban] <name>\" -F \"message=Unbanned IP: <ip> Lines containing IP: `grep '<ip>' <logpath>`\" https://api.pushover.net/1/messages [Init] # Name of the jail in your jail.local file. default = [your-jail-name] name = default # Application token key token = YOUR-APPLICATION-TOKEN # User API key user = YOUR-USER-KEY [eckosc_quote quote=\"If you dont want it to notify you on startup/shutdown/unban you can just comment that line with a #.\" source=\"\" url=\"\" pull=\"false\"] Like so: #actionstart = /usr/bin/curl -s -F \"token=<token>\" -F \"user=<user>\" -F \"title=[Fail2Ban] <name>\" -F \"message=Jail <name> has been started successfully.\" https://api.pushover.net/1/messages Updating jail.local \u00b6 Next edit you jail.local file and add the action. You will have to add to all the jails you want notifications on or you can add it below the [DEFAULT] line. Since I use Cloudflare and already have an action in all my jails, I've added it on the line below. If you don't have another action there already you can just add the line action = pushover eckosc\\_status\\_message title=\"Default action!\" icon=\"\" type=\"error\" message=\"If you only have the **pushover** action in the jail it will not update the iptables as it replaces the default action. You can add the action **iptables-allports**and it will then run both actions when banning\" eckosc\\_status\\_message title=\"Default action!\" icon=\"\" type=\"error\" message=\"If you only have the **pushover** action in the jail it will not update the iptables as it replaces the default action. You can add the action **iptables-allports**and it will then run both actions when banning\" Example: \u00b6 [nginx-http-auth] enabled = true filter = nginx-http-auth action = cloudflare-apiv4 pushover iptables-allports port = http,https logpath = /config/log/nginx/error.log ignoreip = 192.168.1.0/24 Note:**The ignore IP is so that fail2ban won't ban your local IP. Check out https://www.aelius.com/njh/subnet_sheet.html if you are wondering what your ** CIDRnotation is. Most often it will be /24 (netmask 255.255.255.0) To find your netmask run **ipconfig /all** on windows or** ifconfig | grep netmask ** on linux. After you have added the action to all your jails you need to restart fail2ban. For me that will be to restart the swag container as I'm using Docker. Banning \u00b6 A successful ban will look like this: 2019-03-03 16:57:09,608 fail2ban.filter [329]: INFO [nginx-http-auth-technicalramblings] Found 23.92.127.82 - 2019-03-03 16:57:09 2019-03-03 16:57:11,612 fail2ban.filter [329]: INFO [nginx-http-auth-technicalramblings] Found 23.92.127.82 - 2019-03-03 16:57:11 2019-03-03 16:57:12,816 fail2ban.filter [329]: INFO [nginx-http-auth-technicalramblings] Found 23.92.127.82 - 2019-03-03 16:57:12 2019-03-03 16:57:12,900 fail2ban.actions [329]: NOTICE [nginx-http-auth-technicalramblings] Ban 23.92.127.82 Source: https://gist.github.com/sander1/075736a42db2c66bc6ce0fab159ca683 For any questions you can find me here: \u00b6 \u00b6","title":"Adding ban/unban notifications from Fail2Ban to Pushover!"},{"location":"blog/adding-ban-unban-notifications-from-fail2ban-with-pushover/#adding-banunban-notifications-from-fail2ban-to-pushover","text":"If you're like me and think Fail2Ban is an awesome tool for intrusion protection, getting a notification when someone has been banned is the bee's knees! And using Pushover makes it very simple!","title":"Adding ban/unban notifications from Fail2Ban to Pushover!"},{"location":"blog/adding-ban-unban-notifications-from-fail2ban-with-pushover/#setting-up-pushover","text":"Head over to https://pushover.net/ and create a user account and add the devices you want to receive notifications. I'm using the iOS app, and that works great for me. The app has a 7 day trail period that lets you try it out without paying for it. On your user page you will see you user key . Save that as we will need that for later. At the bottom you can add your new Fail2Ban application. After you've added the new application it will display it's API token. Save that as we will use that for later. You can also test Pushover by sending a notification manually on the user page.","title":"Setting up Pushover"},{"location":"blog/adding-ban-unban-notifications-from-fail2ban-with-pushover/#adding-the-pushover-action","text":"Head over to your Fail2Ban action.d folder and create a file called pushover.local and add the following # Fail2Ban Pushover configuration file # Adapted Source: https://gist.github.com/sander1/075736a42db2c66bc6ce0fab159ca683 [Definition] # Notify on Startup actionstart = /usr/bin/curl -s -F \"token=<token>\" -F \"user=<user>\" -F \"title=[Fail2Ban] <name>\" -F \"message=Jail <name> has been started successfully.\" https://api.pushover.net/1/messages # Notify on Shutdown actionstop = /usr/bin/curl -s -F \"token=<token>\" -F \"user=<user>\" -F \"title=[Fail2Ban] <name>\" -F \"message=Jail <name> has been stopped.\" https://api.pushover.net/1/messages # actioncheck = # Notify on Banned actionban = /usr/bin/curl -s -F \"token=<token>\" -F \"user=<user>\" -F \"title=[Fail2Ban] <name>\" -F \"message=Banned IP: <ip> Lines containing IP: `grep '<ip>' <logpath>`\" https://api.pushover.net/1/messages # Notify on Unbanned actionunban = /usr/bin/curl -s -F \"token=<token>\" -F \"user=<user>\" -F \"title=[Fail2Ban] <name>\" -F \"message=Unbanned IP: <ip> Lines containing IP: `grep '<ip>' <logpath>`\" https://api.pushover.net/1/messages [Init] # Name of the jail in your jail.local file. default = [your-jail-name] name = default # Application token key token = YOUR-APPLICATION-TOKEN # User API key user = YOUR-USER-KEY [eckosc_quote quote=\"If you dont want it to notify you on startup/shutdown/unban you can just comment that line with a #.\" source=\"\" url=\"\" pull=\"false\"] Like so: #actionstart = /usr/bin/curl -s -F \"token=<token>\" -F \"user=<user>\" -F \"title=[Fail2Ban] <name>\" -F \"message=Jail <name> has been started successfully.\" https://api.pushover.net/1/messages","title":"Adding the Pushover action"},{"location":"blog/adding-ban-unban-notifications-from-fail2ban-with-pushover/#updating-jaillocal","text":"Next edit you jail.local file and add the action. You will have to add to all the jails you want notifications on or you can add it below the [DEFAULT] line. Since I use Cloudflare and already have an action in all my jails, I've added it on the line below. If you don't have another action there already you can just add the line action = pushover eckosc\\_status\\_message title=\"Default action!\" icon=\"\" type=\"error\" message=\"If you only have the **pushover** action in the jail it will not update the iptables as it replaces the default action. You can add the action **iptables-allports**and it will then run both actions when banning\" eckosc\\_status\\_message title=\"Default action!\" icon=\"\" type=\"error\" message=\"If you only have the **pushover** action in the jail it will not update the iptables as it replaces the default action. You can add the action **iptables-allports**and it will then run both actions when banning\"","title":"Updating jail.local"},{"location":"blog/adding-ban-unban-notifications-from-fail2ban-with-pushover/#example","text":"[nginx-http-auth] enabled = true filter = nginx-http-auth action = cloudflare-apiv4 pushover iptables-allports port = http,https logpath = /config/log/nginx/error.log ignoreip = 192.168.1.0/24 Note:**The ignore IP is so that fail2ban won't ban your local IP. Check out https://www.aelius.com/njh/subnet_sheet.html if you are wondering what your ** CIDRnotation is. Most often it will be /24 (netmask 255.255.255.0) To find your netmask run **ipconfig /all** on windows or** ifconfig | grep netmask ** on linux. After you have added the action to all your jails you need to restart fail2ban. For me that will be to restart the swag container as I'm using Docker.","title":"Example:"},{"location":"blog/adding-ban-unban-notifications-from-fail2ban-with-pushover/#banning","text":"A successful ban will look like this: 2019-03-03 16:57:09,608 fail2ban.filter [329]: INFO [nginx-http-auth-technicalramblings] Found 23.92.127.82 - 2019-03-03 16:57:09 2019-03-03 16:57:11,612 fail2ban.filter [329]: INFO [nginx-http-auth-technicalramblings] Found 23.92.127.82 - 2019-03-03 16:57:11 2019-03-03 16:57:12,816 fail2ban.filter [329]: INFO [nginx-http-auth-technicalramblings] Found 23.92.127.82 - 2019-03-03 16:57:12 2019-03-03 16:57:12,900 fail2ban.actions [329]: NOTICE [nginx-http-auth-technicalramblings] Ban 23.92.127.82 Source: https://gist.github.com/sander1/075736a42db2c66bc6ce0fab159ca683","title":"Banning"},{"location":"blog/adding-ban-unban-notifications-from-fail2ban-with-pushover/#for-any-questions-you-can-find-me-here","text":"","title":"For any questions you can find me here:"},{"location":"blog/adding-ban-unban-notifications-from-fail2ban-with-pushover/#_1","text":"","title":""},{"location":"blog/blocking-countries-with-geolite2-using-the-letsencrypt-docker-container/","text":"Blocking countries with GeoLite2 in nginx using the swag/letsencrypt docker container \u00b6 Since the GeoLite legacy database has been discontinued , we now have to use the GeoLite2 database to get new updates to the database. This will be a followup article from the post i made about the legacy database. As the new GeoLite2 database uses a new format ( maxminddb ) we couldn't just switch to the new database. Nginx also needed to be compiled with the geoip2 modul. And with Aptalca's pull request on the alpine repo added it will just be a matter of a minor update to the **nginx.conf** file! GeoLite2 database \u00b6 eckosc\\_status\\_message title=\"Update\" icon=\"fa-exclamation-triangle\" type=\"info\" message=\"As of 15.05.20 you can add the variable -e **MAXMINDDB\\_LICENSE\\_KEY** = <lisencekey> to have the container download the database and update it weekly!\" eckosc\\_status\\_message title=\"Update\" icon=\"fa-exclamation-triangle\" type=\"info\" message=\"As of 15.05.20 you can add the variable -e **MAXMINDDB\\_LICENSE\\_KEY** = <lisencekey> to have the container download the database and update it weekly!\" As of 12/30/19 you have to sign up to Maxmind to be able to download the database. https://blog.maxmind.com/2019/12/18/significant-changes-to-accessing-and-using-geolite2-databases/ Create an account and go to your account page to download the database. Download the database and extract the .mmdb file to the folder of you choice. I'll be using /config/geoip2db/ for my setup. NGINX \u00b6 In the latest version of nginx.conf there is now a line that says #include /config/nginx/geoip2.conf; Uncomment that line. If you dont have that line, you can just add it. Open the geoip2.conf file and find the line that says map $geoip2_data_country_iso_code $allowed_country { As it says default must be either yes or no. To block everything set it no . Add the country codes you want to allow accessfrom this list. e.g. US yes; This will block all other countries than the one you choose. You can also add more than one country if you want. Like this: # GEOIP2 COUNTRY CONFIG map $geoip2_data_country_iso_code $allowed_country { default no; US yes; } Now since we have set default to no, you will need to add the local ip ranges that you want to allow access in the $allow_list variable below. Like this: # ALLOW LOCAL ACCESS geo $allow_list { default no; 192.168.1.0/24 yes; } Remember to also set default to **no** in in the $allow_list Check out https://www.aelius.com/njh/subnet_sheet.html if you are wondering what your CIDRnotation is. Most often it will be /24 (netmask 255.255.255.0) To find your netmask run **ipconfig /all** on windows or** ifconfig | grep netmask ** on linux. Note: The ALLOW LOCAL ACCESS part is only needed if you set default to no in the map $geoip2_data_country_iso_code config. Setting default to no means that it will block any IP addresses from the database not set to yes , even local ones. For it to actually block you need to add this in your server blocks inside the proxy-confs and site-confs folder: if ($allow_list = yes) { set $allowed_country yes; } if ($allowed_country = no) { return 444; } Here is an example using the unifi-controller.subdomain.conf in proxy-confs : server { listen 443 ssl; listen [::]:443 ssl; server_name unifi.*; include /config/nginx/ssl.conf; #COUNTRY GEO BLOCK if ($allow_list = yes) { set $allowed_country yes; } if ($allowed_country = no) { return 444; } client_max_body_size 0; # enable for ldap auth, fill in ldap details in ldap.conf #include /config/nginx/ldap.conf; # enable for Authelia #include /config/nginx/authelia-server.conf; location / { # enable the next two lines for http auth #auth_basic \"Restricted\"; #auth_basic_user_file /config/nginx/.htpasswd; # enable the next two lines for ldap auth #auth_request /auth; #error_page 401 =200 /ldaplogin; # enable for Authelia #include /config/nginx/authelia-location.conf; include /config/nginx/proxy.conf; resolver 127.0.0.11 valid=30s; set $upstream_app unifi-controller; set $upstream_port 8443; set $upstream_proto https; proxy_pass $upstream_proto://$upstream_app:$upstream_port; proxy_buffering off; } } Multiple geo blocks \u00b6 If you host several websites and want a different country block just add another with a different variable name. e.g. $allowed_country2 : # GEO IP BLOCK DOMAIN 2 map $geoip2_data_country_iso_code $allowed_country2 { default yes; CN no; #China RU no; #Russia HK no; #Hong Kong IN no; #India IR no; #Iran VN no; #Vietnam TR no; #Turkey EG no; #Egypt MX no; #Mexico JP no; #Japan KR no; #South Korea KP no; #North Korea :) PE no; #Peru BR no; #Brazil UA no; #Ukraine ID no; #Indonesia TH no; #Thailand } As **default** is set to yes **it will allow every country except the country codes set to ** no And in the server block add this # COUNTRY GEO BLOCK 2 if ($allowed_country2 = no) { return 444; } I made this list based on the Spamhaus statistics and Aakamai's state of the internet report. Blocked \u00b6 You can test if it worked with a VPN or do a performance test from a location that is blocked here https://www.webpagetest.org/ TIP! This database gets updated! \u00b6 eckosc\\_status\\_message title=\"Update\" icon=\"fa-exclamation-triangle\" type=\"info\" message=\"As of 15.05.20 you can add the variable -e MAXMINDDB\\_LICENSE\\_KEY = <lisencekey> to have the container download the database and update it weekly!\" eckosc\\_status\\_message title=\"Update\" icon=\"fa-exclamation-triangle\" type=\"info\" message=\"As of 15.05.20 you can add the variable -e MAXMINDDB\\_LICENSE\\_KEY = <lisencekey> to have the container download the database and update it weekly!\" By setting up a cronjob you can easily automate the update process. I use the Unraid User Scripts plugin and set a cronjob to run every day but the GeoLite2 Country and City databases are updated on the first Tuesday of each month, so choose whatever suits your needs. Click on Add New Script \u2192 Enter the name\u2192 Click on the name of the script and then **Edit** **Script** eckosc\\_status\\_message title=\"Warning\" icon=\"fa-exclamation-triangle\" type=\"error\" message=\"Since you need to sign up to Maxmind.com to download you need to create a licence key to be able to directly download the database\" eckosc\\_status\\_message title=\"Warning\" icon=\"fa-exclamation-triangle\" type=\"error\" message=\"Since you need to sign up to Maxmind.com to download you need to create a licence key to be able to directly download the database\" Go to the licence keys page and create a license key. Select no when asked if you want to use the key with geoupdate. Replace XXXXXXXXXX with your license key. #!/usr/bin/env bash licensekey=\"XXXXXXXXXXXXX\" wget -O /tmp/GeoLite2-City.tar.gz \"https://download.maxmind.com/app/geoip_download?edition_id=GeoLite2-City&license_key=${licensekey}&suffix=tar.gz\" tar -xvf /tmp/GeoLite2-City.tar.gz -C /tmp/ --wildcards \"*.mmdb\" --strip 1 mv /tmp/GeoLite2-City.mmdb /mnt/user/appdata/swag/geolite2/ chown 911:911 /mnt/user/appdata/letsencrypt/geolite2/GeoLite2-City.mmdb Set the schedule to **Schedule Daily**or whenever you'd like. Click Run In Background and then** Apply ** Cloudflare \u00b6 eckosc\\_status\\_message title=\"Update: cloudflare\\_real-ip - Docker mod for SWAG\" icon=\"fa-exclamation-triangle\" type=\"info\" message=\"Check out the docker mod https://github.com/linuxserver/docker-mods/tree/swag-cloudflare-real-ip This mod adds a startup scipt that gets the IP's from Cloudflares edge servers, and formats them in a format Nginx can use with set\\_real\\_ip\\_from.\" eckosc\\_status\\_message title=\"Update: cloudflare\\_real-ip - Docker mod for SWAG\" icon=\"fa-exclamation-triangle\" type=\"info\" message=\"Check out the docker mod https://github.com/linuxserver/docker-mods/tree/swag-cloudflare-real-ip This mod adds a startup scipt that gets the IP's from Cloudflares edge servers, and formats them in a format Nginx can use with set\\_real\\_ip\\_from.\" If you use Cloudflare you will need to add the following in nginx so that it won't block the Cloudflare IP but the actual IP of the visitor. If you don't do this you will get false positives. Add the following section to your nginx.conf file found in **appdata/swag/nginx/** set_real_ip_from 103.21.244.0/22; set_real_ip_from 103.22.200.0/22; set_real_ip_from 103.31.4.0/22; set_real_ip_from 104.16.0.0/13; set_real_ip_from 104.24.0.0/14; set_real_ip_from 108.162.192.0/18; set_real_ip_from 131.0.72.0/22; set_real_ip_from 141.101.64.0/18; set_real_ip_from 162.158.0.0/15; set_real_ip_from 172.64.0.0/13; set_real_ip_from 173.245.48.0/20; set_real_ip_from 188.114.96.0/20; set_real_ip_from 190.93.240.0/20; set_real_ip_from 197.234.240.0/22; set_real_ip_from 198.41.128.0/17; set_real_ip_from 2400:cb00::/32; set_real_ip_from 2606:4700::/32; set_real_ip_from 2803:f800::/32; set_real_ip_from 2405:b500::/32; set_real_ip_from 2405:8100::/32; set_real_ip_from 2c0f:f248::/32; set_real_ip_from 2a06:98c0::/29; real_ip_header X-Forwarded-For; You can set it up as an include like this too: ## # CF Real IP ## include /config/nginx/cf_real-ip.conf; real_ip_header X-Forwarded-For; After that you need to restart the swag container for the changes to take effect. Automatically updating thecf_real-ip.conf \u00b6 Tronyx over at the discord forums graciously shared his script for updating the Cloudflare ip list. This list is not static and Cloudflare updates it once in a while. The script below will update the list with any changes in the list of IPs from CF #!/usr/bin/env bash curl -s 'https://www.cloudflare.com/ips-v4' > /tmp/cf.txt curl -s 'https://www.cloudflare.com/ips-v6' >> /tmp/cf.txt sed 's/^/set_real_ip_from /' /tmp/cf.txt > /tmp/cf2.txt sed -e 's/$/;/' /tmp/cf2.txt > /home/swag/config/nginx/cf_real-ip.conf I use unraid so I will use the User Scripts plugin to setup a cronjob that will run once a week. Go to Settings > User Scripts and click Add New Script Give it a name and a description if you want Click edit script and add it inside the box. You will need to update the path in the last line to you nginx appdata folder Set the schedule to weekly and click apply and done. #!/bin/bash curl -s 'https://www.cloudflare.com/ips-v4' > /tmp/cf.txt curl -s 'https://www.cloudflare.com/ips-v6' >> /tmp/cf.txt sed 's/^/set_real_ip_from /' /tmp/cf.txt > /tmp/cf2.txt sed -e 's/$/;/' /tmp/cf2.txt > /mnt/user/appdata/swag/nginx/cf_real-ip.conf If you need any extra help join the Discord server! \u00b6 \u00b6 Souce: https://github.com/leev/ngx _http_geoip2_module https://dev.maxmind.com/geoip/legacy/install/country/ http://dev.maxmind.com/geoip/legacy/codes/iso3166/ https://www.howtoforge.com/nginx-how-to-block-visitors-by-country-with-the-geoip-module-debian-ubuntu https://www.spamhaus.org/statistics/botnet-cc/ https://www.akamai.com/us/en/multimedia/documents/state-of-the-internet/q3-2017-state-of-the-internet-security-report.pdf","title":"Blocking countries with GeoLite2 in nginx using the swag docker container"},{"location":"blog/blocking-countries-with-geolite2-using-the-letsencrypt-docker-container/#blocking-countries-with-geolite2-in-nginx-using-the-swagletsencrypt-docker-container","text":"Since the GeoLite legacy database has been discontinued , we now have to use the GeoLite2 database to get new updates to the database. This will be a followup article from the post i made about the legacy database. As the new GeoLite2 database uses a new format ( maxminddb ) we couldn't just switch to the new database. Nginx also needed to be compiled with the geoip2 modul. And with Aptalca's pull request on the alpine repo added it will just be a matter of a minor update to the **nginx.conf** file!","title":"Blocking countries with GeoLite2 in nginx using the swag/letsencrypt docker container"},{"location":"blog/blocking-countries-with-geolite2-using-the-letsencrypt-docker-container/#geolite2-database","text":"eckosc\\_status\\_message title=\"Update\" icon=\"fa-exclamation-triangle\" type=\"info\" message=\"As of 15.05.20 you can add the variable -e **MAXMINDDB\\_LICENSE\\_KEY** = <lisencekey> to have the container download the database and update it weekly!\" eckosc\\_status\\_message title=\"Update\" icon=\"fa-exclamation-triangle\" type=\"info\" message=\"As of 15.05.20 you can add the variable -e **MAXMINDDB\\_LICENSE\\_KEY** = <lisencekey> to have the container download the database and update it weekly!\" As of 12/30/19 you have to sign up to Maxmind to be able to download the database. https://blog.maxmind.com/2019/12/18/significant-changes-to-accessing-and-using-geolite2-databases/ Create an account and go to your account page to download the database. Download the database and extract the .mmdb file to the folder of you choice. I'll be using /config/geoip2db/ for my setup.","title":"GeoLite2 database"},{"location":"blog/blocking-countries-with-geolite2-using-the-letsencrypt-docker-container/#nginx","text":"In the latest version of nginx.conf there is now a line that says #include /config/nginx/geoip2.conf; Uncomment that line. If you dont have that line, you can just add it. Open the geoip2.conf file and find the line that says map $geoip2_data_country_iso_code $allowed_country { As it says default must be either yes or no. To block everything set it no . Add the country codes you want to allow accessfrom this list. e.g. US yes; This will block all other countries than the one you choose. You can also add more than one country if you want. Like this: # GEOIP2 COUNTRY CONFIG map $geoip2_data_country_iso_code $allowed_country { default no; US yes; } Now since we have set default to no, you will need to add the local ip ranges that you want to allow access in the $allow_list variable below. Like this: # ALLOW LOCAL ACCESS geo $allow_list { default no; 192.168.1.0/24 yes; } Remember to also set default to **no** in in the $allow_list Check out https://www.aelius.com/njh/subnet_sheet.html if you are wondering what your CIDRnotation is. Most often it will be /24 (netmask 255.255.255.0) To find your netmask run **ipconfig /all** on windows or** ifconfig | grep netmask ** on linux. Note: The ALLOW LOCAL ACCESS part is only needed if you set default to no in the map $geoip2_data_country_iso_code config. Setting default to no means that it will block any IP addresses from the database not set to yes , even local ones. For it to actually block you need to add this in your server blocks inside the proxy-confs and site-confs folder: if ($allow_list = yes) { set $allowed_country yes; } if ($allowed_country = no) { return 444; } Here is an example using the unifi-controller.subdomain.conf in proxy-confs : server { listen 443 ssl; listen [::]:443 ssl; server_name unifi.*; include /config/nginx/ssl.conf; #COUNTRY GEO BLOCK if ($allow_list = yes) { set $allowed_country yes; } if ($allowed_country = no) { return 444; } client_max_body_size 0; # enable for ldap auth, fill in ldap details in ldap.conf #include /config/nginx/ldap.conf; # enable for Authelia #include /config/nginx/authelia-server.conf; location / { # enable the next two lines for http auth #auth_basic \"Restricted\"; #auth_basic_user_file /config/nginx/.htpasswd; # enable the next two lines for ldap auth #auth_request /auth; #error_page 401 =200 /ldaplogin; # enable for Authelia #include /config/nginx/authelia-location.conf; include /config/nginx/proxy.conf; resolver 127.0.0.11 valid=30s; set $upstream_app unifi-controller; set $upstream_port 8443; set $upstream_proto https; proxy_pass $upstream_proto://$upstream_app:$upstream_port; proxy_buffering off; } }","title":"NGINX"},{"location":"blog/blocking-countries-with-geolite2-using-the-letsencrypt-docker-container/#multiple-geo-blocks","text":"If you host several websites and want a different country block just add another with a different variable name. e.g. $allowed_country2 : # GEO IP BLOCK DOMAIN 2 map $geoip2_data_country_iso_code $allowed_country2 { default yes; CN no; #China RU no; #Russia HK no; #Hong Kong IN no; #India IR no; #Iran VN no; #Vietnam TR no; #Turkey EG no; #Egypt MX no; #Mexico JP no; #Japan KR no; #South Korea KP no; #North Korea :) PE no; #Peru BR no; #Brazil UA no; #Ukraine ID no; #Indonesia TH no; #Thailand } As **default** is set to yes **it will allow every country except the country codes set to ** no And in the server block add this # COUNTRY GEO BLOCK 2 if ($allowed_country2 = no) { return 444; } I made this list based on the Spamhaus statistics and Aakamai's state of the internet report.","title":"Multiple geo blocks"},{"location":"blog/blocking-countries-with-geolite2-using-the-letsencrypt-docker-container/#blocked","text":"You can test if it worked with a VPN or do a performance test from a location that is blocked here https://www.webpagetest.org/","title":"Blocked"},{"location":"blog/blocking-countries-with-geolite2-using-the-letsencrypt-docker-container/#tip-this-database-gets-updated","text":"eckosc\\_status\\_message title=\"Update\" icon=\"fa-exclamation-triangle\" type=\"info\" message=\"As of 15.05.20 you can add the variable -e MAXMINDDB\\_LICENSE\\_KEY = <lisencekey> to have the container download the database and update it weekly!\" eckosc\\_status\\_message title=\"Update\" icon=\"fa-exclamation-triangle\" type=\"info\" message=\"As of 15.05.20 you can add the variable -e MAXMINDDB\\_LICENSE\\_KEY = <lisencekey> to have the container download the database and update it weekly!\" By setting up a cronjob you can easily automate the update process. I use the Unraid User Scripts plugin and set a cronjob to run every day but the GeoLite2 Country and City databases are updated on the first Tuesday of each month, so choose whatever suits your needs. Click on Add New Script \u2192 Enter the name\u2192 Click on the name of the script and then **Edit** **Script** eckosc\\_status\\_message title=\"Warning\" icon=\"fa-exclamation-triangle\" type=\"error\" message=\"Since you need to sign up to Maxmind.com to download you need to create a licence key to be able to directly download the database\" eckosc\\_status\\_message title=\"Warning\" icon=\"fa-exclamation-triangle\" type=\"error\" message=\"Since you need to sign up to Maxmind.com to download you need to create a licence key to be able to directly download the database\" Go to the licence keys page and create a license key. Select no when asked if you want to use the key with geoupdate. Replace XXXXXXXXXX with your license key. #!/usr/bin/env bash licensekey=\"XXXXXXXXXXXXX\" wget -O /tmp/GeoLite2-City.tar.gz \"https://download.maxmind.com/app/geoip_download?edition_id=GeoLite2-City&license_key=${licensekey}&suffix=tar.gz\" tar -xvf /tmp/GeoLite2-City.tar.gz -C /tmp/ --wildcards \"*.mmdb\" --strip 1 mv /tmp/GeoLite2-City.mmdb /mnt/user/appdata/swag/geolite2/ chown 911:911 /mnt/user/appdata/letsencrypt/geolite2/GeoLite2-City.mmdb Set the schedule to **Schedule Daily**or whenever you'd like. Click Run In Background and then** Apply **","title":"TIP! This database gets updated!"},{"location":"blog/blocking-countries-with-geolite2-using-the-letsencrypt-docker-container/#cloudflare","text":"eckosc\\_status\\_message title=\"Update: cloudflare\\_real-ip - Docker mod for SWAG\" icon=\"fa-exclamation-triangle\" type=\"info\" message=\"Check out the docker mod https://github.com/linuxserver/docker-mods/tree/swag-cloudflare-real-ip This mod adds a startup scipt that gets the IP's from Cloudflares edge servers, and formats them in a format Nginx can use with set\\_real\\_ip\\_from.\" eckosc\\_status\\_message title=\"Update: cloudflare\\_real-ip - Docker mod for SWAG\" icon=\"fa-exclamation-triangle\" type=\"info\" message=\"Check out the docker mod https://github.com/linuxserver/docker-mods/tree/swag-cloudflare-real-ip This mod adds a startup scipt that gets the IP's from Cloudflares edge servers, and formats them in a format Nginx can use with set\\_real\\_ip\\_from.\" If you use Cloudflare you will need to add the following in nginx so that it won't block the Cloudflare IP but the actual IP of the visitor. If you don't do this you will get false positives. Add the following section to your nginx.conf file found in **appdata/swag/nginx/** set_real_ip_from 103.21.244.0/22; set_real_ip_from 103.22.200.0/22; set_real_ip_from 103.31.4.0/22; set_real_ip_from 104.16.0.0/13; set_real_ip_from 104.24.0.0/14; set_real_ip_from 108.162.192.0/18; set_real_ip_from 131.0.72.0/22; set_real_ip_from 141.101.64.0/18; set_real_ip_from 162.158.0.0/15; set_real_ip_from 172.64.0.0/13; set_real_ip_from 173.245.48.0/20; set_real_ip_from 188.114.96.0/20; set_real_ip_from 190.93.240.0/20; set_real_ip_from 197.234.240.0/22; set_real_ip_from 198.41.128.0/17; set_real_ip_from 2400:cb00::/32; set_real_ip_from 2606:4700::/32; set_real_ip_from 2803:f800::/32; set_real_ip_from 2405:b500::/32; set_real_ip_from 2405:8100::/32; set_real_ip_from 2c0f:f248::/32; set_real_ip_from 2a06:98c0::/29; real_ip_header X-Forwarded-For; You can set it up as an include like this too: ## # CF Real IP ## include /config/nginx/cf_real-ip.conf; real_ip_header X-Forwarded-For; After that you need to restart the swag container for the changes to take effect.","title":"Cloudflare"},{"location":"blog/blocking-countries-with-geolite2-using-the-letsencrypt-docker-container/#automatically-updating-thecf_real-ipconf","text":"Tronyx over at the discord forums graciously shared his script for updating the Cloudflare ip list. This list is not static and Cloudflare updates it once in a while. The script below will update the list with any changes in the list of IPs from CF #!/usr/bin/env bash curl -s 'https://www.cloudflare.com/ips-v4' > /tmp/cf.txt curl -s 'https://www.cloudflare.com/ips-v6' >> /tmp/cf.txt sed 's/^/set_real_ip_from /' /tmp/cf.txt > /tmp/cf2.txt sed -e 's/$/;/' /tmp/cf2.txt > /home/swag/config/nginx/cf_real-ip.conf I use unraid so I will use the User Scripts plugin to setup a cronjob that will run once a week. Go to Settings > User Scripts and click Add New Script Give it a name and a description if you want Click edit script and add it inside the box. You will need to update the path in the last line to you nginx appdata folder Set the schedule to weekly and click apply and done. #!/bin/bash curl -s 'https://www.cloudflare.com/ips-v4' > /tmp/cf.txt curl -s 'https://www.cloudflare.com/ips-v6' >> /tmp/cf.txt sed 's/^/set_real_ip_from /' /tmp/cf.txt > /tmp/cf2.txt sed -e 's/$/;/' /tmp/cf2.txt > /mnt/user/appdata/swag/nginx/cf_real-ip.conf","title":"Automatically updating thecf_real-ip.conf"},{"location":"blog/blocking-countries-with-geolite2-using-the-letsencrypt-docker-container/#if-you-need-any-extra-help-join-the-discord-server","text":"","title":"If you need any extra help join the Discord server!"},{"location":"blog/blocking-countries-with-geolite2-using-the-letsencrypt-docker-container/#_1","text":"Souce: https://github.com/leev/ngx _http_geoip2_module https://dev.maxmind.com/geoip/legacy/install/country/ http://dev.maxmind.com/geoip/legacy/codes/iso3166/ https://www.howtoforge.com/nginx-how-to-block-visitors-by-country-with-the-geoip-module-debian-ubuntu https://www.spamhaus.org/statistics/botnet-cc/ https://www.akamai.com/us/en/multimedia/documents/state-of-the-internet/q3-2017-state-of-the-internet-security-report.pdf","title":""},{"location":"blog/blocking-ssh-connections-with-the-geolite2-database/","text":"Blocking SSH Connections with the GeoLite2 Database \u00b6 This guide will make it possible to block SSH access to your server based on the origin of the IP trying to access it! First and foremost, I need to give credit where it is due. This method is a modified and combined version of these two approaches to achieving this, so most of the credit goes to them: https://www.claudiokuenzler.com/blog/676/ssh-access-filter-based-on-geoip-database-allow-deny https://www.axllent.org/docs/view/ssh-geoip/ Setting up the MaxMind GeoLite2 Database \u00b6 The first thing we need to do is get yourself a copy of the MaxMind GeoLite2 Database. This will allow the detection of the Country of origin of IP addresses that try to access your Server. You can follow the first bit of instructions from the post \u201cBlocking countries with GeoLite2 in Nginx using the LetsEncrypt Docker container\u201d found here . As the database gets updated regularly, it\u2019s a good idea to automate downloading the database. The above linked post covers that for Unraid, so you can follow those instructions. If you\u2019re not using Unraid, just create the script and create a cronjob manually. Setting Up GeoIP Blocking for SSH \u00b6 Now that the database for the IP lookup is in place, we can move on to configuring the use of the lookup to deny SSH access to the Server based on the Country the IP is associated with. We will need to install two packages to get this all working. The first one is the command-line tool for performing the IP lookups, mmdb-bin . The second one is a modified grep utility, called grepcidr , for CIDR notated IP addresses, IE: 192.168.1.0/24 . On Ubuntu 18.04, you can do this with the following command: apt install mmdb-bin grepcidr Next, we will setup the script that performs the lookup of the IP address that is attempting to access your Server to determine the Country that it\u2019s coming from. Create the script wherever you would like, but make sure it\u2019s easy to remember as we will need it for another step, IE: /home/tronyx/scripts/ssh_filter.sh . Paste in the following code to create the script: #!/usr/bin/env bash # UPPERCASE space-separated country codes to ACCEPT ALLOW_COUNTRIES = \"US\" # Make sure you add your Country code here # Space-separated list of IPs to whitelist # You can use CIDR notation as well, IE: 192.168.1.0/24 ALLOW_IPS = \"\" # You can add your public IP address here if [[ $# -ne 1 ]] ; then echo \"Usage: `basename $0 ` <ip>\" 1 > & 2 exit 0 # return true in case of config issue fi # Fixed static IP echo $1 | /usr/bin/grepcidr \" $ALLOW_IPS \" & > /dev/null if [ ${ PIPESTATUS [1] } -eq 0 ] ; then RESPONSE = \"ALLOW\" logger \" $RESPONSE sshd connection from $1 (Whitelisted)\" exit 0 fi COUNTRY = \" $( /usr/bin/mmdblookup -f /home/letsencrypt-vps/config/geolite2/GeoLite2-City.mmdb -i \" $1 \" country iso_code 2 > & 1 | awk -F '\"' '{ print $2 }' | head -n 2 | tail -n 1 ) \" [[ $COUNTRY = \"IP Address not found\" || $ALLOW_COUNTRIES = ~ $COUNTRY ]] && RESPONSE = \"ALLOW\" || RESPONSE = \"DENY\" if [ $RESPONSE = \"ALLOW\" ] then exit 0 else logger \" $RESPONSE sshd connection from $1 ( $COUNTRY )\" exit 1 fi Make sure to put the country codes into the allow for any Country that you want to allow access from, especially the Country that you live in, so that you do not lose access to your Server. You can find a list of all of the country codes HERE . If you would like, you can add your public IP address to the whitelist, if your server is remote, to ensure you never get blocked, but you shouldn\u2019t be blocking the Country where you live anyway. Make the script executable with the following command: chmod a+x /home/tronyx/scripts/ssh_filter.sh Locking Down SSH \u00b6 The final thing that we need to do is lock SSH down by telling it what IP addresses to deny and which ones to allow, determined by the script that we just created. Add the following to the /etc/hosts.deny file: sshd: ALL This will initially block all connections to the Server via SSH. Then, add the following to the /etc/hosts.allow file: sshd: ALL: aclexec /home/tronyx/scripts/ssh_filter.sh %a This part tells it to execute the ssh_filter.sh script against the IP address that is attempting to connect to the Server via SSH to determine whether or not the IP address is allowed to connect. If the lookup of the IP address fails to determine the Country it\u2019s from, like a private IP address for example, it will allow the connection. Time to Test \u00b6 Now that we\u2019ve got all of the requirements in place, we can test the script to make sure that it\u2019s doing what it\u2019s supposed to. We can do this by running the script against some IP addresses from Countries that we\u2019ve configured the script to block and allow. I am located in the US, so I\u2019m going to first test the IP of one of Google\u2019s DNS Servers: /home/tronyx/scripts/ssh_filter.sh 8.8.8.8 The script will not output anything, and it\u2019s only configured to log deny and whitelist messages to the /var/log/syslog file, so you want to make sure that you do not see a deny message for the IP address you are testing. Next, as I\u2019m only allowing IP addresses from the US, I\u2019m going to test an IP address from China and one from Germany to make sure I see a deny message in the syslog for both of them: /home/tronyx/scripts/ssh_filter.sh 222.186.180.130 /home/tronyx/scripts/ssh_filter.sh 95.217.185.78 Looking at the at the /var/log/syslog file, I see that both IP addresses were denied: Apr 26 12:05:04 1and1-vps root: DENY sshd connection from 222.186.180.130 (CN) Apr 26 12:07:11 1and1-vps tronyx: DENY sshd connection from 95.217.185.78 (DE) A user that was trying to connect to your Server via SSH from a Country that you\u2019re blocking would simply see that the connection was closed or that it was unable to be established, like this: ssh_exchange_identification: Connection closed by remote host When accessing SSH from an IP address that you\u2019ve added to the whitelist, the entry in the /var/log/syslog will look like this: Apr 26 12:07:30 1and1-vps tronyx: ALLOW sshd connection from 192.168.1.2 (Whitelisted) Congratulations, your Server is now denying SSH connections based on the Country in which the IP address is associated!","title":"Blocking SSH Connections with the GeoLite2 Database"},{"location":"blog/blocking-ssh-connections-with-the-geolite2-database/#blocking-ssh-connections-with-the-geolite2-database","text":"This guide will make it possible to block SSH access to your server based on the origin of the IP trying to access it! First and foremost, I need to give credit where it is due. This method is a modified and combined version of these two approaches to achieving this, so most of the credit goes to them: https://www.claudiokuenzler.com/blog/676/ssh-access-filter-based-on-geoip-database-allow-deny https://www.axllent.org/docs/view/ssh-geoip/","title":"Blocking SSH Connections with the GeoLite2 Database"},{"location":"blog/blocking-ssh-connections-with-the-geolite2-database/#setting-up-the-maxmind-geolite2-database","text":"The first thing we need to do is get yourself a copy of the MaxMind GeoLite2 Database. This will allow the detection of the Country of origin of IP addresses that try to access your Server. You can follow the first bit of instructions from the post \u201cBlocking countries with GeoLite2 in Nginx using the LetsEncrypt Docker container\u201d found here . As the database gets updated regularly, it\u2019s a good idea to automate downloading the database. The above linked post covers that for Unraid, so you can follow those instructions. If you\u2019re not using Unraid, just create the script and create a cronjob manually.","title":"Setting up the MaxMind GeoLite2 Database"},{"location":"blog/blocking-ssh-connections-with-the-geolite2-database/#setting-up-geoip-blocking-for-ssh","text":"Now that the database for the IP lookup is in place, we can move on to configuring the use of the lookup to deny SSH access to the Server based on the Country the IP is associated with. We will need to install two packages to get this all working. The first one is the command-line tool for performing the IP lookups, mmdb-bin . The second one is a modified grep utility, called grepcidr , for CIDR notated IP addresses, IE: 192.168.1.0/24 . On Ubuntu 18.04, you can do this with the following command: apt install mmdb-bin grepcidr Next, we will setup the script that performs the lookup of the IP address that is attempting to access your Server to determine the Country that it\u2019s coming from. Create the script wherever you would like, but make sure it\u2019s easy to remember as we will need it for another step, IE: /home/tronyx/scripts/ssh_filter.sh . Paste in the following code to create the script: #!/usr/bin/env bash # UPPERCASE space-separated country codes to ACCEPT ALLOW_COUNTRIES = \"US\" # Make sure you add your Country code here # Space-separated list of IPs to whitelist # You can use CIDR notation as well, IE: 192.168.1.0/24 ALLOW_IPS = \"\" # You can add your public IP address here if [[ $# -ne 1 ]] ; then echo \"Usage: `basename $0 ` <ip>\" 1 > & 2 exit 0 # return true in case of config issue fi # Fixed static IP echo $1 | /usr/bin/grepcidr \" $ALLOW_IPS \" & > /dev/null if [ ${ PIPESTATUS [1] } -eq 0 ] ; then RESPONSE = \"ALLOW\" logger \" $RESPONSE sshd connection from $1 (Whitelisted)\" exit 0 fi COUNTRY = \" $( /usr/bin/mmdblookup -f /home/letsencrypt-vps/config/geolite2/GeoLite2-City.mmdb -i \" $1 \" country iso_code 2 > & 1 | awk -F '\"' '{ print $2 }' | head -n 2 | tail -n 1 ) \" [[ $COUNTRY = \"IP Address not found\" || $ALLOW_COUNTRIES = ~ $COUNTRY ]] && RESPONSE = \"ALLOW\" || RESPONSE = \"DENY\" if [ $RESPONSE = \"ALLOW\" ] then exit 0 else logger \" $RESPONSE sshd connection from $1 ( $COUNTRY )\" exit 1 fi Make sure to put the country codes into the allow for any Country that you want to allow access from, especially the Country that you live in, so that you do not lose access to your Server. You can find a list of all of the country codes HERE . If you would like, you can add your public IP address to the whitelist, if your server is remote, to ensure you never get blocked, but you shouldn\u2019t be blocking the Country where you live anyway. Make the script executable with the following command: chmod a+x /home/tronyx/scripts/ssh_filter.sh","title":"Setting Up GeoIP Blocking for SSH"},{"location":"blog/blocking-ssh-connections-with-the-geolite2-database/#locking-down-ssh","text":"The final thing that we need to do is lock SSH down by telling it what IP addresses to deny and which ones to allow, determined by the script that we just created. Add the following to the /etc/hosts.deny file: sshd: ALL This will initially block all connections to the Server via SSH. Then, add the following to the /etc/hosts.allow file: sshd: ALL: aclexec /home/tronyx/scripts/ssh_filter.sh %a This part tells it to execute the ssh_filter.sh script against the IP address that is attempting to connect to the Server via SSH to determine whether or not the IP address is allowed to connect. If the lookup of the IP address fails to determine the Country it\u2019s from, like a private IP address for example, it will allow the connection.","title":"Locking Down SSH"},{"location":"blog/blocking-ssh-connections-with-the-geolite2-database/#time-to-test","text":"Now that we\u2019ve got all of the requirements in place, we can test the script to make sure that it\u2019s doing what it\u2019s supposed to. We can do this by running the script against some IP addresses from Countries that we\u2019ve configured the script to block and allow. I am located in the US, so I\u2019m going to first test the IP of one of Google\u2019s DNS Servers: /home/tronyx/scripts/ssh_filter.sh 8.8.8.8 The script will not output anything, and it\u2019s only configured to log deny and whitelist messages to the /var/log/syslog file, so you want to make sure that you do not see a deny message for the IP address you are testing. Next, as I\u2019m only allowing IP addresses from the US, I\u2019m going to test an IP address from China and one from Germany to make sure I see a deny message in the syslog for both of them: /home/tronyx/scripts/ssh_filter.sh 222.186.180.130 /home/tronyx/scripts/ssh_filter.sh 95.217.185.78 Looking at the at the /var/log/syslog file, I see that both IP addresses were denied: Apr 26 12:05:04 1and1-vps root: DENY sshd connection from 222.186.180.130 (CN) Apr 26 12:07:11 1and1-vps tronyx: DENY sshd connection from 95.217.185.78 (DE) A user that was trying to connect to your Server via SSH from a Country that you\u2019re blocking would simply see that the connection was closed or that it was unable to be established, like this: ssh_exchange_identification: Connection closed by remote host When accessing SSH from an IP address that you\u2019ve added to the whitelist, the entry in the /var/log/syslog will look like this: Apr 26 12:07:30 1and1-vps tronyx: ALLOW sshd connection from 192.168.1.2 (Whitelisted) Congratulations, your Server is now denying SSH connections based on the Country in which the IP address is associated!","title":"Time to Test"},{"location":"blog/cloudflare-fail2ban-integration-with-automated-set_real_ip_from-in-nginx/","text":"How to setup Cloudflare and fail2ban with automated \"set_real_ip_from\" in nginx \u00b6 If you've decided to use cloudflare as a CDN you've might have noticed that fail2ban isn't working as expected. The fail2ban.log file will say that it has banned an IP, but since the connection is going through Cloudflare it will still let the banned IP browse your website. But luckily Cloudflare has an API we can use to update the Cloudflare firewall on the fly. Adding the action \u00b6 If you've read my other fail2ban guides you already know I'm using linuxservers swag container. So there won't be any walkthrough of installing fail2ban. I will only go through the cloudflare configuration. Go to your appdata location and find the action.d folder **appdata/swag/fail2ban/action.d** In that folder there already is an action for cloudflare ( cloudflare.conf ) but that is using the deprecated API. Create a new file called cloudflare-apiv4.conf and add the following: # # Author: Gilbn from https://technicalramblings.com # Adapted Source: https://github.com/fail2ban/fail2ban/blob/master/config/action.d/cloudflare.conf and https://guides.wp-bullet.com/integrate-fail2ban-cloudflare-api-v4-guide/ # # To get your Cloudflare API key: https://dash.cloudflare.com/profile use the Global API Key # [Definition] # Option: actionstart # Notes.: command executed once at the start of Fail2Ban. # Values: CMD # actionstart = # Option: actionstop # Notes.: command executed once at the end of Fail2Ban # Values: CMD # actionstop = # Option: actioncheck # Notes.: command executed once before each actionban command # Values: CMD # actioncheck = # Option: actionban # Notes.: command executed when banning an IP. Take care that the # command is executed with Fail2Ban user rights. # Tags: IP address # number of failures # unix timestamp of the ban time # Values: CMD actionban = curl -s -X POST \"https://api.cloudflare.com/client/v4/user/firewall/access_rules/rules\" \\ -H \"X-Auth-Email: <cfuser>\" \\ -H \"X-Auth-Key: <cftoken>\" \\ -H \"Content-Type: application/json\" \\ --data '{\"mode\":\"block\",\"configuration\":{\"target\":\"ip\",\"value\":\"<ip>\"},\"notes\":\"Fail2ban <name>\"}' # Option: actionunban # Notes.: command executed when unbanning an IP. Take care that the # command is executed with Fail2Ban user rights. # Tags: IP address # number of failures # unix timestamp of the ban time # Values: CMD # actionunban = curl -s -X DELETE \"https://api.cloudflare.com/client/v4/user/firewall/access_rules/rules/$( \\ curl -s -X GET \"https://api.cloudflare.com/client/v4/user/firewall/access_rules/rules?mode=block&configuration_target=ip&configuration_value=<ip>&page=1&per_page=1&match=all\" \\ -H \"X-Auth-Email: <cfuser>\" \\ -H \"X-Auth-Key: <cftoken>\" \\ -H \"Content-Type: application/json\" | awk -F\"[,:}]\" '{for(i=1;i<=NF;i++){if($i~/'id'\\042/){print $(i+1);}}}' | tr -d '\"' | sed -e 's/^[ \\t]*//' | head -n 1)\" \\ -H \"X-Auth-Email: <cfuser>\" \\ -H \"X-Auth-Key: <cftoken>\" \\ -H \"Content-Type: application/json\" [Init] # Name of the jail in your jail.local file. default = [jail name] name = default # Option: cfuser # Notes.: Replaces <cfuser> in actionban and actionunban with cfuser value below # Values: Your CloudFlare user account cfuser = user@mail.com # Option: cftoken (Global API Key) # Notes.: Replaces <cftoken> in actionban and actionunban with cftoken value below # Values: Your CloudFlare API key cftoken = YOUR-API-KEY The unban curl command from https://guides.wp-bullet.com/integrate-fail2ban-cloudflare-api-v4-guide/ did not work for me but changing it to what this user on serverfault shared did https://serverfault.com/a/912547 At the end of the config file add your cloudflare email on the \" cfuser \" line and add your Cloudflare token on the \" cftoken \" line. Your Cloudflare token can be found on your profile page. Use the \" Global API Key \" \u00b6 Updating jail.local \u00b6 Next is updating or adding your jails in the jail.local file. Go to your appdata location **appdata/swag/fail2ban/** and edit the file called jail.local. The only thing you really need to add is the action fail2ban will run after it has banned an IP. Add action = cloudflare-apiv4 in the jails you want to use it on. For me that would be all the jails. Example: [eckosc_status_message title=\"Default action!\" icon=\"\" type=\"error\" message=\"If you only have the **cloudflare**action in the jail it will not update the iptables as it replaces the default action. You can add the action **iptables-allports**and it will then run both actions when banning\"] [nginx-http-auth] enabled = true filter = nginx-http-auth action = cloudflare-apiv4 iptables-allports port = http,https logpath = /config/log/nginx/error.log ignoreip = 192.168.1.0/24 [organizrv2-auth] enabled = true filter = organizrv2-auth action = cloudflare-apiv4 iptables-allports port = http,https logpath = /fail2ban/organizrLoginLog.json ignoreip = 192.168.1.0/24 Optional: Specifying which site the ban works on \u00b6 If you have several sites on your Cloudflare account and you want to specify which one the action should work on, you need to change the URL on the actionban line. Instead of user it needs to say / zones / and then your zone ID . actionban = curl -s -X POST \"https://api.cloudflare.com/client/v4/zones/YOUR-CLOUDFLARE-ZONE-ID/firewall/access_rules/rules\" \\ And the same on the actionunban line: actionunban = curl -s -X DELETE \"https://api.cloudflare.com/client/v4/zones/YOUR-CLOUDFLARE-ZONE-ID/firewall/access_rules/rules/$( \\ curl -s -X GET \"https://api.cloudflare.com/client/v4/zones/YOUR-CLOUDFLARE-ZONE-ID/firewall/access_rules/rules?mode=block&configuration_target=ip&configuration_value=1.2.3.4&page=1&per_page=1&match=all\" \\ Your zone ID can be found on the overview page on Cloudflare. \u00b6 I recommend adding a whitelist on your WAN IP so you don't accidently ban yourself! You can add the whitelist on Cloudflare by going to Firewall and then Tools. There you can add the access rule. Nginx \u00b6 Next up is configuring nginx so that it won't just ban the Cloudflare CDN IP but the actual IP of the visitor. Add the following section to your http block in the nginx.conf file found in **appdata/swag/nginx/** set_real_ip_from 103.21.244.0/22; set_real_ip_from 103.22.200.0/22; set_real_ip_from 103.31.4.0/22; set_real_ip_from 104.16.0.0/12; set_real_ip_from 108.162.192.0/18; set_real_ip_from 131.0.72.0/22; set_real_ip_from 141.101.64.0/18; set_real_ip_from 162.158.0.0/15; set_real_ip_from 172.64.0.0/13; set_real_ip_from 173.245.48.0/20; set_real_ip_from 188.114.96.0/20; set_real_ip_from 190.93.240.0/20; set_real_ip_from 197.234.240.0/22; set_real_ip_from 198.41.128.0/17; set_real_ip_from 2400:cb00::/32; set_real_ip_from 2606:4700::/32; set_real_ip_from 2803:f800::/32; set_real_ip_from 2405:b500::/32; set_real_ip_from 2405:8100::/32; set_real_ip_from 2c0f:f248::/32; set_real_ip_from 2a06:98c0::/29; real_ip_header X-Forwarded-For; The IP's are from these URLS: https://www.cloudflare.com/ips-v4 https://www.cloudflare.com/ips-v6 You can set it up as an include like this too: ## # CF Real IP ## include /config/nginx/cf_real-ip.conf; real_ip_header X-Forwarded-For; After that you need to restart the swag container for the changes to take effect. Next you can test that it actually works by using a vpn ect and ban yourself. Set bantime to 60 for it to only ban the IP for 1 minute. After the IP is banned you can see the new firewall rule on cloudflare dashboard. I've noticed that with the new API it is much faster in banning and unbanning IP's! When using the old API it could sometimes take up to 2 minutes for the rule to show in Cloudflare. Now it's there in a matter of seconds. Automatically updating thecf_real-ip.conf \u00b6 Tronyx over at the discord forums graciously shared his script for updating the Cloudflare ip list. This list is not static and Cloudflare updates it once in a while. The script below will update the list with any changes in the list of IPs from CF #!/bin/bash printf \"set_real_ip_from %b;\\n\" $({ curl -s -w '\\n' \"https://www.cloudflare.com/ips-v4\" & curl -s -w '\\n' \"https://www.cloudflare.com/ips-v6\" & ip route | grep -v default | awk '{print $1}' }) > /mnt/nvme/docker/swag/nginx/cf_real-ip.conf I use unraid so I will use the User Scripts plugin to setup a cronjob that will run once a week. Go to Settings > User Scripts and click Add New Script Give it a name and a description if you want Click edit script and add it inside the box. You will need to update the path in the last line to you nginx appdata folder Set the schedule to weekly and click apply and done. #!/bin/bash printf \"set_real_ip_from %b;\\n\" $({ curl -s -w '\\n' \"https://www.cloudflare.com/ips-v4\" & curl -s -w '\\n' \"https://www.cloudflare.com/ips-v6\" & ip route | grep -v default | awk '{print $1}' }) > /mnt/user/docker/swag/nginx/cf_real-ip.conf For any questions you can find me here: \u00b6 \u00b6 Sources: Tronyx \ud83d\ude18 Thank you Tronyx for creating the first draft of the guide. https://guides.wp-bullet.com/integrate-fail2ban-cloudflare-api-v4-guide https://serverfault.com/a/912547","title":"How to setup Cloudflare and fail2ban with automated \u201cset_real_ip_from\u201d in nginx"},{"location":"blog/cloudflare-fail2ban-integration-with-automated-set_real_ip_from-in-nginx/#how-to-setup-cloudflare-and-fail2ban-with-automated-set_real_ip_from-in-nginx","text":"If you've decided to use cloudflare as a CDN you've might have noticed that fail2ban isn't working as expected. The fail2ban.log file will say that it has banned an IP, but since the connection is going through Cloudflare it will still let the banned IP browse your website. But luckily Cloudflare has an API we can use to update the Cloudflare firewall on the fly.","title":"How to setup Cloudflare and fail2ban with automated \"set_real_ip_from\" in nginx"},{"location":"blog/cloudflare-fail2ban-integration-with-automated-set_real_ip_from-in-nginx/#adding-the-action","text":"If you've read my other fail2ban guides you already know I'm using linuxservers swag container. So there won't be any walkthrough of installing fail2ban. I will only go through the cloudflare configuration. Go to your appdata location and find the action.d folder **appdata/swag/fail2ban/action.d** In that folder there already is an action for cloudflare ( cloudflare.conf ) but that is using the deprecated API. Create a new file called cloudflare-apiv4.conf and add the following: # # Author: Gilbn from https://technicalramblings.com # Adapted Source: https://github.com/fail2ban/fail2ban/blob/master/config/action.d/cloudflare.conf and https://guides.wp-bullet.com/integrate-fail2ban-cloudflare-api-v4-guide/ # # To get your Cloudflare API key: https://dash.cloudflare.com/profile use the Global API Key # [Definition] # Option: actionstart # Notes.: command executed once at the start of Fail2Ban. # Values: CMD # actionstart = # Option: actionstop # Notes.: command executed once at the end of Fail2Ban # Values: CMD # actionstop = # Option: actioncheck # Notes.: command executed once before each actionban command # Values: CMD # actioncheck = # Option: actionban # Notes.: command executed when banning an IP. Take care that the # command is executed with Fail2Ban user rights. # Tags: IP address # number of failures # unix timestamp of the ban time # Values: CMD actionban = curl -s -X POST \"https://api.cloudflare.com/client/v4/user/firewall/access_rules/rules\" \\ -H \"X-Auth-Email: <cfuser>\" \\ -H \"X-Auth-Key: <cftoken>\" \\ -H \"Content-Type: application/json\" \\ --data '{\"mode\":\"block\",\"configuration\":{\"target\":\"ip\",\"value\":\"<ip>\"},\"notes\":\"Fail2ban <name>\"}' # Option: actionunban # Notes.: command executed when unbanning an IP. Take care that the # command is executed with Fail2Ban user rights. # Tags: IP address # number of failures # unix timestamp of the ban time # Values: CMD # actionunban = curl -s -X DELETE \"https://api.cloudflare.com/client/v4/user/firewall/access_rules/rules/$( \\ curl -s -X GET \"https://api.cloudflare.com/client/v4/user/firewall/access_rules/rules?mode=block&configuration_target=ip&configuration_value=<ip>&page=1&per_page=1&match=all\" \\ -H \"X-Auth-Email: <cfuser>\" \\ -H \"X-Auth-Key: <cftoken>\" \\ -H \"Content-Type: application/json\" | awk -F\"[,:}]\" '{for(i=1;i<=NF;i++){if($i~/'id'\\042/){print $(i+1);}}}' | tr -d '\"' | sed -e 's/^[ \\t]*//' | head -n 1)\" \\ -H \"X-Auth-Email: <cfuser>\" \\ -H \"X-Auth-Key: <cftoken>\" \\ -H \"Content-Type: application/json\" [Init] # Name of the jail in your jail.local file. default = [jail name] name = default # Option: cfuser # Notes.: Replaces <cfuser> in actionban and actionunban with cfuser value below # Values: Your CloudFlare user account cfuser = user@mail.com # Option: cftoken (Global API Key) # Notes.: Replaces <cftoken> in actionban and actionunban with cftoken value below # Values: Your CloudFlare API key cftoken = YOUR-API-KEY The unban curl command from https://guides.wp-bullet.com/integrate-fail2ban-cloudflare-api-v4-guide/ did not work for me but changing it to what this user on serverfault shared did https://serverfault.com/a/912547 At the end of the config file add your cloudflare email on the \" cfuser \" line and add your Cloudflare token on the \" cftoken \" line. Your Cloudflare token can be found on your profile page. Use the \" Global API Key \"","title":"Adding the action"},{"location":"blog/cloudflare-fail2ban-integration-with-automated-set_real_ip_from-in-nginx/#_1","text":"","title":""},{"location":"blog/cloudflare-fail2ban-integration-with-automated-set_real_ip_from-in-nginx/#updating-jaillocal","text":"Next is updating or adding your jails in the jail.local file. Go to your appdata location **appdata/swag/fail2ban/** and edit the file called jail.local. The only thing you really need to add is the action fail2ban will run after it has banned an IP. Add action = cloudflare-apiv4 in the jails you want to use it on. For me that would be all the jails. Example: [eckosc_status_message title=\"Default action!\" icon=\"\" type=\"error\" message=\"If you only have the **cloudflare**action in the jail it will not update the iptables as it replaces the default action. You can add the action **iptables-allports**and it will then run both actions when banning\"] [nginx-http-auth] enabled = true filter = nginx-http-auth action = cloudflare-apiv4 iptables-allports port = http,https logpath = /config/log/nginx/error.log ignoreip = 192.168.1.0/24 [organizrv2-auth] enabled = true filter = organizrv2-auth action = cloudflare-apiv4 iptables-allports port = http,https logpath = /fail2ban/organizrLoginLog.json ignoreip = 192.168.1.0/24","title":"Updating jail.local"},{"location":"blog/cloudflare-fail2ban-integration-with-automated-set_real_ip_from-in-nginx/#optional-specifying-which-site-the-ban-works-on","text":"If you have several sites on your Cloudflare account and you want to specify which one the action should work on, you need to change the URL on the actionban line. Instead of user it needs to say / zones / and then your zone ID . actionban = curl -s -X POST \"https://api.cloudflare.com/client/v4/zones/YOUR-CLOUDFLARE-ZONE-ID/firewall/access_rules/rules\" \\ And the same on the actionunban line: actionunban = curl -s -X DELETE \"https://api.cloudflare.com/client/v4/zones/YOUR-CLOUDFLARE-ZONE-ID/firewall/access_rules/rules/$( \\ curl -s -X GET \"https://api.cloudflare.com/client/v4/zones/YOUR-CLOUDFLARE-ZONE-ID/firewall/access_rules/rules?mode=block&configuration_target=ip&configuration_value=1.2.3.4&page=1&per_page=1&match=all\" \\ Your zone ID can be found on the overview page on Cloudflare.","title":"Optional: Specifying which site the ban works on"},{"location":"blog/cloudflare-fail2ban-integration-with-automated-set_real_ip_from-in-nginx/#_2","text":"I recommend adding a whitelist on your WAN IP so you don't accidently ban yourself! You can add the whitelist on Cloudflare by going to Firewall and then Tools. There you can add the access rule.","title":""},{"location":"blog/cloudflare-fail2ban-integration-with-automated-set_real_ip_from-in-nginx/#nginx","text":"Next up is configuring nginx so that it won't just ban the Cloudflare CDN IP but the actual IP of the visitor. Add the following section to your http block in the nginx.conf file found in **appdata/swag/nginx/** set_real_ip_from 103.21.244.0/22; set_real_ip_from 103.22.200.0/22; set_real_ip_from 103.31.4.0/22; set_real_ip_from 104.16.0.0/12; set_real_ip_from 108.162.192.0/18; set_real_ip_from 131.0.72.0/22; set_real_ip_from 141.101.64.0/18; set_real_ip_from 162.158.0.0/15; set_real_ip_from 172.64.0.0/13; set_real_ip_from 173.245.48.0/20; set_real_ip_from 188.114.96.0/20; set_real_ip_from 190.93.240.0/20; set_real_ip_from 197.234.240.0/22; set_real_ip_from 198.41.128.0/17; set_real_ip_from 2400:cb00::/32; set_real_ip_from 2606:4700::/32; set_real_ip_from 2803:f800::/32; set_real_ip_from 2405:b500::/32; set_real_ip_from 2405:8100::/32; set_real_ip_from 2c0f:f248::/32; set_real_ip_from 2a06:98c0::/29; real_ip_header X-Forwarded-For; The IP's are from these URLS: https://www.cloudflare.com/ips-v4 https://www.cloudflare.com/ips-v6 You can set it up as an include like this too: ## # CF Real IP ## include /config/nginx/cf_real-ip.conf; real_ip_header X-Forwarded-For; After that you need to restart the swag container for the changes to take effect. Next you can test that it actually works by using a vpn ect and ban yourself. Set bantime to 60 for it to only ban the IP for 1 minute. After the IP is banned you can see the new firewall rule on cloudflare dashboard. I've noticed that with the new API it is much faster in banning and unbanning IP's! When using the old API it could sometimes take up to 2 minutes for the rule to show in Cloudflare. Now it's there in a matter of seconds.","title":"Nginx"},{"location":"blog/cloudflare-fail2ban-integration-with-automated-set_real_ip_from-in-nginx/#automatically-updating-thecf_real-ipconf","text":"Tronyx over at the discord forums graciously shared his script for updating the Cloudflare ip list. This list is not static and Cloudflare updates it once in a while. The script below will update the list with any changes in the list of IPs from CF #!/bin/bash printf \"set_real_ip_from %b;\\n\" $({ curl -s -w '\\n' \"https://www.cloudflare.com/ips-v4\" & curl -s -w '\\n' \"https://www.cloudflare.com/ips-v6\" & ip route | grep -v default | awk '{print $1}' }) > /mnt/nvme/docker/swag/nginx/cf_real-ip.conf I use unraid so I will use the User Scripts plugin to setup a cronjob that will run once a week. Go to Settings > User Scripts and click Add New Script Give it a name and a description if you want Click edit script and add it inside the box. You will need to update the path in the last line to you nginx appdata folder Set the schedule to weekly and click apply and done. #!/bin/bash printf \"set_real_ip_from %b;\\n\" $({ curl -s -w '\\n' \"https://www.cloudflare.com/ips-v4\" & curl -s -w '\\n' \"https://www.cloudflare.com/ips-v6\" & ip route | grep -v default | awk '{print $1}' }) > /mnt/user/docker/swag/nginx/cf_real-ip.conf","title":"Automatically updating thecf_real-ip.conf"},{"location":"blog/cloudflare-fail2ban-integration-with-automated-set_real_ip_from-in-nginx/#for-any-questions-you-can-find-me-here","text":"","title":"For any questions you can find me here:"},{"location":"blog/cloudflare-fail2ban-integration-with-automated-set_real_ip_from-in-nginx/#_3","text":"Sources: Tronyx \ud83d\ude18 Thank you Tronyx for creating the first draft of the guide. https://guides.wp-bullet.com/integrate-fail2ban-cloudflare-api-v4-guide https://serverfault.com/a/912547","title":""},{"location":"blog/how-to-add-a-custom-login-page-for-unraid/","text":"How to add a custom login page for Unraid! \u00b6 As I said in my previous post, I have for some time now been creating css themes/skins for different applications that reside in the \u201cmedia server/selfhosting\u201d category. That also included the Unraid webUI, but up until recently only the login page. Last week I added the rest of the WebUI to the theme suite. Custom login page \u00b6 The custom login page have 3 types with different sub themes. Retro Terminal, Alien and Fallout \u251c\u2500\u2500 Retro Terminal \u2502 \u251c\u2500\u2500 amber.css \u2502 \u251c\u2500\u2500 red.css \u2502 \u251c\u2500\u2500 green.css \u2502 \u251c\u2500\u2500 blue.css \u2502 \u251c\u2500\u2500 white.css \u2502 \u2514\u2500\u2500 custom.css /* Make it your own */ \u251c\u2500\u2500 Alien \u2502 \u251c\u2500\u2500 hallway.css \u2502 \u251c\u2500\u2500 hallway2.css \u2502 \u251c\u2500\u2500 hallway3.css \u2502 \u251c\u2500\u2500 hallway4.css \u2502 \u251c\u2500\u2500 isolation.css \u2502 \u251c\u2500\u2500 isolation_video.css \u2502 \u251c\u2500\u2500 scanner.css \u2502 \u251c\u2500\u2500 nightmare.css \u2502 \u2514\u2500\u2500 custom.css /* Make it your own */ \u2514\u2500\u2500 Fallout \u251c\u2500\u2500 terminal.css \u251c\u2500\u2500 terminal2.css \u251c\u2500\u2500 dirty_terminal.css \u251c\u2500\u2500 dirty_terminal2.css \u251c\u2500\u2500 fallout_video.css \u2514\u2500\u2500 custom.css /* Make it your own */ Retro Terminal \u00b6 \u00b6 Alien \u00b6 \u00b6 Fallout \u00b6 \u00b6 Installation \u00b6 To install the custom css and javascript(optional) we must edit the html in the login.php file located at /usr/local/emhttp/login.php To do that , I've created a bash script that uses sed to inject an html link tag for our custom css stylesheet. If you're unfamiliar with running scripts, the easiest way to run would be to use the plugin** CA User Scripts . Install the plugin and add a new user script by clicking Add new script Give it a name and click OK Click or hover over the gear icon and click Edit Script Paste the contents of the bash script: custom_login.sh ** Below the shebang( #!/bin/bash ) are the variables you need to change for the different themes. The default values are the ones below TYPE = \"retro-terminal\" THEME = \"green.css\" DOMAIN = \"theme-park.dev\" ADD_JS = \"true\" JS = \"custom_text_header.js\" DISABLE_THEME = \"false\" Set the values to what you like, and click Save Changes To have the script applied at every boot, set the schedule to At Startup of Array Now just click Run Script and it will print some text in the window. Thats it.. logout and have a look at your new theme :) Javascript \u00b6 The javascript variable will add some custom html tags into the login page. The Retro Terminal javascript adds an animated <pre> tag that says nostromolink. It's inspired by a blog post by Stephen Brennan. If you want something else, there are a ton of ACSII generators out there. Retro Terminal Javascript: \u00b6 Set ADD_JS to \"true\" to enable. Set JS to custom_text_header.js custom_text_header.js Alien Theme Javascript: \u00b6 isolation.js Injects an animated video wallpaper from the Alien: Isolation game. Set THEME to isolation_video.css Set ADD_JS to \"true\" Set JS to isolation.js Fallout Theme Javascript: \u00b6 please_stand_by.js vault-tec-crt.js vault-tec-crt_no-scanline.js Set THEME to fallout_video.css Set ADD_JS to \"true\" to enable. Choose the video you want. See: videos Available js: please_stand_by.js , vault-tec-crt.js , vault-tec-crt_no-scanline.js Set JS to the one you want. vault-tec-crt.js vault-tec-crt_no-scanline.js please_stand_by.js FAQ \u00b6 Backups \u00b6 The script will create a backup of the login.php file if one does not exist. Uninstall/Restore the original \u00b6 To uninstall the theme set the variable DISABLE_THEME to \"true\" Can I selfhost this? \u00b6 Of course! Just clone the repo into your webserver. Remember to change the DOMAIN variable in the bash script. My server is not connected to the internet! How can I add this? \u00b6 With the current version of the bash script, that is not possible as it injects the stylesheet using the a URL and not a file path. However, nothing is stopping you from just doing some small changes to the script and replace the href urls to the path you stored the files. I will try and create a version of the script that is made for local hosting in the future. I hate the flickering!! \u00b6 To remove the background flickering you need to edit the css file. Now since you don't have any control over those files, you'll need to fork it and setup Github pages or selfhost them. You can't use the raw link from Github, as they don't pass the mime types. The background flickering can be disabled by setting the --body-animation root variable to none The <pre> tag flicker can be disabled by setting --custom-text-header-animation to none . I hate the CRT lines!! \u00b6 Set the --body-before and --body-after root variables to none I want my own logo!! \u00b6 Fork it and change the --logo variable or if you're using stylus ect, just add a new --logo root variable below the import line. I don't like XYZ !! \u00b6 To change the colors,background, logo ect you need to edit the css file. Now since you don't have any control over those files, you'll need to fork it and setup Github pages or selfhost the files. You can't use the raw link from Github, as they don't pass the mime types. Each css file have a bunch of variables you can change to your linking. All CSS and javascript files can be found here: https://github.com/gilbN/theme.park/tree/master/css/addons/unraid/login-page Example: : root { --main-bg-color : black ; --body-before : #00ff77 1 a ; --body-after : #00ff77 33 ; --body-animation : flicker ; --logo : url ( https://theme-park.dev/css/addons/unraid/login-page/alien/logo/wings_green.png ) center no-repeat ; --text-color : #37f592 ; --input-color : #37f592 ; --link-color : #37f592 ; --link-color-hover : #68ffff ; --case-color : #37f592 ; --button-text-color : #37f592 ; --button-text-color-hover : #000 ; --button-color : #37f592 ; --button-color-hover : #68ffff ; --selection-color : #68ffff ; --custom-text-header : #37f592 ; --custom-text-header-shadow : #37f592 ; --custom-text-header-animation : textflicker ; --input-font : 'Share Tech Mono' , monospace ; --text-font : 'Share Tech Mono' , monospace ; --loginbox-background-color : transparent ; --text-shadow : 0 0 8 px ; --text-shadow-color : #37f592 ; --box-shadow : 0 0 15 px ; } Custom Unraid Themes \u00b6 Installation \u00b6 The custom themes for the Unraid WebUI are the same as the ones in my theme.park repository . Aquamarine, Hotline, Plex, Space-gray, Dark, and Organizr-dark. The easiest way to add them is to use the Theme Engine plugin. Install the Theme Engine plugin from the CA appstore and open it. Set Base Theme to black Enable Advanced View Scroll down and set Enable custom styling (below): to Yes Add the HTML below in the Custom styling (advanced): textarea. Remember to change <THEME> to the theme you want. </ style >< link type = \"text/css\" rel = \"Stylesheet\" href = \"https://theme-park.dev/css/themes/unraid/<THEME>.css\" /> Example: </ style >< link type = \"text/css\" rel = \"Stylesheet\" href = \"https://theme-park.dev/css/themes/unraid/plex.css\" /> Installation","title":"How to add a custom login page for Unraid!"},{"location":"blog/how-to-add-a-custom-login-page-for-unraid/#how-to-add-a-custom-login-page-for-unraid","text":"As I said in my previous post, I have for some time now been creating css themes/skins for different applications that reside in the \u201cmedia server/selfhosting\u201d category. That also included the Unraid webUI, but up until recently only the login page. Last week I added the rest of the WebUI to the theme suite.","title":"How to add a custom login page for Unraid!"},{"location":"blog/how-to-add-a-custom-login-page-for-unraid/#custom-login-page","text":"The custom login page have 3 types with different sub themes. Retro Terminal, Alien and Fallout \u251c\u2500\u2500 Retro Terminal \u2502 \u251c\u2500\u2500 amber.css \u2502 \u251c\u2500\u2500 red.css \u2502 \u251c\u2500\u2500 green.css \u2502 \u251c\u2500\u2500 blue.css \u2502 \u251c\u2500\u2500 white.css \u2502 \u2514\u2500\u2500 custom.css /* Make it your own */ \u251c\u2500\u2500 Alien \u2502 \u251c\u2500\u2500 hallway.css \u2502 \u251c\u2500\u2500 hallway2.css \u2502 \u251c\u2500\u2500 hallway3.css \u2502 \u251c\u2500\u2500 hallway4.css \u2502 \u251c\u2500\u2500 isolation.css \u2502 \u251c\u2500\u2500 isolation_video.css \u2502 \u251c\u2500\u2500 scanner.css \u2502 \u251c\u2500\u2500 nightmare.css \u2502 \u2514\u2500\u2500 custom.css /* Make it your own */ \u2514\u2500\u2500 Fallout \u251c\u2500\u2500 terminal.css \u251c\u2500\u2500 terminal2.css \u251c\u2500\u2500 dirty_terminal.css \u251c\u2500\u2500 dirty_terminal2.css \u251c\u2500\u2500 fallout_video.css \u2514\u2500\u2500 custom.css /* Make it your own */","title":"Custom login page"},{"location":"blog/how-to-add-a-custom-login-page-for-unraid/#retro-terminal","text":"","title":"Retro Terminal"},{"location":"blog/how-to-add-a-custom-login-page-for-unraid/#_1","text":"","title":""},{"location":"blog/how-to-add-a-custom-login-page-for-unraid/#alien","text":"","title":"Alien"},{"location":"blog/how-to-add-a-custom-login-page-for-unraid/#_2","text":"","title":""},{"location":"blog/how-to-add-a-custom-login-page-for-unraid/#fallout","text":"","title":"Fallout"},{"location":"blog/how-to-add-a-custom-login-page-for-unraid/#_3","text":"","title":""},{"location":"blog/how-to-add-a-custom-login-page-for-unraid/#installation","text":"To install the custom css and javascript(optional) we must edit the html in the login.php file located at /usr/local/emhttp/login.php To do that , I've created a bash script that uses sed to inject an html link tag for our custom css stylesheet. If you're unfamiliar with running scripts, the easiest way to run would be to use the plugin** CA User Scripts . Install the plugin and add a new user script by clicking Add new script Give it a name and click OK Click or hover over the gear icon and click Edit Script Paste the contents of the bash script: custom_login.sh ** Below the shebang( #!/bin/bash ) are the variables you need to change for the different themes. The default values are the ones below TYPE = \"retro-terminal\" THEME = \"green.css\" DOMAIN = \"theme-park.dev\" ADD_JS = \"true\" JS = \"custom_text_header.js\" DISABLE_THEME = \"false\" Set the values to what you like, and click Save Changes To have the script applied at every boot, set the schedule to At Startup of Array Now just click Run Script and it will print some text in the window. Thats it.. logout and have a look at your new theme :)","title":"Installation"},{"location":"blog/how-to-add-a-custom-login-page-for-unraid/#javascript","text":"The javascript variable will add some custom html tags into the login page. The Retro Terminal javascript adds an animated <pre> tag that says nostromolink. It's inspired by a blog post by Stephen Brennan. If you want something else, there are a ton of ACSII generators out there.","title":"Javascript"},{"location":"blog/how-to-add-a-custom-login-page-for-unraid/#retro-terminal-javascript","text":"Set ADD_JS to \"true\" to enable. Set JS to custom_text_header.js custom_text_header.js","title":"Retro Terminal Javascript:"},{"location":"blog/how-to-add-a-custom-login-page-for-unraid/#alien-theme-javascript","text":"isolation.js Injects an animated video wallpaper from the Alien: Isolation game. Set THEME to isolation_video.css Set ADD_JS to \"true\" Set JS to isolation.js","title":"Alien Theme Javascript:"},{"location":"blog/how-to-add-a-custom-login-page-for-unraid/#fallout-theme-javascript","text":"please_stand_by.js vault-tec-crt.js vault-tec-crt_no-scanline.js Set THEME to fallout_video.css Set ADD_JS to \"true\" to enable. Choose the video you want. See: videos Available js: please_stand_by.js , vault-tec-crt.js , vault-tec-crt_no-scanline.js Set JS to the one you want. vault-tec-crt.js vault-tec-crt_no-scanline.js please_stand_by.js","title":"Fallout Theme Javascript:"},{"location":"blog/how-to-add-a-custom-login-page-for-unraid/#faq","text":"","title":"FAQ"},{"location":"blog/how-to-add-a-custom-login-page-for-unraid/#backups","text":"The script will create a backup of the login.php file if one does not exist.","title":"Backups"},{"location":"blog/how-to-add-a-custom-login-page-for-unraid/#uninstallrestore-the-original","text":"To uninstall the theme set the variable DISABLE_THEME to \"true\"","title":"Uninstall/Restore the original"},{"location":"blog/how-to-add-a-custom-login-page-for-unraid/#can-i-selfhost-this","text":"Of course! Just clone the repo into your webserver. Remember to change the DOMAIN variable in the bash script.","title":"Can I selfhost this?"},{"location":"blog/how-to-add-a-custom-login-page-for-unraid/#my-server-is-not-connected-to-the-internet-how-can-i-add-this","text":"With the current version of the bash script, that is not possible as it injects the stylesheet using the a URL and not a file path. However, nothing is stopping you from just doing some small changes to the script and replace the href urls to the path you stored the files. I will try and create a version of the script that is made for local hosting in the future.","title":"My server is not connected to the internet! How can I add this?"},{"location":"blog/how-to-add-a-custom-login-page-for-unraid/#i-hate-the-flickering","text":"To remove the background flickering you need to edit the css file. Now since you don't have any control over those files, you'll need to fork it and setup Github pages or selfhost them. You can't use the raw link from Github, as they don't pass the mime types. The background flickering can be disabled by setting the --body-animation root variable to none The <pre> tag flicker can be disabled by setting --custom-text-header-animation to none .","title":"I hate the flickering!!"},{"location":"blog/how-to-add-a-custom-login-page-for-unraid/#i-hate-the-crt-lines","text":"Set the --body-before and --body-after root variables to none","title":"I hate the CRT lines!!"},{"location":"blog/how-to-add-a-custom-login-page-for-unraid/#i-want-my-own-logo","text":"Fork it and change the --logo variable or if you're using stylus ect, just add a new --logo root variable below the import line.","title":"I want my own logo!!"},{"location":"blog/how-to-add-a-custom-login-page-for-unraid/#i-dont-like-xyz","text":"To change the colors,background, logo ect you need to edit the css file. Now since you don't have any control over those files, you'll need to fork it and setup Github pages or selfhost the files. You can't use the raw link from Github, as they don't pass the mime types. Each css file have a bunch of variables you can change to your linking. All CSS and javascript files can be found here: https://github.com/gilbN/theme.park/tree/master/css/addons/unraid/login-page Example: : root { --main-bg-color : black ; --body-before : #00ff77 1 a ; --body-after : #00ff77 33 ; --body-animation : flicker ; --logo : url ( https://theme-park.dev/css/addons/unraid/login-page/alien/logo/wings_green.png ) center no-repeat ; --text-color : #37f592 ; --input-color : #37f592 ; --link-color : #37f592 ; --link-color-hover : #68ffff ; --case-color : #37f592 ; --button-text-color : #37f592 ; --button-text-color-hover : #000 ; --button-color : #37f592 ; --button-color-hover : #68ffff ; --selection-color : #68ffff ; --custom-text-header : #37f592 ; --custom-text-header-shadow : #37f592 ; --custom-text-header-animation : textflicker ; --input-font : 'Share Tech Mono' , monospace ; --text-font : 'Share Tech Mono' , monospace ; --loginbox-background-color : transparent ; --text-shadow : 0 0 8 px ; --text-shadow-color : #37f592 ; --box-shadow : 0 0 15 px ; }","title":"I don't like XYZ !!"},{"location":"blog/how-to-add-a-custom-login-page-for-unraid/#custom-unraid-themes","text":"","title":"Custom Unraid Themes"},{"location":"blog/how-to-add-a-custom-login-page-for-unraid/#installation_1","text":"The custom themes for the Unraid WebUI are the same as the ones in my theme.park repository . Aquamarine, Hotline, Plex, Space-gray, Dark, and Organizr-dark. The easiest way to add them is to use the Theme Engine plugin. Install the Theme Engine plugin from the CA appstore and open it. Set Base Theme to black Enable Advanced View Scroll down and set Enable custom styling (below): to Yes Add the HTML below in the Custom styling (advanced): textarea. Remember to change <THEME> to the theme you want. </ style >< link type = \"text/css\" rel = \"Stylesheet\" href = \"https://theme-park.dev/css/themes/unraid/<THEME>.css\" /> Example: </ style >< link type = \"text/css\" rel = \"Stylesheet\" href = \"https://theme-park.dev/css/themes/unraid/plex.css\" /> Installation","title":"Installation"},{"location":"blog/how-to-add-dark-mode-to-any-app-with-this-one-simple-trick/","text":"How to add dark mode to any app with this one simple trick! \u00b6 Developers hate me for sharing this one weird trick! Yes..the title is clickbait, and no this does not work on any app/container ;) I have for some time now been creating css themes/skins for different applications that reside in the \"media server/selfhosting\" category. Normally you would add the themes using a \"subfilter\" module like http://nginx.org/en/docs/http/ngx_http_sub_module.html or https://httpd.apache.org/docs/2.4/mod/mod_filter.html . This means that you would have to reverse proxy the application to be able to add the theme. Doing that would only apply the theme when accessing the application though the proxy and not locally. So, to fix that I've created a bunch of docker mods for all the applications that have a linuxserver container. The docker mod, will run a script at startup to inject the stylesheet into the html file using sed . The script does the exact same thing as the subfiltering module except it does it on the backend instead of on the proxy side. You can find all the mods here: https://github.com/gilbN/theme.park/tree/docker-mods The scripts are quite simple and only has a couple of variables. TP_DOMAIN and TP_THEME Both these variable have a default value if not set. TP_DOMAIN is set to theme-park.dev and TP_THEME is set to organizr_dark Example: #!/usr/bin/with-contenv bash echo '---------------------------' echo '| Sonarr theme.park Mod |' echo '---------------------------' # Display variables for troubleshooting echo -e \"Variables set:\\\\n\\ 'TP_DOMAIN'= ${ TP_DOMAIN } \\\\n\\ 'TP_THEME'= ${ TP_THEME } \\\\n\" # Set default if [[ -z ${ TP_DOMAIN } ]] ; then echo 'No domain set, defaulting to theme-park.dev' TP_DOMAIN = 'theme-park.dev' fi if [[ -z ${ TP_THEME } ]] ; then echo 'No theme set, defaulting to organizr-dark' TP_THEME = 'organizr-dark' fi # Adding stylesheets if ! grep -q \" ${ TP_DOMAIN } \" /app/sonarr/bin/UI/index.html ; then echo '---------------------------' echo '| Adding the stylesheet |' echo '---------------------------' sed -i \"s/<\\/head>/<link rel='stylesheet' href='https:\\/\\/ ${ TP_DOMAIN } \\/theme.park\\/CSS\\/themes\\/sonarr\\/ ${ TP_THEME } .css'><\\/head> /g\" /app/sonarr/bin/UI/index.html printf 'Stylesheet set to %s\\n' \" ${ TP_THEME } \" fi Adding the theme \u00b6 Adding the mod, is quite simple. Add the variable DOCKER_MODS=ghcr.io/gilbn/theme.park:<app> e.g. ghcr.io/gilbn/theme.park:sonarr to your docker run command or compose file. On Unraid simply click on + Add another Path, Port, Variable, label or Device And fill out the fields. As noted earlier it will default to the organizr_dark theme and the theme-park.dev domain. So if you want a different theme, you must add the TP_THEME variable with the value you want. The available themes are: aquamarine , hotline , space-gray , dark , plex and organizr Click the banners here for screenshots of the different themes: https://docs.theme-park.dev/#themes You can find applications that support Docker Mods installation here: https://github.com/gilbN/theme.park/tree/docker-mods For other installation methods check the wiki https://docs.theme-park.dev/setup/","title":"How to add dark mode to any app with this one simple trick!"},{"location":"blog/how-to-add-dark-mode-to-any-app-with-this-one-simple-trick/#how-to-add-dark-mode-to-any-app-with-this-one-simple-trick","text":"Developers hate me for sharing this one weird trick! Yes..the title is clickbait, and no this does not work on any app/container ;) I have for some time now been creating css themes/skins for different applications that reside in the \"media server/selfhosting\" category. Normally you would add the themes using a \"subfilter\" module like http://nginx.org/en/docs/http/ngx_http_sub_module.html or https://httpd.apache.org/docs/2.4/mod/mod_filter.html . This means that you would have to reverse proxy the application to be able to add the theme. Doing that would only apply the theme when accessing the application though the proxy and not locally. So, to fix that I've created a bunch of docker mods for all the applications that have a linuxserver container. The docker mod, will run a script at startup to inject the stylesheet into the html file using sed . The script does the exact same thing as the subfiltering module except it does it on the backend instead of on the proxy side. You can find all the mods here: https://github.com/gilbN/theme.park/tree/docker-mods The scripts are quite simple and only has a couple of variables. TP_DOMAIN and TP_THEME Both these variable have a default value if not set. TP_DOMAIN is set to theme-park.dev and TP_THEME is set to organizr_dark Example: #!/usr/bin/with-contenv bash echo '---------------------------' echo '| Sonarr theme.park Mod |' echo '---------------------------' # Display variables for troubleshooting echo -e \"Variables set:\\\\n\\ 'TP_DOMAIN'= ${ TP_DOMAIN } \\\\n\\ 'TP_THEME'= ${ TP_THEME } \\\\n\" # Set default if [[ -z ${ TP_DOMAIN } ]] ; then echo 'No domain set, defaulting to theme-park.dev' TP_DOMAIN = 'theme-park.dev' fi if [[ -z ${ TP_THEME } ]] ; then echo 'No theme set, defaulting to organizr-dark' TP_THEME = 'organizr-dark' fi # Adding stylesheets if ! grep -q \" ${ TP_DOMAIN } \" /app/sonarr/bin/UI/index.html ; then echo '---------------------------' echo '| Adding the stylesheet |' echo '---------------------------' sed -i \"s/<\\/head>/<link rel='stylesheet' href='https:\\/\\/ ${ TP_DOMAIN } \\/theme.park\\/CSS\\/themes\\/sonarr\\/ ${ TP_THEME } .css'><\\/head> /g\" /app/sonarr/bin/UI/index.html printf 'Stylesheet set to %s\\n' \" ${ TP_THEME } \" fi","title":"How to add dark mode to any app with this one simple trick!"},{"location":"blog/how-to-add-dark-mode-to-any-app-with-this-one-simple-trick/#adding-the-theme","text":"Adding the mod, is quite simple. Add the variable DOCKER_MODS=ghcr.io/gilbn/theme.park:<app> e.g. ghcr.io/gilbn/theme.park:sonarr to your docker run command or compose file. On Unraid simply click on + Add another Path, Port, Variable, label or Device And fill out the fields. As noted earlier it will default to the organizr_dark theme and the theme-park.dev domain. So if you want a different theme, you must add the TP_THEME variable with the value you want. The available themes are: aquamarine , hotline , space-gray , dark , plex and organizr Click the banners here for screenshots of the different themes: https://docs.theme-park.dev/#themes You can find applications that support Docker Mods installation here: https://github.com/gilbN/theme.park/tree/docker-mods For other installation methods check the wiki https://docs.theme-park.dev/setup/","title":"Adding the theme"},{"location":"blog/how-to-add-email-notifications-to-fail2ban/","text":"How to add email notifications to Fail2ban \u00b6 Following up an my other two post about Fail2ban notifications, that you can read here: Adding ban/unban notifications from Fail2Ban to Discord! and here Adding ban/unban notifications from Fail2Ban to Pushover! I recently got email notifications working (Thank you count_confucius ) and thought I'd share how to get that working! Adding the action \u00b6 eckosc\\_status\\_message title=\"Note\" icon=\"fa-exclamation-circle\" type=\"info\" message=\"I am using the linuxserver letsencrypt container in this guide. https://github.com/linuxserver/docker-letsencrypt\" eckosc\\_status\\_message title=\"Note\" icon=\"fa-exclamation-circle\" type=\"info\" message=\"I am using the linuxserver letsencrypt container in this guide. https://github.com/linuxserver/docker-letsencrypt\" Go into your /action.d folder and copy and rename sendmail-whois.conf to sendmail-whois.local . Edit the file and replace the actionban and add the actionunban with the code below: actionban = printf %%b \"Subject:\ud83d\udd75\ufe0f [Fail2Ban] <name>: BANNED IP <ip>! \ud83d\udd28 Date: `LC_ALL=C date +\"%%a, %%d %%h %%Y %%T %%z\"` From: <sendername> <<sender>> To: <destination>\\n Hi,\\n The jail <name> has banned ip <ip> after <failures> attempts against <name>.\\n Here is some info about the IP: https://db-ip.com/<ip> \\n Lines containing IP <ip>: \\n `grep '<ip>' <logpath>` \\n Regards,\\n Fail2Ban\" | /usr/sbin/sendmail -t -v -H 'exec openssl s_client -quiet -tls1 -connect smtp.gmail.com:465' -au<from> -ap<password> <destination> actionunban = printf %%b \"Subject:\ud83d\udd14 [Fail2Ban] <name>: UNBANNED IP <ip> \u2705 Date: `LC_ALL=C date +\"%%a, %%d %%h %%Y %%T %%z\"` From: <sendername> <<sender>> To: <destination>\\n Hi,\\n Fail2ban has unbanned ip https://db-ip.com/<ip> successfully. \\n Regards,\\n Fail2Ban\" | /usr/sbin/sendmail -t -v -H 'exec openssl s_client -quiet -tls1 -connect smtp.gmail.com:465' -au<from> -ap<password> <destination> NOTE: If you don't use gmail you need to update the smtp address in the code! Next save the file and copy and rename the sendmail-common.conf file to sendmail-common.local We have to edit this file or else we'll get a lot of errors in the Fail2ban log about failing to send jail startup and shutdown emails. In the sendmail-common.local file remove everything after actionstart = and actionstop = If you want emails on start and stop, add the code above and just change the subject and body of the email. jail.local \u00b6 In your jail.local file add the following in the [DEFAULT] section: action = iptables-allports %(action_mw)s[from=example@gmail.com, password=secretpassword, destination=example@gmail.com, sendername=Fail2Ban] Let's break down the mail action. from = The email account it sends from. password = The password to the sender account. destination = Where you want to send the notification. sendername = Name of the sender. The action iptables-allports is needed because if you only have the send mail action it will override the action that updates the iptables! So it won't ban the IP without it. If you only want to add the mail notification to a specific jail you can add it to just that specific jail. On [DEFAULT] it will be default on every jail in jail.local . Lastly you need to restart fail2ban and try and ban yourself. Email \u00b6 The email will look like this: If you need any extra help join the Discord server! \u00b6 \u00b6","title":"How to add email notifications to Fail2ban"},{"location":"blog/how-to-add-email-notifications-to-fail2ban/#how-to-add-email-notifications-to-fail2ban","text":"Following up an my other two post about Fail2ban notifications, that you can read here: Adding ban/unban notifications from Fail2Ban to Discord! and here Adding ban/unban notifications from Fail2Ban to Pushover! I recently got email notifications working (Thank you count_confucius ) and thought I'd share how to get that working!","title":"How to add email notifications to Fail2ban"},{"location":"blog/how-to-add-email-notifications-to-fail2ban/#adding-the-action","text":"eckosc\\_status\\_message title=\"Note\" icon=\"fa-exclamation-circle\" type=\"info\" message=\"I am using the linuxserver letsencrypt container in this guide. https://github.com/linuxserver/docker-letsencrypt\" eckosc\\_status\\_message title=\"Note\" icon=\"fa-exclamation-circle\" type=\"info\" message=\"I am using the linuxserver letsencrypt container in this guide. https://github.com/linuxserver/docker-letsencrypt\" Go into your /action.d folder and copy and rename sendmail-whois.conf to sendmail-whois.local . Edit the file and replace the actionban and add the actionunban with the code below: actionban = printf %%b \"Subject:\ud83d\udd75\ufe0f [Fail2Ban] <name>: BANNED IP <ip>! \ud83d\udd28 Date: `LC_ALL=C date +\"%%a, %%d %%h %%Y %%T %%z\"` From: <sendername> <<sender>> To: <destination>\\n Hi,\\n The jail <name> has banned ip <ip> after <failures> attempts against <name>.\\n Here is some info about the IP: https://db-ip.com/<ip> \\n Lines containing IP <ip>: \\n `grep '<ip>' <logpath>` \\n Regards,\\n Fail2Ban\" | /usr/sbin/sendmail -t -v -H 'exec openssl s_client -quiet -tls1 -connect smtp.gmail.com:465' -au<from> -ap<password> <destination> actionunban = printf %%b \"Subject:\ud83d\udd14 [Fail2Ban] <name>: UNBANNED IP <ip> \u2705 Date: `LC_ALL=C date +\"%%a, %%d %%h %%Y %%T %%z\"` From: <sendername> <<sender>> To: <destination>\\n Hi,\\n Fail2ban has unbanned ip https://db-ip.com/<ip> successfully. \\n Regards,\\n Fail2Ban\" | /usr/sbin/sendmail -t -v -H 'exec openssl s_client -quiet -tls1 -connect smtp.gmail.com:465' -au<from> -ap<password> <destination> NOTE: If you don't use gmail you need to update the smtp address in the code! Next save the file and copy and rename the sendmail-common.conf file to sendmail-common.local We have to edit this file or else we'll get a lot of errors in the Fail2ban log about failing to send jail startup and shutdown emails. In the sendmail-common.local file remove everything after actionstart = and actionstop = If you want emails on start and stop, add the code above and just change the subject and body of the email.","title":"Adding the action"},{"location":"blog/how-to-add-email-notifications-to-fail2ban/#jaillocal","text":"In your jail.local file add the following in the [DEFAULT] section: action = iptables-allports %(action_mw)s[from=example@gmail.com, password=secretpassword, destination=example@gmail.com, sendername=Fail2Ban] Let's break down the mail action. from = The email account it sends from. password = The password to the sender account. destination = Where you want to send the notification. sendername = Name of the sender. The action iptables-allports is needed because if you only have the send mail action it will override the action that updates the iptables! So it won't ban the IP without it. If you only want to add the mail notification to a specific jail you can add it to just that specific jail. On [DEFAULT] it will be default on every jail in jail.local . Lastly you need to restart fail2ban and try and ban yourself.","title":"jail.local"},{"location":"blog/how-to-add-email-notifications-to-fail2ban/#email","text":"The email will look like this:","title":"Email"},{"location":"blog/how-to-add-email-notifications-to-fail2ban/#if-you-need-any-extra-help-join-the-discord-server","text":"","title":"If you need any extra help join the Discord server!"},{"location":"blog/how-to-add-email-notifications-to-fail2ban/#_1","text":"","title":""},{"location":"blog/how-to-route-different-metrics-in-telegraf-to-different-influx-databases/","text":"How to route different metrics in Telegraf to different Influx databases \u00b6 So, at the beginning of the last couple of years I have dropped my Influx Telegraf database containing all the host metrics gathered from the previous year. I did this because it was getting too big, and my container appdata backups where getting too big and taking too long to backup. Yes I know I could have just set a retention policy on the database and have it cleared every week, but I wanted some long term metrics like disk usage, so I could see the growth over the year. My Influxdb container appdata folder is currently 40GB so lets fix that. Creating the long term database \u00b6 Log into your Influxdb instance. If you use docker you can exec in like so: docker exec -it Influxdb influx where Influxdb is the name of the container. Create the database with the following command: CREATE DATABASE longterm_metrics This creates the database longterm_metrics without any retention policy. If you want a retention policy on the long term metrics, say for example 1 year, you can run this: CREATE DATABASE longterm_metrics WITH DURATION 365d REPLICATION 1 SHARD DURATION 1w NAME RP_longterm_365d This will create the database and set the 365d retention policy to default for that database. If you want you can read more about replication and shards here: https://docs.influxdata.com/influxdb/v1.7/concepts/glossary/#replication-factor and https://docs.influxdata.com/influxdb/v1.7/concepts/glossary/#shard You can also look up retention policies with the show retention policies command. First select which database to use with the use <database> command and then run the show retention policies command like so: > use longterm_metrics Using database longterm_metrics > show retention policies name duration shardGroupDuration replicaN default ---- -------- ------------------ -------- ------- RP_longterm_365d 8760h0m0s 168h0m0s 1 true > Adding a new default retention policy on the Telegraf database \u00b6 Run the following command to create a new default retention policy on the telegraf database: Note This will ''reset'' the whole database! The data won't be gone, it's still accessible using the autogen retention policy. But the command below sets the new one as default , and that's what the panels normally use in Grafana. If you want to migrate some data after you can check out this post https://community.influxdata.com/t/applying-retention-policies-to-existing-measurments/802/2 CREATE RETENTION POLICY \"7_day_retention\" ON \"telegraf\" DURATION 1w REPLICATION 1 SHARD DURATION 1w DEFAULT This will create the retention policy called 7_day_retention and set it as the default policy. After I set the new default retention policy my Influxdb appdata folder went from 40GB to 225MB :) Read more here: https://docs.influxdata.com/influxdb/v1.7/query_language/database_management/#retention-policy-management Sending the metrics to a different database \u00b6 Now in Telegraf we simply need to add an extra output that tells Telegraf to also route the metrics we want to another database. Note This won't stop telegraf from writing the metrics to the OG telegraf database, it will write to both Add the following to the telegraf.conf file. Note add, not replace. [[outputs.influxdb]] urls = [\"http://192.168.1.34:8086\"] # required database = \"longterm_metrics\" # required retention_policy = \"\" write_consistency = \"any\" timeout = \"5s\" namepass = [\"apcupsd\",\"disk\",\"diskio\"] As I didn't add a retention policy for my long term database I have set it to use an empty string as that will use the default retention policy (autogen) of that database. If you first created the database, and then added a retention policy to that database that you want to use, you must set retention_policy = \"<retention_policy>\" to the retention policy you want. If not it will use the autogen retention policy as that is set to default when just running create <database> The namepass = [\"apcupsd\",\"disk\",\"diskio\"] is what tells Telegraf which metrics to send to that specific database. After you've added the lines restart Telegraf. Adding a new datasource in Grafana \u00b6 Since my Telegraf datasource uses the telegraf database, we need to add a new data source that uses our new database. Click on Add data source and select InfluxDB. Next give the data source a name, add the URL to InfluxDB, set the database to use the new database you created and click Save & Test Updating the Grafana panels \u00b6 Next it's just a matter of updating the Grafana panels to use the new data source. If you use my Unraid System Dashboard https://grafana.com/grafana/dashboards/7233 you can just download the latest version and select the disk data source in the drop down. Sources: https://docs.influxdata.com/influxdb/v1.7/query_language/database_management https://docs.influxdata.com/telegraf/v1.13/administration/configuration/ If you need any extra help join the Discord server! \u00b6 \u00b6","title":"How to route metrics in Telegraf to different Influx databases"},{"location":"blog/how-to-route-different-metrics-in-telegraf-to-different-influx-databases/#how-to-route-different-metrics-in-telegraf-to-different-influx-databases","text":"So, at the beginning of the last couple of years I have dropped my Influx Telegraf database containing all the host metrics gathered from the previous year. I did this because it was getting too big, and my container appdata backups where getting too big and taking too long to backup. Yes I know I could have just set a retention policy on the database and have it cleared every week, but I wanted some long term metrics like disk usage, so I could see the growth over the year. My Influxdb container appdata folder is currently 40GB so lets fix that.","title":"How to route different metrics in Telegraf to different Influx databases"},{"location":"blog/how-to-route-different-metrics-in-telegraf-to-different-influx-databases/#creating-the-long-term-database","text":"Log into your Influxdb instance. If you use docker you can exec in like so: docker exec -it Influxdb influx where Influxdb is the name of the container. Create the database with the following command: CREATE DATABASE longterm_metrics This creates the database longterm_metrics without any retention policy. If you want a retention policy on the long term metrics, say for example 1 year, you can run this: CREATE DATABASE longterm_metrics WITH DURATION 365d REPLICATION 1 SHARD DURATION 1w NAME RP_longterm_365d This will create the database and set the 365d retention policy to default for that database. If you want you can read more about replication and shards here: https://docs.influxdata.com/influxdb/v1.7/concepts/glossary/#replication-factor and https://docs.influxdata.com/influxdb/v1.7/concepts/glossary/#shard You can also look up retention policies with the show retention policies command. First select which database to use with the use <database> command and then run the show retention policies command like so: > use longterm_metrics Using database longterm_metrics > show retention policies name duration shardGroupDuration replicaN default ---- -------- ------------------ -------- ------- RP_longterm_365d 8760h0m0s 168h0m0s 1 true >","title":"Creating the long term database"},{"location":"blog/how-to-route-different-metrics-in-telegraf-to-different-influx-databases/#adding-a-new-default-retention-policy-on-the-telegraf-database","text":"Run the following command to create a new default retention policy on the telegraf database: Note This will ''reset'' the whole database! The data won't be gone, it's still accessible using the autogen retention policy. But the command below sets the new one as default , and that's what the panels normally use in Grafana. If you want to migrate some data after you can check out this post https://community.influxdata.com/t/applying-retention-policies-to-existing-measurments/802/2 CREATE RETENTION POLICY \"7_day_retention\" ON \"telegraf\" DURATION 1w REPLICATION 1 SHARD DURATION 1w DEFAULT This will create the retention policy called 7_day_retention and set it as the default policy. After I set the new default retention policy my Influxdb appdata folder went from 40GB to 225MB :) Read more here: https://docs.influxdata.com/influxdb/v1.7/query_language/database_management/#retention-policy-management","title":"Adding a new default retention policy on the Telegraf database"},{"location":"blog/how-to-route-different-metrics-in-telegraf-to-different-influx-databases/#sending-the-metrics-to-a-different-database","text":"Now in Telegraf we simply need to add an extra output that tells Telegraf to also route the metrics we want to another database. Note This won't stop telegraf from writing the metrics to the OG telegraf database, it will write to both Add the following to the telegraf.conf file. Note add, not replace. [[outputs.influxdb]] urls = [\"http://192.168.1.34:8086\"] # required database = \"longterm_metrics\" # required retention_policy = \"\" write_consistency = \"any\" timeout = \"5s\" namepass = [\"apcupsd\",\"disk\",\"diskio\"] As I didn't add a retention policy for my long term database I have set it to use an empty string as that will use the default retention policy (autogen) of that database. If you first created the database, and then added a retention policy to that database that you want to use, you must set retention_policy = \"<retention_policy>\" to the retention policy you want. If not it will use the autogen retention policy as that is set to default when just running create <database> The namepass = [\"apcupsd\",\"disk\",\"diskio\"] is what tells Telegraf which metrics to send to that specific database. After you've added the lines restart Telegraf.","title":"Sending the metrics to a different database"},{"location":"blog/how-to-route-different-metrics-in-telegraf-to-different-influx-databases/#adding-a-new-datasource-in-grafana","text":"Since my Telegraf datasource uses the telegraf database, we need to add a new data source that uses our new database. Click on Add data source and select InfluxDB. Next give the data source a name, add the URL to InfluxDB, set the database to use the new database you created and click Save & Test","title":"Adding a new datasource in Grafana"},{"location":"blog/how-to-route-different-metrics-in-telegraf-to-different-influx-databases/#updating-the-grafana-panels","text":"Next it's just a matter of updating the Grafana panels to use the new data source. If you use my Unraid System Dashboard https://grafana.com/grafana/dashboards/7233 you can just download the latest version and select the disk data source in the drop down. Sources: https://docs.influxdata.com/influxdb/v1.7/query_language/database_management https://docs.influxdata.com/telegraf/v1.13/administration/configuration/","title":"Updating the Grafana panels"},{"location":"blog/how-to-route-different-metrics-in-telegraf-to-different-influx-databases/#if-you-need-any-extra-help-join-the-discord-server","text":"","title":"If you need any extra help join the Discord server!"},{"location":"blog/how-to-route-different-metrics-in-telegraf-to-different-influx-databases/#_1","text":"","title":""},{"location":"blog/how-to-setup-a-cloudflare-worker-to-show-a-maintenance-page-when-ca-backup-plugin-is-running/","text":"How to setup a Cloudflare worker to show a maintenance page when the CA Backup plugin is running on Unraid \u00b6 Since I use the CA Backup/Restore plugin every night my blog site will some times show the Cloudflare 523 error: origin is unreachable for around 1 hour before the plugin finishes and starts all my docker containers up again. So since that has been a minor annoyance for some time, I decided to look into how I could set up a maintenance page automatically when the backup starts. Note: This wouldn't have been an issue if the \"Always Online\" fuctionality worked on my site So after some googling I found this great resource on how to route people to their maintenance page while they are doing maintenance. The javascript returns the maintenance page if you are not calling from a trusted IP. Now Since that is something I don't need I have removed that function so you will be routed to the page regardless with the code below. This is all made possible by using the Cloudflare API and Cloudflare workers. We will need to create a worker and setup a route for it. Creating a worker \u00b6 On your Cloudflare dashboard click on Workers and go through the first time setup if you haven't done that yet. Next click on Manage Workers and Create a Worker Give your worker a name and paste the code below. Edit the html part to say what you want. Click Save and Deploy. After a minute or so you should be able to visit the page the worker is deployed on. After you've created the worker, go back to the main page and click on Add route Set the route to a subdomain that doesnt point to your site. I'm using maintenance.technicalramblings.com Remember to add the DNS record before you create the route. The subdomain you choose shouldn't be something you use as that will disrupt that domain. So I just added something that made sense to me. The subdomains only purpose is to be a placeholder for the maintenance page when the nightly backups aren't running. The way I have this setup is that I am using the API to update the \"route pattern\" that the worker is using. So when the backup starts it will run a script that updates the route pattern to technicalramblings.com/* and sets the route to use the maintenance worker. This will display the page in the screenshot below when someone is trying to access my blog. eckosc\\_full\\_width\\_block eckosc\\_full\\_width\\_block /eckosc\\_full\\_width\\_block /eckosc\\_full\\_width\\_block When the backup is finished a script will run and it will change the \"route pattern\" back to maintenance.technicalramblings.com/* I have also added another worker that I called up So when everything is back up the maintenance subdomain will display this: The up script is identical with only the html part changed. Its not really needed, but I wanted the maintenance page to display something different when the backup was not running in case someone stumbled over the subdomain. addEventListener('fetch', event => { event.respondWith(handleRequest(event.request)) }) /** * Respond to the request * @param {Request} request */ async function handleRequest(request) { let modifiedHeaders = new Headers() modifiedHeaders.set('Content-Type', 'text/html') modifiedHeaders.append('Pragma', 'no-cache') return new Response(maintenancepage, {headers: modifiedHeaders}) } let maintenancepage = ` <!doctype html> <title>Site Maintenance</title> <style> body { text-align: center; padding: 150px; background: url('https://raw.githubusercontent.com/gilbN/Nostromo/master/blog/Senja-death-star.jpg') no-repeat center center fixed; background-size: cover; -webkit-background-size: cover; -moz-background-size: cover; -o-background-size: cover; } .content { background-color: rgba(255, 255, 255, 0.75); background-size: 100%; color: inherit; padding: 1px 100px 10px 100px; border-radius: 15px; } h1 { font-size: 40pt;} body { font: 20px Helvetica, sans-serif; color: #333; } article { display: block; text-align: left; width: 75%; margin: 0 auto; } a:hover { color: #333; text-decoration: none; } </style> <article> <div class=\"background\"> <div class=\"content\"> <h1>We&rsquo;ll be right back!</h1> <p>We're very sorry for the inconvenience but we&rsquo;re performing maintenance.</p> <p>Maintenance is performed between <strong>3AM</strong> to <strong>4AM</strong> <strong>UTC</strong>.</p> <p>Please check back soon...</p> <p>You can use <span style=\"color: #000000;\"><strong><a style=\"color: #000000;\" href=\"https://cachedview.com/\">https://cachedview.com/</a></strong></span> in the mean time.</p> <p>&mdash; <B>GilbN</B></p> </div> </div> </article> `; CA Backup Scripts \u00b6 So, for this to all work automatically we need to add a couple of start/stop scripts to the CA Backup plugin. But before we can do that we need to get the ID of the route we just created. We can only get the ID by using the Cloudflare API. So run the curl command below to get the route ID you created. Remember to change the zone, API key and email. curl -X GET \"https://api.cloudflare.com/client/v4/zones/YOUR-ZONE-ID/workers/routes/\" \\ -H \"X-Auth-Email: YOUR@CLOUDFLARE-EMAIL.com\" \\ -H \"X-Auth-Key: YOUR-API-KEY\" The Zone ID is found on the overview page of the domain you want to use, and the API Key is found on the api tokens page https://dash.cloudflare.com/profile/api-tokens Use the global token. The command should output something like this: { \"result\": [ { \"id\": \"8998sfd23sd48ds0g5jk3s5sdhd098\", \"pattern\": \"maintenance.technicalramblings.com/*\", \"script\": \"maintenance\" } ], \"success\": true, \"errors\": [], \"messages\": [] } The id is the route id we need to use in the start/stop scripts, so save that. Stop script: \u00b6 (Runs when CA Backup starts . It's called stop script because it runs when stopping the containers) #!/bin/bash email='EXAMPLE@DOMAIN.COM' apikey='XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX' zone_id='XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX' route_id='XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX' route_pattern='technicalramblings.com/*' worker='maintenance' curl -X PUT \"https://api.cloudflare.com/client/v4/zones/\"$zone_id\"/workers/routes/\"$route_id\"\" \\ -H \"X-Auth-Email: \"$email\"\" \\ -H \"X-Auth-Key: \"$apikey\"\" \\ -H \"Content-Type: application/json\" \\ --data '{\"pattern\":\"'\"$route_pattern\"'\",\"script\":\"'\"$worker\"'\"}' Update the scripts to use your api key, route id and zone id ect. You can try the script by setting the domain variable to a test domain (Must be the same domain as the zone ID ). Note: the pattern I use has a wildcard at the end so it will match any url from my blog. You can read more about the matching behavior here https://workers.cloudflare.com/docs/reference/workers-concepts/routes/ Start script \u00b6 (Runs when CA Backup is finished and the containers have been started): #!/bin/bash email='EXAMPLE@DOMAIN.COM' apikey='XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX' zone_id='XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX' route_id='XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX' route_pattern='maintenance.technicalramblings.com/*' worker='up' curl -X PUT \"https://api.cloudflare.com/client/v4/zones/\"$zone_id\"/workers/routes/\"$route_id\"\" \\ -H \"X-Auth-Email: \"$email\"\" \\ -H \"X-Auth-Key: \"$apikey\"\" \\ -H \"Content-Type: application/json\" \\ --data '{\"pattern\":\"'\"$route_pattern\"'\",\"script\":\"'\"$worker\"'\"}' Next create the scripts at your desired location. nano start.sh paste the contents, save and run chmod +x start.sh Test the script with ./start.sh Do the same for the stop script Add the paths in the CA Backup plugin settings. If you need any extra help join the Discord server! \u00b6 \u00b6 Sources: https://www.resdevops.com/2018/03/20/cloudflare-workers-maintenance-mode-static-page/ https://api.cloudflare.com/#worker-routes-update-route","title":"How to setup a Cloudflare worker to show a maintenance page when the CA Backup plugin is running on Unraid"},{"location":"blog/how-to-setup-a-cloudflare-worker-to-show-a-maintenance-page-when-ca-backup-plugin-is-running/#how-to-setup-a-cloudflare-worker-to-show-a-maintenance-page-when-the-ca-backup-plugin-is-running-on-unraid","text":"Since I use the CA Backup/Restore plugin every night my blog site will some times show the Cloudflare 523 error: origin is unreachable for around 1 hour before the plugin finishes and starts all my docker containers up again. So since that has been a minor annoyance for some time, I decided to look into how I could set up a maintenance page automatically when the backup starts. Note: This wouldn't have been an issue if the \"Always Online\" fuctionality worked on my site So after some googling I found this great resource on how to route people to their maintenance page while they are doing maintenance. The javascript returns the maintenance page if you are not calling from a trusted IP. Now Since that is something I don't need I have removed that function so you will be routed to the page regardless with the code below. This is all made possible by using the Cloudflare API and Cloudflare workers. We will need to create a worker and setup a route for it.","title":"How to setup a Cloudflare worker to show a maintenance page when the CA Backup plugin is running on Unraid"},{"location":"blog/how-to-setup-a-cloudflare-worker-to-show-a-maintenance-page-when-ca-backup-plugin-is-running/#creating-a-worker","text":"On your Cloudflare dashboard click on Workers and go through the first time setup if you haven't done that yet. Next click on Manage Workers and Create a Worker Give your worker a name and paste the code below. Edit the html part to say what you want. Click Save and Deploy. After a minute or so you should be able to visit the page the worker is deployed on. After you've created the worker, go back to the main page and click on Add route Set the route to a subdomain that doesnt point to your site. I'm using maintenance.technicalramblings.com Remember to add the DNS record before you create the route. The subdomain you choose shouldn't be something you use as that will disrupt that domain. So I just added something that made sense to me. The subdomains only purpose is to be a placeholder for the maintenance page when the nightly backups aren't running. The way I have this setup is that I am using the API to update the \"route pattern\" that the worker is using. So when the backup starts it will run a script that updates the route pattern to technicalramblings.com/* and sets the route to use the maintenance worker. This will display the page in the screenshot below when someone is trying to access my blog. eckosc\\_full\\_width\\_block eckosc\\_full\\_width\\_block /eckosc\\_full\\_width\\_block /eckosc\\_full\\_width\\_block When the backup is finished a script will run and it will change the \"route pattern\" back to maintenance.technicalramblings.com/* I have also added another worker that I called up So when everything is back up the maintenance subdomain will display this: The up script is identical with only the html part changed. Its not really needed, but I wanted the maintenance page to display something different when the backup was not running in case someone stumbled over the subdomain. addEventListener('fetch', event => { event.respondWith(handleRequest(event.request)) }) /** * Respond to the request * @param {Request} request */ async function handleRequest(request) { let modifiedHeaders = new Headers() modifiedHeaders.set('Content-Type', 'text/html') modifiedHeaders.append('Pragma', 'no-cache') return new Response(maintenancepage, {headers: modifiedHeaders}) } let maintenancepage = ` <!doctype html> <title>Site Maintenance</title> <style> body { text-align: center; padding: 150px; background: url('https://raw.githubusercontent.com/gilbN/Nostromo/master/blog/Senja-death-star.jpg') no-repeat center center fixed; background-size: cover; -webkit-background-size: cover; -moz-background-size: cover; -o-background-size: cover; } .content { background-color: rgba(255, 255, 255, 0.75); background-size: 100%; color: inherit; padding: 1px 100px 10px 100px; border-radius: 15px; } h1 { font-size: 40pt;} body { font: 20px Helvetica, sans-serif; color: #333; } article { display: block; text-align: left; width: 75%; margin: 0 auto; } a:hover { color: #333; text-decoration: none; } </style> <article> <div class=\"background\"> <div class=\"content\"> <h1>We&rsquo;ll be right back!</h1> <p>We're very sorry for the inconvenience but we&rsquo;re performing maintenance.</p> <p>Maintenance is performed between <strong>3AM</strong> to <strong>4AM</strong> <strong>UTC</strong>.</p> <p>Please check back soon...</p> <p>You can use <span style=\"color: #000000;\"><strong><a style=\"color: #000000;\" href=\"https://cachedview.com/\">https://cachedview.com/</a></strong></span> in the mean time.</p> <p>&mdash; <B>GilbN</B></p> </div> </div> </article> `;","title":"Creating a worker"},{"location":"blog/how-to-setup-a-cloudflare-worker-to-show-a-maintenance-page-when-ca-backup-plugin-is-running/#ca-backup-scripts","text":"So, for this to all work automatically we need to add a couple of start/stop scripts to the CA Backup plugin. But before we can do that we need to get the ID of the route we just created. We can only get the ID by using the Cloudflare API. So run the curl command below to get the route ID you created. Remember to change the zone, API key and email. curl -X GET \"https://api.cloudflare.com/client/v4/zones/YOUR-ZONE-ID/workers/routes/\" \\ -H \"X-Auth-Email: YOUR@CLOUDFLARE-EMAIL.com\" \\ -H \"X-Auth-Key: YOUR-API-KEY\" The Zone ID is found on the overview page of the domain you want to use, and the API Key is found on the api tokens page https://dash.cloudflare.com/profile/api-tokens Use the global token. The command should output something like this: { \"result\": [ { \"id\": \"8998sfd23sd48ds0g5jk3s5sdhd098\", \"pattern\": \"maintenance.technicalramblings.com/*\", \"script\": \"maintenance\" } ], \"success\": true, \"errors\": [], \"messages\": [] } The id is the route id we need to use in the start/stop scripts, so save that.","title":"CA Backup Scripts"},{"location":"blog/how-to-setup-a-cloudflare-worker-to-show-a-maintenance-page-when-ca-backup-plugin-is-running/#stop-script","text":"(Runs when CA Backup starts . It's called stop script because it runs when stopping the containers) #!/bin/bash email='EXAMPLE@DOMAIN.COM' apikey='XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX' zone_id='XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX' route_id='XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX' route_pattern='technicalramblings.com/*' worker='maintenance' curl -X PUT \"https://api.cloudflare.com/client/v4/zones/\"$zone_id\"/workers/routes/\"$route_id\"\" \\ -H \"X-Auth-Email: \"$email\"\" \\ -H \"X-Auth-Key: \"$apikey\"\" \\ -H \"Content-Type: application/json\" \\ --data '{\"pattern\":\"'\"$route_pattern\"'\",\"script\":\"'\"$worker\"'\"}' Update the scripts to use your api key, route id and zone id ect. You can try the script by setting the domain variable to a test domain (Must be the same domain as the zone ID ). Note: the pattern I use has a wildcard at the end so it will match any url from my blog. You can read more about the matching behavior here https://workers.cloudflare.com/docs/reference/workers-concepts/routes/","title":"Stop script:"},{"location":"blog/how-to-setup-a-cloudflare-worker-to-show-a-maintenance-page-when-ca-backup-plugin-is-running/#start-script","text":"(Runs when CA Backup is finished and the containers have been started): #!/bin/bash email='EXAMPLE@DOMAIN.COM' apikey='XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX' zone_id='XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX' route_id='XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX' route_pattern='maintenance.technicalramblings.com/*' worker='up' curl -X PUT \"https://api.cloudflare.com/client/v4/zones/\"$zone_id\"/workers/routes/\"$route_id\"\" \\ -H \"X-Auth-Email: \"$email\"\" \\ -H \"X-Auth-Key: \"$apikey\"\" \\ -H \"Content-Type: application/json\" \\ --data '{\"pattern\":\"'\"$route_pattern\"'\",\"script\":\"'\"$worker\"'\"}' Next create the scripts at your desired location. nano start.sh paste the contents, save and run chmod +x start.sh Test the script with ./start.sh Do the same for the stop script Add the paths in the CA Backup plugin settings.","title":"Start script"},{"location":"blog/how-to-setup-a-cloudflare-worker-to-show-a-maintenance-page-when-ca-backup-plugin-is-running/#if-you-need-any-extra-help-join-the-discord-server","text":"","title":"If you need any extra help join the Discord server!"},{"location":"blog/how-to-setup-a-cloudflare-worker-to-show-a-maintenance-page-when-ca-backup-plugin-is-running/#_1","text":"Sources: https://www.resdevops.com/2018/03/20/cloudflare-workers-maintenance-mode-static-page/ https://api.cloudflare.com/#worker-routes-update-route","title":""},{"location":"blog/how-to-setup-a-ghost-site-with-letsencrypt-and-mariadb-on-unraid/","text":"How to setup a Ghost blog with swag/letsencrypt and MariaDB on Unraid \u00b6 Now, I don't really have any issues with Wordpress, I like it. But It's always fun to try something new to see if you're missing out. The setup process is fairly similar to Wordpress except I will be using the Ghost docker container this time. There is also some custom setup you might have to do with the Ghost template to make it work. What is Ghost \u00b6 Info Ghost is a free and open source blogging platform written in JavaScript and distributed under the MIT License, designed to simplify the process of online publishing for individual bloggers as well as online publications. MariaDB Installation \u00b6 Installing MariaDB is very straight forward. Go to the \"Apps\" tab and search for mariadb and click install. If you already have mariadb installed and are using it with another application you can scroll down to the Create the ghost database manually part. Choose your host port and your MYSQL Root password. Add the database name variable. MYSQL_DATABASE Add the database user variable. MYSQL_USER Add the user password variable. MYSQL_PASSWORD Optional: Create the ghost database manually \u00b6 Open terminal and exec into the container with ** docker exec -it mariadb bash **or use the console shortcut on the Dashboard page. Log into mysql with user root and the password you chose. ** mysql -uroot -p **enter your password. The output will look like this: root@Nostromo:~# docker exec -it mariadb bash root@ac436a71f4be:/# mysql -uroot -p Enter password: Welcome to the MariaDB monitor. Commands end with ; or g. Your MariaDB connection id is 3 Server version: 10 .1.30-MariaDB-1~xenial mariadb.org binary distribution Copyright ( c ) 2000 , 2017 , Oracle, MariaDB Corporation Ab and others. Type 'help;' or 'h' for help. Type 'c' to clear the current input statement. MariaDB [( none )] Next up is creating the database. (Remember to end all queries with a semicolon) Start with creating a user for the database. CREATE USER 'user' IDENTIFIED by 'password'; Where 'user' is your username and 'password' is the password you want for the new user. The ouput will be like this. MariaDB [( none )] > CREATE USER 'ghost' IDENTIFIED by 'ghost' ; Query OK, 0 rows affected ( 0 .01 sec ) Create the database with CREATE DATABASE IF NOT EXISTS ghost; MariaDB [( none )] > CREATE DATABASE IF NOT EXISTS ghost ; Query OK, 1 row affected ( 0 .00 sec ) Give the user permissions to the database with GRANT ALL PRIVILEGES ON ghost.* TO 'ghost' IDENTIFIED BY 'ghost'; MariaDB [( none )] > GRANT ALL PRIVILEGES ON ghost.* TO 'ghost' IDENTIFIED BY 'ghost' ; Query OK, 0 rows affected ( 0 .00 sec ) Then quit mysql with quit and exit from the container by issuing the command exit swag/Letsencrypt \u00b6 If you already have swag setup you can just skip down to the nginx part. For first time installation I strongly recommend reading this excellent guide by aptalca https://blog.linuxserver.io/2019/04/25/letsencrypt-nginx-starter-guide/ It covers all the basics on setting up this container. There's no point for me invent the wheel again. For troubleshooting the container have a look at this https://blog.linuxserver.io/2019/07/10/troubleshooting-letsencrypt-image-port-mapping-and-forwarding/ . Warning TTL differs from each provider, some has a minimum 60 minutes before DNS propagates and others have 1 minute. So it might take a while before https://yourdomain.com works. If you already have swag setup and working with a domain and want to use another domain for your ghost site you can do that by using the EXTRA_DOMAINS variable. Click on Add another Path, Port or Variable Add these values. Config Type: Variable Name: Extra domain Key: EXTRA_DOMAINS Value: yourotherdomain.com, ghost.yourotherdomain.com Nginx \u00b6 Go to the swag appdata location. Find the nginx folder and either create a new ghost.conf file in the \"site-conf\" folder(domains and subdomains only) or use the proxy-confs folder and create a file with the correct naming scheme( ghost.subdomain.conf or ghost.subfolder.conf ). I recommend using notepad++ if you are editing the files on a windows machine. I've made a PR on the linuxserver/reverse-proxy-confs repo, so the files might already be there depending on when you read this. https://github.com/linuxserver/reverse-proxy-confs/pull/118 If you want to Geo block your site read more here Select the config you want below: Info If you are using docker dns in you reverse proxy remember to change the Ghost container name to ghost lower case! Docker DNS does not like Uppercase letters. Subdomain server { listen 443 ssl ; listen [::]:443 ssl ; server_name ghost.* ; include /config/nginx/ssl.conf ; client_max_body_size 0 ; # enable for ldap auth, fill in ldap details in ldap.conf #include /config/nginx/ldap.conf; location / { #enable the next two lines for http auth #auth_basic \"Restricted\"; #auth_basic_user_file /config/nginx/.htpasswd; # enable the next two lines for ldap auth #auth_request /auth; #error_page 401 =200 /login; include /config/nginx/proxy.conf ; resolver 127 .0.0.11 valid=30s ; set $upstream_ghost ghost ; proxy_pass http:// $upstream_ghost:2368 ; proxy_redirect off ; } } Subfolder location /blog { resolver 127 .0.0.11 valid=30s ; set $upstream_ghost ghost ; proxy_pass http:// $upstream_ghost:2368 ; include /config/nginx/proxy.conf ; proxy_redirect off ; } Note Make sure you are using a subdirectory in your ghost config file. https://ghost.org/docs/concepts/config/#url And the subdirectory /ghost/ is by default used for the admin page. See https://ghost.org/docs/concepts/config/#admin-url Ghost \u00b6 Ghost was fairly simple to install, but I had to do some modifications to the Unraid container template. Database Port : The template does not specify a database port for your SQL server. So I had to add the database__connection__port variable as I don't use the default 3306 port. Mail Host: The template does not have the mail__options__host variable needed for Mailgun EU or custom mail setup i.e. Gmail. For example: smtp.eu.mailgun.org or smtp.gmail.com Mail Port: The template does not have the mail__options__port variable. This is needed if you are using Gmail for example. Set it to 465 So for a Gmail setup you need only to set the Mail service to Gmail and add the necessary variables. Note: The Username and Password for Mailgun is just the mail username and password variables. Doesn't really have anything to do with Mailgun. For a Mailgun setup see the Ghost docs: https://ghost.org/docs/concepts/config/#configure-mail-with-mailgun The rest is just filling out the different variables. Remember to a subdirectory in the URL field if you hare using that. For example: https://technicalramblings.com/blog or https://ghost.technicalramblings.com/blog Make the site private \u00b6 A nice feature Ghost has is a setting which can make the site private with password protection. Just go into the general settings and enable it under advanced settings. If you need any extra help join the Discord server! \u00b6 \u00b6","title":"How to setup a Ghost blog on Unraid"},{"location":"blog/how-to-setup-a-ghost-site-with-letsencrypt-and-mariadb-on-unraid/#how-to-setup-a-ghost-blog-with-swagletsencrypt-and-mariadb-on-unraid","text":"Now, I don't really have any issues with Wordpress, I like it. But It's always fun to try something new to see if you're missing out. The setup process is fairly similar to Wordpress except I will be using the Ghost docker container this time. There is also some custom setup you might have to do with the Ghost template to make it work.","title":"How to setup a Ghost blog with swag/letsencrypt and MariaDB on Unraid"},{"location":"blog/how-to-setup-a-ghost-site-with-letsencrypt-and-mariadb-on-unraid/#what-is-ghost","text":"Info Ghost is a free and open source blogging platform written in JavaScript and distributed under the MIT License, designed to simplify the process of online publishing for individual bloggers as well as online publications.","title":"What is Ghost"},{"location":"blog/how-to-setup-a-ghost-site-with-letsencrypt-and-mariadb-on-unraid/#mariadb-installation","text":"Installing MariaDB is very straight forward. Go to the \"Apps\" tab and search for mariadb and click install. If you already have mariadb installed and are using it with another application you can scroll down to the Create the ghost database manually part. Choose your host port and your MYSQL Root password. Add the database name variable. MYSQL_DATABASE Add the database user variable. MYSQL_USER Add the user password variable. MYSQL_PASSWORD","title":"MariaDB Installation"},{"location":"blog/how-to-setup-a-ghost-site-with-letsencrypt-and-mariadb-on-unraid/#optional-create-the-ghost-database-manually","text":"Open terminal and exec into the container with ** docker exec -it mariadb bash **or use the console shortcut on the Dashboard page. Log into mysql with user root and the password you chose. ** mysql -uroot -p **enter your password. The output will look like this: root@Nostromo:~# docker exec -it mariadb bash root@ac436a71f4be:/# mysql -uroot -p Enter password: Welcome to the MariaDB monitor. Commands end with ; or g. Your MariaDB connection id is 3 Server version: 10 .1.30-MariaDB-1~xenial mariadb.org binary distribution Copyright ( c ) 2000 , 2017 , Oracle, MariaDB Corporation Ab and others. Type 'help;' or 'h' for help. Type 'c' to clear the current input statement. MariaDB [( none )] Next up is creating the database. (Remember to end all queries with a semicolon) Start with creating a user for the database. CREATE USER 'user' IDENTIFIED by 'password'; Where 'user' is your username and 'password' is the password you want for the new user. The ouput will be like this. MariaDB [( none )] > CREATE USER 'ghost' IDENTIFIED by 'ghost' ; Query OK, 0 rows affected ( 0 .01 sec ) Create the database with CREATE DATABASE IF NOT EXISTS ghost; MariaDB [( none )] > CREATE DATABASE IF NOT EXISTS ghost ; Query OK, 1 row affected ( 0 .00 sec ) Give the user permissions to the database with GRANT ALL PRIVILEGES ON ghost.* TO 'ghost' IDENTIFIED BY 'ghost'; MariaDB [( none )] > GRANT ALL PRIVILEGES ON ghost.* TO 'ghost' IDENTIFIED BY 'ghost' ; Query OK, 0 rows affected ( 0 .00 sec ) Then quit mysql with quit and exit from the container by issuing the command exit","title":"Optional: Create the ghost database manually"},{"location":"blog/how-to-setup-a-ghost-site-with-letsencrypt-and-mariadb-on-unraid/#swagletsencrypt","text":"If you already have swag setup you can just skip down to the nginx part. For first time installation I strongly recommend reading this excellent guide by aptalca https://blog.linuxserver.io/2019/04/25/letsencrypt-nginx-starter-guide/ It covers all the basics on setting up this container. There's no point for me invent the wheel again. For troubleshooting the container have a look at this https://blog.linuxserver.io/2019/07/10/troubleshooting-letsencrypt-image-port-mapping-and-forwarding/ . Warning TTL differs from each provider, some has a minimum 60 minutes before DNS propagates and others have 1 minute. So it might take a while before https://yourdomain.com works. If you already have swag setup and working with a domain and want to use another domain for your ghost site you can do that by using the EXTRA_DOMAINS variable. Click on Add another Path, Port or Variable Add these values. Config Type: Variable Name: Extra domain Key: EXTRA_DOMAINS Value: yourotherdomain.com, ghost.yourotherdomain.com","title":"swag/Letsencrypt"},{"location":"blog/how-to-setup-a-ghost-site-with-letsencrypt-and-mariadb-on-unraid/#nginx","text":"Go to the swag appdata location. Find the nginx folder and either create a new ghost.conf file in the \"site-conf\" folder(domains and subdomains only) or use the proxy-confs folder and create a file with the correct naming scheme( ghost.subdomain.conf or ghost.subfolder.conf ). I recommend using notepad++ if you are editing the files on a windows machine. I've made a PR on the linuxserver/reverse-proxy-confs repo, so the files might already be there depending on when you read this. https://github.com/linuxserver/reverse-proxy-confs/pull/118 If you want to Geo block your site read more here Select the config you want below: Info If you are using docker dns in you reverse proxy remember to change the Ghost container name to ghost lower case! Docker DNS does not like Uppercase letters. Subdomain server { listen 443 ssl ; listen [::]:443 ssl ; server_name ghost.* ; include /config/nginx/ssl.conf ; client_max_body_size 0 ; # enable for ldap auth, fill in ldap details in ldap.conf #include /config/nginx/ldap.conf; location / { #enable the next two lines for http auth #auth_basic \"Restricted\"; #auth_basic_user_file /config/nginx/.htpasswd; # enable the next two lines for ldap auth #auth_request /auth; #error_page 401 =200 /login; include /config/nginx/proxy.conf ; resolver 127 .0.0.11 valid=30s ; set $upstream_ghost ghost ; proxy_pass http:// $upstream_ghost:2368 ; proxy_redirect off ; } } Subfolder location /blog { resolver 127 .0.0.11 valid=30s ; set $upstream_ghost ghost ; proxy_pass http:// $upstream_ghost:2368 ; include /config/nginx/proxy.conf ; proxy_redirect off ; } Note Make sure you are using a subdirectory in your ghost config file. https://ghost.org/docs/concepts/config/#url And the subdirectory /ghost/ is by default used for the admin page. See https://ghost.org/docs/concepts/config/#admin-url","title":"Nginx"},{"location":"blog/how-to-setup-a-ghost-site-with-letsencrypt-and-mariadb-on-unraid/#ghost","text":"Ghost was fairly simple to install, but I had to do some modifications to the Unraid container template. Database Port : The template does not specify a database port for your SQL server. So I had to add the database__connection__port variable as I don't use the default 3306 port. Mail Host: The template does not have the mail__options__host variable needed for Mailgun EU or custom mail setup i.e. Gmail. For example: smtp.eu.mailgun.org or smtp.gmail.com Mail Port: The template does not have the mail__options__port variable. This is needed if you are using Gmail for example. Set it to 465 So for a Gmail setup you need only to set the Mail service to Gmail and add the necessary variables. Note: The Username and Password for Mailgun is just the mail username and password variables. Doesn't really have anything to do with Mailgun. For a Mailgun setup see the Ghost docs: https://ghost.org/docs/concepts/config/#configure-mail-with-mailgun The rest is just filling out the different variables. Remember to a subdirectory in the URL field if you hare using that. For example: https://technicalramblings.com/blog or https://ghost.technicalramblings.com/blog","title":"Ghost"},{"location":"blog/how-to-setup-a-ghost-site-with-letsencrypt-and-mariadb-on-unraid/#make-the-site-private","text":"A nice feature Ghost has is a setting which can make the site private with password protection. Just go into the general settings and enable it under advanced settings.","title":"Make the site private"},{"location":"blog/how-to-setup-a-ghost-site-with-letsencrypt-and-mariadb-on-unraid/#if-you-need-any-extra-help-join-the-discord-server","text":"","title":"If you need any extra help join the Discord server!"},{"location":"blog/how-to-setup-a-ghost-site-with-letsencrypt-and-mariadb-on-unraid/#_1","text":"","title":""},{"location":"blog/how-to-setup-grafana-influxdb-and-telegraf-to-monitor-your-unraid-system/","text":"How to setup Grafana, InfluxDB and Telegraf to monitor your unRAID system. \u00b6 I have for some time shared my Unraid System dashboard over at Grafana.com but never really had the time to make a quick write up on how to set it all up. So this will try to do just that. This guide will make it so you will be able to monitor cpu usage, cpu temps, network stats, ram usage and much more by simply importing a dashboard. How it works \u00b6 In getting all this setup, there are 3 main moving parts. Telegraf , InfluxDB and Grafana . Telegraf is what collects all the different system metrics and outputs it to an InfluxDB database that Grafana uses to visualize everything with pretty graphs and bars. This is a pretty simplified explanation and you can read more here: Telegraf , InfluxDB , Grafana Installing Influxdb \u00b6 Search for influxdb in Community Apps and install it using the default template. Select your appdata path and host ports if the default ones are taken. There is no other setup than just installing the container. eckosc\\_status\\_message title=\"Don't use the latest tag\" icon=\"fa-exclamation-triangle\" type=\"warn\" message=\"The `:latest` tag will run InfluxDB V2! This guide was written for v1.8. Change the tag to `:1.8.4` for it to work!\" eckosc\\_status\\_message title=\"Don't use the latest tag\" icon=\"fa-exclamation-triangle\" type=\"warn\" message=\"The `:latest` tag will run InfluxDB V2! This guide was written for v1.8. Change the tag to `:1.8.4` for it to work!\" Installing Telegraf \u00b6 Do the same here, just search for the container in Community Apps and use the default template settings. Set the appdata location to where you want it, but don't click install just yet! eckosc\\_status\\_message title=\"Network\" icon=\"fa-exclamation-triangle\" type=\"info\" message=\"Make sure the container uses **Host** networking!\" eckosc\\_status\\_message title=\"Network\" icon=\"fa-exclamation-triangle\" type=\"info\" message=\"Make sure the container uses **Host** networking!\" eckosc\\_status\\_message title=\"Warning\" icon=\"fa-exclamation-triangle\" type=\"error\" message=\"This container wont start unless the `telegraf.conf` file already exists on the host. (Host path 7) Do not install the container before you follow the steps below!\" eckosc\\_status\\_message title=\"Warning\" icon=\"fa-exclamation-triangle\" type=\"error\" message=\"This container wont start unless the `telegraf.conf` file already exists on the host. (Host path 7) Do not install the container before you follow the steps below!\" eckosc\\_status\\_message title=\"Troubleshooting\" icon=\"fa-exclamation-triangle\" type=\"warn\" message=\"If you happened to start the container without doing the steps below first you will need to delete the folder it created instead of mounting the file. Go to the location you selected for the appdata and delete the `telegraf.conf` folder. Next follow the steps below.\" eckosc\\_status\\_message title=\"Troubleshooting\" icon=\"fa-exclamation-triangle\" type=\"warn\" message=\"If you happened to start the container without doing the steps below first you will need to delete the folder it created instead of mounting the file. Go to the location you selected for the appdata and delete the `telegraf.conf` folder. Next follow the steps below.\" Download the file and place it in the location you want the telegraf appdata to be. e.g. /mnt/cache/appdata/telegraf/telegraf.conf The default config file can be downloaded here: https://raw.githubusercontent.com/influxdata/telegraf/master/etc/telegraf.conf Next you need to edit the telegraf.conf file. Go to the location you saved the file and scroll down to OUTPUT PLUGINS which should be around line 90-120.Uncomment (Remove #) the http url line for InfluxDB and the \"database\" line, like so: # urls = [\"unix:///var/run/influxdb.sock\"] # urls = [\"udp://127.0.0.1:8089\"] urls = [\"http://192.168.1.34:8086\"] 192.168.1.34 is the IP address to my Unraid server and 8086 is the default InfluxDB port that runs the InfluxDB HTTP service. 3. Next we need to setup the input plugins. A lot of these are already enabled but we need to add a couple so that all the panels on the Grafana dashboard will work. 4. Uncomment the following plugins and lines: 1. HDD temps/stats: [[inputs.smart]] 2. CPU temps: [[inputs.sensors]] and attributes = true (This is default set to false) 3. Network: [[inputs.net]] and interfaces = [\"eth0\"] ect 4. Netstat: [[inputs.netstat]] 5. Docker: [[inputs.docker]] and endpoint = \"unix:///var/run/docker.sock\" 6. UPS: [[inputs.apcupsd]] 5. Now go back to the install page of telegraf and add the following into the Post Arguments input field: /bin/sh -c 'apt update && apt install -y smartmontools && apt install -y lm-sensors && telegraf' --user 0 To be able to see this field we need to click on the Advanced View button. This will install smartmontools and without it you won't be able to get the S.M.A.R.T statistics. Note: If you also want to add IPMI and nvme stats you can add the following: /bin/sh -c 'apt update && apt install -y smartmontools && apt install -y lm-sensors && apt install -y nvme-cli && apt install -y ipmitool && telegraf' --user 0 [eckosc_status_message title=\"Alpine\" icon=\"fa-exclamation-triangle\" type=\"info\" message=\"If you use the alpine tag use these commands instead.\"] /bin/sh -c 'apk update && apk add smartmontools && apk add lm-sensors lm-sensors-detect perl && telegraf' --user 0 With IPMI and nvme: /bin/sh -c 'apk update && apk add smartmontools && apk add lm-sensors lm-sensors-detect perl && apk add nvme-cli && apk add ipmitool && telegraf' --user 0 [eckosc_full_width_block] /eckosc\\_full\\_width\\_block /eckosc\\_full\\_width\\_block After editing the telegraf.conf and adding the post arguments you can start the Telegraf container. Telegraf will automatically create a database called telegraf when started for the first time with the influxdb plugin activated. Installing Grafana \u00b6 Installing Grafana is also quite simple. Chose your host port for the webUI and add your unraid URL and admin password to the container settings. Configuring Grafana \u00b6 After the installation is finished go to the WebUI. ( http://unraidIP:3000 ) and log in with username admin and the password you chose. You should then see this on you screen: Click on Add data source and select InfluxDB. Next give the data source a name(I named it Telegraf), add the URL to InfluxDB, enter the database to use ( telegraf ) and set the HTTP Method to POST. This is helpful on some of the more heavy queries. Grafana will use the default username and password for Influxdb (root root), if you have added a user you will need to add that too. Next click Save & Test If all your settings are correct you should see this message. Next import the dashboard by hovering over the + icon and selecting Import Paste the dashboard ID 7233 **and click **Load Give it a name and UID, select the database in the drop down and click Import . Next, select the correct values on the menu at the top. \u00b6 Some assembly needed \u00b6 You should now already see most of the panels working and displaying stats. But there will be some panels where you need to select some values in the dropdowns at the top. Like Cache Devices. On the Cache Devices (diskio) dropdown you can select multiple devices, and it will add them to the Cache Read/Write panel. The Interval text box is the interval that is set in telegraf.conf The default value is 10 seconds, but if you changed this you can update it here. To update the drive names on the Storage Consumption panel, edit the panel and go to the Field menu. There you will can add the different Value Mappings for the different drive paths. See the video below. [video width=\"1904\" height=\"1006\" mp4=\" https://technicalramblings.com/wp-content/uploads/2019/07/Yiz3iZBsFb.mp4 \"][/video] And that's about it! This should get you going on adding or creating awesome dashboards for you Unraid system. There are tons of different dashboards on grafana.com to get inspiration from. My dashboard is far from the best one out there, so please share your awesome dashboards in the comment section or on Discord ! eckosc\\_status\\_message title=\"Not UUD\" icon=\"fa-exclamation-triangle\" type=\"error\" message=\"The dashboard used in this guide is not the **Ultimate Unraid Dashboard**seen from the offical unraid blog post. You can find that dashboard and the extra instructions in the link below!\" eckosc\\_status\\_message title=\"Not UUD\" icon=\"fa-exclamation-triangle\" type=\"error\" message=\"The dashboard used in this guide is not the **Ultimate Unraid Dashboard**seen from the offical unraid blog post. You can find that dashboard and the extra instructions in the link below!\" UUD: https://forums.unraid.net/topic/96895-ultimate-unraid-dashboard-uud/ And if you're wondering why my Grafana page looks different from the stock theme you can take a look here: https://github.com/gilbN/theme.park Optional: Adding UPS stats \u00b6 On the top of my dashboard I have UPS stats, now if you don't have a UPS (You should by the way) you can just delete those panel. But if you have a UPS that's compatible with Unraid you can check out this awesome guide: \ufeff \ufeff \ufeff \ufeff \ufeff \ufeff \ufeff \ufeff \ufeff \ufeff \ufeff \ufeff \ufeff \ufeff \ufeff \ufeff If you need any extra help join the Discord server! \u00b6 \u00b6","title":"How to setup Grafana, InfluxDB and Telegraf to monitor your unRAID system"},{"location":"blog/how-to-setup-grafana-influxdb-and-telegraf-to-monitor-your-unraid-system/#how-to-setup-grafana-influxdb-and-telegraf-to-monitor-your-unraid-system","text":"I have for some time shared my Unraid System dashboard over at Grafana.com but never really had the time to make a quick write up on how to set it all up. So this will try to do just that. This guide will make it so you will be able to monitor cpu usage, cpu temps, network stats, ram usage and much more by simply importing a dashboard.","title":"How to setup Grafana, InfluxDB and Telegraf to monitor your unRAID system."},{"location":"blog/how-to-setup-grafana-influxdb-and-telegraf-to-monitor-your-unraid-system/#how-it-works","text":"In getting all this setup, there are 3 main moving parts. Telegraf , InfluxDB and Grafana . Telegraf is what collects all the different system metrics and outputs it to an InfluxDB database that Grafana uses to visualize everything with pretty graphs and bars. This is a pretty simplified explanation and you can read more here: Telegraf , InfluxDB , Grafana","title":"How it works"},{"location":"blog/how-to-setup-grafana-influxdb-and-telegraf-to-monitor-your-unraid-system/#installing-influxdb","text":"Search for influxdb in Community Apps and install it using the default template. Select your appdata path and host ports if the default ones are taken. There is no other setup than just installing the container. eckosc\\_status\\_message title=\"Don't use the latest tag\" icon=\"fa-exclamation-triangle\" type=\"warn\" message=\"The `:latest` tag will run InfluxDB V2! This guide was written for v1.8. Change the tag to `:1.8.4` for it to work!\" eckosc\\_status\\_message title=\"Don't use the latest tag\" icon=\"fa-exclamation-triangle\" type=\"warn\" message=\"The `:latest` tag will run InfluxDB V2! This guide was written for v1.8. Change the tag to `:1.8.4` for it to work!\"","title":"Installing Influxdb"},{"location":"blog/how-to-setup-grafana-influxdb-and-telegraf-to-monitor-your-unraid-system/#installing-telegraf","text":"Do the same here, just search for the container in Community Apps and use the default template settings. Set the appdata location to where you want it, but don't click install just yet! eckosc\\_status\\_message title=\"Network\" icon=\"fa-exclamation-triangle\" type=\"info\" message=\"Make sure the container uses **Host** networking!\" eckosc\\_status\\_message title=\"Network\" icon=\"fa-exclamation-triangle\" type=\"info\" message=\"Make sure the container uses **Host** networking!\" eckosc\\_status\\_message title=\"Warning\" icon=\"fa-exclamation-triangle\" type=\"error\" message=\"This container wont start unless the `telegraf.conf` file already exists on the host. (Host path 7) Do not install the container before you follow the steps below!\" eckosc\\_status\\_message title=\"Warning\" icon=\"fa-exclamation-triangle\" type=\"error\" message=\"This container wont start unless the `telegraf.conf` file already exists on the host. (Host path 7) Do not install the container before you follow the steps below!\" eckosc\\_status\\_message title=\"Troubleshooting\" icon=\"fa-exclamation-triangle\" type=\"warn\" message=\"If you happened to start the container without doing the steps below first you will need to delete the folder it created instead of mounting the file. Go to the location you selected for the appdata and delete the `telegraf.conf` folder. Next follow the steps below.\" eckosc\\_status\\_message title=\"Troubleshooting\" icon=\"fa-exclamation-triangle\" type=\"warn\" message=\"If you happened to start the container without doing the steps below first you will need to delete the folder it created instead of mounting the file. Go to the location you selected for the appdata and delete the `telegraf.conf` folder. Next follow the steps below.\" Download the file and place it in the location you want the telegraf appdata to be. e.g. /mnt/cache/appdata/telegraf/telegraf.conf The default config file can be downloaded here: https://raw.githubusercontent.com/influxdata/telegraf/master/etc/telegraf.conf Next you need to edit the telegraf.conf file. Go to the location you saved the file and scroll down to OUTPUT PLUGINS which should be around line 90-120.Uncomment (Remove #) the http url line for InfluxDB and the \"database\" line, like so: # urls = [\"unix:///var/run/influxdb.sock\"] # urls = [\"udp://127.0.0.1:8089\"] urls = [\"http://192.168.1.34:8086\"] 192.168.1.34 is the IP address to my Unraid server and 8086 is the default InfluxDB port that runs the InfluxDB HTTP service. 3. Next we need to setup the input plugins. A lot of these are already enabled but we need to add a couple so that all the panels on the Grafana dashboard will work. 4. Uncomment the following plugins and lines: 1. HDD temps/stats: [[inputs.smart]] 2. CPU temps: [[inputs.sensors]] and attributes = true (This is default set to false) 3. Network: [[inputs.net]] and interfaces = [\"eth0\"] ect 4. Netstat: [[inputs.netstat]] 5. Docker: [[inputs.docker]] and endpoint = \"unix:///var/run/docker.sock\" 6. UPS: [[inputs.apcupsd]] 5. Now go back to the install page of telegraf and add the following into the Post Arguments input field: /bin/sh -c 'apt update && apt install -y smartmontools && apt install -y lm-sensors && telegraf' --user 0 To be able to see this field we need to click on the Advanced View button. This will install smartmontools and without it you won't be able to get the S.M.A.R.T statistics. Note: If you also want to add IPMI and nvme stats you can add the following: /bin/sh -c 'apt update && apt install -y smartmontools && apt install -y lm-sensors && apt install -y nvme-cli && apt install -y ipmitool && telegraf' --user 0 [eckosc_status_message title=\"Alpine\" icon=\"fa-exclamation-triangle\" type=\"info\" message=\"If you use the alpine tag use these commands instead.\"] /bin/sh -c 'apk update && apk add smartmontools && apk add lm-sensors lm-sensors-detect perl && telegraf' --user 0 With IPMI and nvme: /bin/sh -c 'apk update && apk add smartmontools && apk add lm-sensors lm-sensors-detect perl && apk add nvme-cli && apk add ipmitool && telegraf' --user 0 [eckosc_full_width_block] /eckosc\\_full\\_width\\_block /eckosc\\_full\\_width\\_block After editing the telegraf.conf and adding the post arguments you can start the Telegraf container. Telegraf will automatically create a database called telegraf when started for the first time with the influxdb plugin activated.","title":"Installing Telegraf"},{"location":"blog/how-to-setup-grafana-influxdb-and-telegraf-to-monitor-your-unraid-system/#installing-grafana","text":"Installing Grafana is also quite simple. Chose your host port for the webUI and add your unraid URL and admin password to the container settings.","title":"Installing Grafana"},{"location":"blog/how-to-setup-grafana-influxdb-and-telegraf-to-monitor-your-unraid-system/#configuring-grafana","text":"After the installation is finished go to the WebUI. ( http://unraidIP:3000 ) and log in with username admin and the password you chose. You should then see this on you screen: Click on Add data source and select InfluxDB. Next give the data source a name(I named it Telegraf), add the URL to InfluxDB, enter the database to use ( telegraf ) and set the HTTP Method to POST. This is helpful on some of the more heavy queries. Grafana will use the default username and password for Influxdb (root root), if you have added a user you will need to add that too. Next click Save & Test If all your settings are correct you should see this message. Next import the dashboard by hovering over the + icon and selecting Import Paste the dashboard ID 7233 **and click **Load Give it a name and UID, select the database in the drop down and click Import . Next, select the correct values on the menu at the top.","title":"Configuring Grafana"},{"location":"blog/how-to-setup-grafana-influxdb-and-telegraf-to-monitor-your-unraid-system/#_1","text":"","title":""},{"location":"blog/how-to-setup-grafana-influxdb-and-telegraf-to-monitor-your-unraid-system/#some-assembly-needed","text":"You should now already see most of the panels working and displaying stats. But there will be some panels where you need to select some values in the dropdowns at the top. Like Cache Devices. On the Cache Devices (diskio) dropdown you can select multiple devices, and it will add them to the Cache Read/Write panel. The Interval text box is the interval that is set in telegraf.conf The default value is 10 seconds, but if you changed this you can update it here. To update the drive names on the Storage Consumption panel, edit the panel and go to the Field menu. There you will can add the different Value Mappings for the different drive paths. See the video below. [video width=\"1904\" height=\"1006\" mp4=\" https://technicalramblings.com/wp-content/uploads/2019/07/Yiz3iZBsFb.mp4 \"][/video] And that's about it! This should get you going on adding or creating awesome dashboards for you Unraid system. There are tons of different dashboards on grafana.com to get inspiration from. My dashboard is far from the best one out there, so please share your awesome dashboards in the comment section or on Discord ! eckosc\\_status\\_message title=\"Not UUD\" icon=\"fa-exclamation-triangle\" type=\"error\" message=\"The dashboard used in this guide is not the **Ultimate Unraid Dashboard**seen from the offical unraid blog post. You can find that dashboard and the extra instructions in the link below!\" eckosc\\_status\\_message title=\"Not UUD\" icon=\"fa-exclamation-triangle\" type=\"error\" message=\"The dashboard used in this guide is not the **Ultimate Unraid Dashboard**seen from the offical unraid blog post. You can find that dashboard and the extra instructions in the link below!\" UUD: https://forums.unraid.net/topic/96895-ultimate-unraid-dashboard-uud/ And if you're wondering why my Grafana page looks different from the stock theme you can take a look here: https://github.com/gilbN/theme.park","title":"Some assembly needed"},{"location":"blog/how-to-setup-grafana-influxdb-and-telegraf-to-monitor-your-unraid-system/#optional-adding-ups-stats","text":"On the top of my dashboard I have UPS stats, now if you don't have a UPS (You should by the way) you can just delete those panel. But if you have a UPS that's compatible with Unraid you can check out this awesome guide: \ufeff \ufeff \ufeff \ufeff \ufeff \ufeff \ufeff \ufeff \ufeff \ufeff \ufeff \ufeff \ufeff \ufeff \ufeff \ufeff","title":"Optional: Adding UPS stats"},{"location":"blog/how-to-setup-grafana-influxdb-and-telegraf-to-monitor-your-unraid-system/#if-you-need-any-extra-help-join-the-discord-server","text":"","title":"If you need any extra help join the Discord server!"},{"location":"blog/how-to-setup-grafana-influxdb-and-telegraf-to-monitor-your-unraid-system/#_2","text":"","title":""},{"location":"blog/howto-setup-gitlab-to-use-rack-attack-to-ban-abusive-ips/","text":"How to setup GitLab to use Rack Attack and ban abusive IPs and rate limit requests \u00b6 So, for anyone that's running the GitLab Docker container, I got real IPs to pass through to the logs and was then able to setup Rack Attack (similar to Fail2Ban), which is included by default, to ban abusive IPs and rate limit failed login attempts. Note: Rack attack does not ban IPs that fail to login on you GitLab, it bans IPs that fail to authenticate after x attempts when using git http authentication! The first step is getting real IPs to pass through to the GitLab container logs. The first thing that you will need to do is edit the gitlab.rb file from inside the container itself. You can do this by first execing into the container: docker exec -it gitlab /bin/bash Where **gitlab** is the container name, and then open the file with a text editor (vim is installed): **:/# vim /etc/gitlab/gitlab.rb** Next, you will need to find the following lines: #nginx['real_ip_trusted_addresses'] = [] #nginx['real_ip_header'] = Uncomment the lines and then change them to something like this: nginx['real_ip_trusted_addresses'] = ['172.17.0.0/16','172.18.0.0/16','172.19.0.0/16','172.20.0.0/16','192.168.1.0/24'] nginx['real_ip_header'] = 'X-Forwarded-For' You will need to modify the IP address ranges to make your network(s). Once you're done, save the changes and exit the text editor. Now you need to reconfigure gitlab, while still inside the container, with the following command: gitlab-ctl reconfigure It should go through and reconfigure everything and add the changes you just made. You can verify that the changes were added with the following grep command: **grep real_ip** **/var/opt/gitlab/nginx/conf/gitlab-http.conf** The output should look similar to this: :/# grep real_ip /var/opt/gitlab/nginx/conf/gitlab-http.conf real_ip_header X-Forwarded-For; set_real_ip_from 172.17.0.0/16; set_real_ip_from 172.18.0.0/16; set_real_ip_from 172.19.0.0/16; set_real_ip_from 172.20.0.0/16; set_real_ip_from 192.168.1.0/24; With these changes now in place you should be able to see real IP addresses in the **/log/nginx/gitlab_access.log** the /log/gitlab-rails/application.log and the /log/gitlab-rails/production.log . I have **/mnt/user/Docker/gitlab-ce** set as my application data directory for the GitLab container so the full path for me is **/mnt/user/Docker/gitlab-ce/log/nginx/gitlab_access.log** . Now that real IPs are getting logged you can enable and configure the built-in Rack Attack utility to find and block abusive IPs and rate limit failed login attempts. You will need to exec back into the container if you logged out: docker exec -it gitlab /bin/bash And open the gitlab.rb file again: :/# vim /etc/gitlab/gitlab.rb Find the following section and uncomment it: # gitlab_rails['rack_attack_git_basic_auth'] = { # 'enabled' => true, # 'ip_whitelist' => [\"127.0.0.1\"], # 'maxretry' => 5, # 'findtime' => 60, # 'bantime' => 3600 # } You will need to add the IP ranges you wish to white-list, most likely the same list that you setup for the real_ip configuration, so you don't accidentally ban yourself. It will end up looking something like this: gitlab_rails['rack_attack_git_basic_auth'] = { 'enabled' => true, 'ip_whitelist' => [\"127.0.0.1\", \"172.17.0.0/16\", \"172.18.0.0/16\", \"172.19.0.0/16\", \"172.20.0.0/16\", \"192.168.1.0/24\"], 'maxretry' => 5, 'findtime' => 60, 'bantime' => 3600 } Next you need to reconfigure GitLab again: **gitlab-ctl reconfigure** Once the reconfiguration is done you can have someone or yourself test the functionality and try to git clone with invalid credentials. Once they're blocked, they should see a \" fatal: unable to access \" message like below. gilbn@DESKTOP-UP9572O MINGW64 /f/github $ git clone https://gitlab.domain.com/gilbn/testproject Cloning into 'testproject'... remote: HTTP Basic: Access denied fatal: Authentication failed for 'https://gitlab.domain.com/gilbn/testproject.git/' gilbn@DESKTOP-UP9572O MINGW64 /f/github $ git clone https://gitlab.domain.com/gilbn/testproject Cloning into 'testproject'... remote: HTTP Basic: Access denied fatal: Authentication failed for 'https://gitlab.domain.com/gilbn/testproject.git/' gilbn@DESKTOP-UP9572O MINGW64 /f/github $ git clone https://gitlab.domain.com/gilbn/testproject Cloning into 'testproject'... remote: Forbidden fatal: unable to access 'https://gitlab.domain.com/gilbn/testproject/': The requested URL returned error: 403 In addition to them or you seeing that message , you can check the production.log file in the appdata directory for the container: grep -i blacklist /mnt/user/Docker/gitlab-ce/log/gitlab-rails/production.log If the IP was blocked, you should see something similar to the following: root@Nostromo:# grep -i blacklist /mnt/user/Docker/gitlab-ce/log/gitlab-rails/production.log Rack_Attack: blacklist 46.246.123.33 GET /gilbn/testproject/info/refs?service=git-upload-pack For rate limit throttling on failed logins you will see: :~# grep -i rack_attack /home/gitlab/logs/gitlab-rails/production.log Rack_Attack: throttle 82.37.176.202 POST /users/sign_in And the user will see a Retry Later message in their browser. Note: The rate limit does not follow the blacklist **bantim**e . The rate limit can be adjusted on the rate limit lines in the gitlab.rb file. #gitlab_rails['rate_limit_requests_per_period'] = 10 #gitlab_rails['rate_limit_period'] = 60 Default is 10 requests in a 60 second period. If you want to add fail2ban on your login page you can use this filter: https://gist.github.com/pawilon/238c278d3c6c4669771eb81b03264acd Written by Tronyx - https://github.com/christronyxyocum Edited by GilbN If you need any extra help join the Discord server! \u00b6 \u00b6","title":"How to setup GitLab to use Rack Attack and ban abusive IPs and rate limit requests"},{"location":"blog/howto-setup-gitlab-to-use-rack-attack-to-ban-abusive-ips/#how-to-setup-gitlab-to-use-rack-attack-and-ban-abusive-ips-and-rate-limit-requests","text":"So, for anyone that's running the GitLab Docker container, I got real IPs to pass through to the logs and was then able to setup Rack Attack (similar to Fail2Ban), which is included by default, to ban abusive IPs and rate limit failed login attempts. Note: Rack attack does not ban IPs that fail to login on you GitLab, it bans IPs that fail to authenticate after x attempts when using git http authentication! The first step is getting real IPs to pass through to the GitLab container logs. The first thing that you will need to do is edit the gitlab.rb file from inside the container itself. You can do this by first execing into the container: docker exec -it gitlab /bin/bash Where **gitlab** is the container name, and then open the file with a text editor (vim is installed): **:/# vim /etc/gitlab/gitlab.rb** Next, you will need to find the following lines: #nginx['real_ip_trusted_addresses'] = [] #nginx['real_ip_header'] = Uncomment the lines and then change them to something like this: nginx['real_ip_trusted_addresses'] = ['172.17.0.0/16','172.18.0.0/16','172.19.0.0/16','172.20.0.0/16','192.168.1.0/24'] nginx['real_ip_header'] = 'X-Forwarded-For' You will need to modify the IP address ranges to make your network(s). Once you're done, save the changes and exit the text editor. Now you need to reconfigure gitlab, while still inside the container, with the following command: gitlab-ctl reconfigure It should go through and reconfigure everything and add the changes you just made. You can verify that the changes were added with the following grep command: **grep real_ip** **/var/opt/gitlab/nginx/conf/gitlab-http.conf** The output should look similar to this: :/# grep real_ip /var/opt/gitlab/nginx/conf/gitlab-http.conf real_ip_header X-Forwarded-For; set_real_ip_from 172.17.0.0/16; set_real_ip_from 172.18.0.0/16; set_real_ip_from 172.19.0.0/16; set_real_ip_from 172.20.0.0/16; set_real_ip_from 192.168.1.0/24; With these changes now in place you should be able to see real IP addresses in the **/log/nginx/gitlab_access.log** the /log/gitlab-rails/application.log and the /log/gitlab-rails/production.log . I have **/mnt/user/Docker/gitlab-ce** set as my application data directory for the GitLab container so the full path for me is **/mnt/user/Docker/gitlab-ce/log/nginx/gitlab_access.log** . Now that real IPs are getting logged you can enable and configure the built-in Rack Attack utility to find and block abusive IPs and rate limit failed login attempts. You will need to exec back into the container if you logged out: docker exec -it gitlab /bin/bash And open the gitlab.rb file again: :/# vim /etc/gitlab/gitlab.rb Find the following section and uncomment it: # gitlab_rails['rack_attack_git_basic_auth'] = { # 'enabled' => true, # 'ip_whitelist' => [\"127.0.0.1\"], # 'maxretry' => 5, # 'findtime' => 60, # 'bantime' => 3600 # } You will need to add the IP ranges you wish to white-list, most likely the same list that you setup for the real_ip configuration, so you don't accidentally ban yourself. It will end up looking something like this: gitlab_rails['rack_attack_git_basic_auth'] = { 'enabled' => true, 'ip_whitelist' => [\"127.0.0.1\", \"172.17.0.0/16\", \"172.18.0.0/16\", \"172.19.0.0/16\", \"172.20.0.0/16\", \"192.168.1.0/24\"], 'maxretry' => 5, 'findtime' => 60, 'bantime' => 3600 } Next you need to reconfigure GitLab again: **gitlab-ctl reconfigure** Once the reconfiguration is done you can have someone or yourself test the functionality and try to git clone with invalid credentials. Once they're blocked, they should see a \" fatal: unable to access \" message like below. gilbn@DESKTOP-UP9572O MINGW64 /f/github $ git clone https://gitlab.domain.com/gilbn/testproject Cloning into 'testproject'... remote: HTTP Basic: Access denied fatal: Authentication failed for 'https://gitlab.domain.com/gilbn/testproject.git/' gilbn@DESKTOP-UP9572O MINGW64 /f/github $ git clone https://gitlab.domain.com/gilbn/testproject Cloning into 'testproject'... remote: HTTP Basic: Access denied fatal: Authentication failed for 'https://gitlab.domain.com/gilbn/testproject.git/' gilbn@DESKTOP-UP9572O MINGW64 /f/github $ git clone https://gitlab.domain.com/gilbn/testproject Cloning into 'testproject'... remote: Forbidden fatal: unable to access 'https://gitlab.domain.com/gilbn/testproject/': The requested URL returned error: 403 In addition to them or you seeing that message , you can check the production.log file in the appdata directory for the container: grep -i blacklist /mnt/user/Docker/gitlab-ce/log/gitlab-rails/production.log If the IP was blocked, you should see something similar to the following: root@Nostromo:# grep -i blacklist /mnt/user/Docker/gitlab-ce/log/gitlab-rails/production.log Rack_Attack: blacklist 46.246.123.33 GET /gilbn/testproject/info/refs?service=git-upload-pack For rate limit throttling on failed logins you will see: :~# grep -i rack_attack /home/gitlab/logs/gitlab-rails/production.log Rack_Attack: throttle 82.37.176.202 POST /users/sign_in And the user will see a Retry Later message in their browser. Note: The rate limit does not follow the blacklist **bantim**e . The rate limit can be adjusted on the rate limit lines in the gitlab.rb file. #gitlab_rails['rate_limit_requests_per_period'] = 10 #gitlab_rails['rate_limit_period'] = 60 Default is 10 requests in a 60 second period. If you want to add fail2ban on your login page you can use this filter: https://gist.github.com/pawilon/238c278d3c6c4669771eb81b03264acd Written by Tronyx - https://github.com/christronyxyocum Edited by GilbN","title":"How to setup GitLab to use Rack Attack and ban abusive IPs and rate limit requests"},{"location":"blog/howto-setup-gitlab-to-use-rack-attack-to-ban-abusive-ips/#if-you-need-any-extra-help-join-the-discord-server","text":"","title":"If you need any extra help join the Discord server!"},{"location":"blog/howto-setup-gitlab-to-use-rack-attack-to-ban-abusive-ips/#_1","text":"","title":""},{"location":"blog/migrating-view-history-between-two-plex-servers-avoiding-negative-unwatched-count/","text":"Migrating/Merging View History between two Plex Servers - Avoiding Negative Unwatched Count \u00b6 Every so often you may put yourself in a situation where you're forced to reinstall Plex. Regrettably, Plex has no built-in functionality for database back-up and migration. This may seem logical, as it is typically unimportant to backup and restore posters and folder matches. However, there is one piece of database information that is worth restoring from previous servers: the view history . This information tells the Plex Media Server instance what has been marked as Played/Unplayed. It also contains some extra information such as user ratings. But the issue arises when merging into a server that isn't a clean install (absolutely no watch history). In this scenario, you may be faced with errors such as Error: near line 2319: UNIQUE constraint failed:metadata_item_settings.id , and you may see negative unplayed counts within Plex. Migrating watch history while avoiding these issues can be done in six easy steps. Part One: Merging Databases \u00b6 1) Locate the databases directory for the Plex install that contains the view history you wish to save. This will be found in **./Plex Media Server/Plug-in Support/Databases/** The default location of this Plex Media Server folder will vary depending on operating system. For more directories see Where is the Plex Media Server data directory located? Here's the location for a few common operating systems. Windows: %LOCALAPPDATA% OSX: ~/Library/ApplicationSupport/ Linux: $PLEX_HOME/Library/ApplicationSupport/ Debian: /var/lib/plexmediaserver/Library/Application Support/ FreeBSD: /usr/local/plexdata/ FreeNAS: /var/db/plexdata/ Unraid Docker (Binhex): /mnt/cache/appdata/binhex-plex/ When you locate this directory, navigate to it via a terminal. This can be done with cd on Linux and dir on Windows. 2) Ensure that sqlite3 is installed on the host operating system by typing sqlite3 -version into your terminal. If an error shows indicating that it is not installed, install SQLite3 through your package manager or through this link . 3) Put the view history into a file called viewhistory.sql. This can be done via typing the following command while in the Databases directory: echo \".dump metadata_item_settings\" | sqlite3 com.plexapp.plugins.library.db | grep -v TABLE | grep -v INDEX > viewhistory.sql 4) Move viewhistory.sql to the databases directory for the Plex install that you're migrating data into. 5) Merge view history data from the old server into the new server. This can by done by running the following: cat viewhistory.sql | sqlite3 com.plexapp.plugins.library.db Do not be alarmed if you see a _ UNIQUE constraint failed _error. This will be fixed in the next step. Part Two: Removing the Duplicates \u00b6 6) Remove duplicate database entries that cause negative a view count. Please note, it is highly recommended to create a backup of ** com.plexapp.plugins.library.db **before attempting to modify it. If the server you're merging view states to is not perfectly clean (a server with no watch history), or if you received ** UNIQUE constraint failed **in the previous steps then you must run the following command in the current directory: sqlite3 com.plexapp.plugins.library.db \"DELETE FROM metadata_item_settings WHERE id in (SELECT MIN(id) FROM metadata_item_settings GROUP BY guid HAVING COUNT(guid) > 1);\"","title":"Migrating/Merging View History between two Plex Servers - Avoiding Negative Unwatched Count"},{"location":"blog/migrating-view-history-between-two-plex-servers-avoiding-negative-unwatched-count/#migratingmerging-view-history-between-two-plex-servers-avoiding-negative-unwatched-count","text":"Every so often you may put yourself in a situation where you're forced to reinstall Plex. Regrettably, Plex has no built-in functionality for database back-up and migration. This may seem logical, as it is typically unimportant to backup and restore posters and folder matches. However, there is one piece of database information that is worth restoring from previous servers: the view history . This information tells the Plex Media Server instance what has been marked as Played/Unplayed. It also contains some extra information such as user ratings. But the issue arises when merging into a server that isn't a clean install (absolutely no watch history). In this scenario, you may be faced with errors such as Error: near line 2319: UNIQUE constraint failed:metadata_item_settings.id , and you may see negative unplayed counts within Plex. Migrating watch history while avoiding these issues can be done in six easy steps.","title":"Migrating/Merging View History between two Plex Servers - Avoiding Negative Unwatched Count"},{"location":"blog/migrating-view-history-between-two-plex-servers-avoiding-negative-unwatched-count/#part-one-merging-databases","text":"1) Locate the databases directory for the Plex install that contains the view history you wish to save. This will be found in **./Plex Media Server/Plug-in Support/Databases/** The default location of this Plex Media Server folder will vary depending on operating system. For more directories see Where is the Plex Media Server data directory located? Here's the location for a few common operating systems. Windows: %LOCALAPPDATA% OSX: ~/Library/ApplicationSupport/ Linux: $PLEX_HOME/Library/ApplicationSupport/ Debian: /var/lib/plexmediaserver/Library/Application Support/ FreeBSD: /usr/local/plexdata/ FreeNAS: /var/db/plexdata/ Unraid Docker (Binhex): /mnt/cache/appdata/binhex-plex/ When you locate this directory, navigate to it via a terminal. This can be done with cd on Linux and dir on Windows. 2) Ensure that sqlite3 is installed on the host operating system by typing sqlite3 -version into your terminal. If an error shows indicating that it is not installed, install SQLite3 through your package manager or through this link . 3) Put the view history into a file called viewhistory.sql. This can be done via typing the following command while in the Databases directory: echo \".dump metadata_item_settings\" | sqlite3 com.plexapp.plugins.library.db | grep -v TABLE | grep -v INDEX > viewhistory.sql 4) Move viewhistory.sql to the databases directory for the Plex install that you're migrating data into. 5) Merge view history data from the old server into the new server. This can by done by running the following: cat viewhistory.sql | sqlite3 com.plexapp.plugins.library.db Do not be alarmed if you see a _ UNIQUE constraint failed _error. This will be fixed in the next step.","title":"Part One: Merging Databases"},{"location":"blog/migrating-view-history-between-two-plex-servers-avoiding-negative-unwatched-count/#part-two-removing-the-duplicates","text":"6) Remove duplicate database entries that cause negative a view count. Please note, it is highly recommended to create a backup of ** com.plexapp.plugins.library.db **before attempting to modify it. If the server you're merging view states to is not perfectly clean (a server with no watch history), or if you received ** UNIQUE constraint failed **in the previous steps then you must run the following command in the current directory: sqlite3 com.plexapp.plugins.library.db \"DELETE FROM metadata_item_settings WHERE id in (SELECT MIN(id) FROM metadata_item_settings GROUP BY guid HAVING COUNT(guid) > 1);\"","title":"Part Two: Removing the Duplicates"},{"location":"blog/monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-2019-edition/","text":"Monitoring your UPS stats and cost with InfluxDB and Grafana on Unraid - Apcupsd Container Edition \u00b6 I recently discovered the atribe/apcupsd-influxdb-exporter container on the CA plugin page and immediately thought it would be a great replacement for the script that I run, described in this post. But time got in the way and I forgot about it. But now the summer is here, the days are longer and free time is no longer a rarity :) So this will be a quick follow up post on how to switch to this container and get even more accurate readings! Grafana \u00b6 If you haven't installed or used Grafana and InfluxDB, I recommend reading this post first. You can skip the Telegraf part but that's no fun :) InfluxDB \u00b6 eckosc\\_status\\_message title=\"Dont' use the latest tag\" icon=\"fa-exclamation-triangle\" type=\"warn\" message=\"The `:latest` tag will run InfluxDB V2! This guide was written for v1.8. Change the tag to `:1.8.4` for it to work!\" eckosc\\_status\\_message title=\"Dont' use the latest tag\" icon=\"fa-exclamation-triangle\" type=\"warn\" message=\"The `:latest` tag will run InfluxDB V2! This guide was written for v1.8. Change the tag to `:1.8.4` for it to work!\" Installing the container \u00b6 eckosc\\_status\\_message title=\"Note\" icon=\"fa-exclamation-triangle\" type=\"info\" message=\"You need to activate the apcupsd daemon to be able to show any statistics. Go to Settings -> UPS Settings and set Start APC UPS daemon: to Yes. Then Click `Apply`\" eckosc\\_status\\_message title=\"Note\" icon=\"fa-exclamation-triangle\" type=\"info\" message=\"You need to activate the apcupsd daemon to be able to show any statistics. Go to Settings -> UPS Settings and set Start APC UPS daemon: to Yes. Then Click `Apply`\" Search for apcupsd in CA and click install. Fill out the different container variables to match your setup. Remember to click on Show more settings... to see the rest of the variables. [eckosc_status_message title=\"Warning\" icon=\"fa-exclamation-triangle\" type=\"error\" message=\"If your UPS has the NOMPOWER metric you need to remove this variable as it may interfere with how it reports the watts usage\"] You can see if it reports it by going to the dashboard and look at the stats or run the apcaccess command. apcaccess | grep NOMPOWER The INFLUXDB_HOST and APCUPSD_HOST will most likely be your Unraid IP and INFLUXDB_PORT is the port for your InfluxDB http service. Default it will be 8086 . You can leave user and password blank if you don't have a specific user you want to use in your InfluxDB instance. The database will be created at the launch of the apcupsd container, so you don't need to create it manually. If you're using the php script from my previous post I recommend using a different database as the intervals are not the same and the queries in the first dashboard wont work. If you want to change the interval you can add the INTERVAL variable set your desired value. Default is 10(seconds) eckosc\\_status\\_message title=\"Note\" icon=\"\" type=\"info\" message=\"If you change the interval you need to update the queries on the dashboard to reflect the change. The default is 360 values per hour (6 intervals per minute \\* 60 minutes)\" eckosc\\_status\\_message title=\"Note\" icon=\"\" type=\"info\" message=\"If you change the interval you need to update the queries on the dashboard to reflect the change. The default is 360 values per hour (6 intervals per minute \\* 60 minutes)\" eckosc\\_full\\_width\\_block eckosc\\_full\\_width\\_block /eckosc\\_full\\_width\\_block /eckosc\\_full\\_width\\_block UPS Dashboard \u00b6 After you have installed the apcupsd container add the datasource in Grafana and use the database name you chose above. Next import my new UPS dashboard and select the correct datasource in the drop down menu at the top. Link to dashboard: https://grafana.com/grafana/dashboards/10615 And that's it! Enjoy your new and improved UPS stats! [eckosc_full_width_block] /eckosc\\_full\\_width\\_block /eckosc\\_full\\_width\\_block The custom theme for Grafana can be found here: https://github.com/gilbN/theme.park If you need any extra help join the Discord server! \u00b6 \u00b6","title":"Monitoring your UPS stats and cost with InfluxDB and Grafana on Unraid - Apcupsd Container Edition"},{"location":"blog/monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-2019-edition/#monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-apcupsd-container-edition","text":"I recently discovered the atribe/apcupsd-influxdb-exporter container on the CA plugin page and immediately thought it would be a great replacement for the script that I run, described in this post. But time got in the way and I forgot about it. But now the summer is here, the days are longer and free time is no longer a rarity :) So this will be a quick follow up post on how to switch to this container and get even more accurate readings!","title":"Monitoring your UPS stats and cost with InfluxDB and Grafana on Unraid - Apcupsd Container Edition"},{"location":"blog/monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-2019-edition/#grafana","text":"If you haven't installed or used Grafana and InfluxDB, I recommend reading this post first. You can skip the Telegraf part but that's no fun :)","title":"Grafana"},{"location":"blog/monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-2019-edition/#influxdb","text":"eckosc\\_status\\_message title=\"Dont' use the latest tag\" icon=\"fa-exclamation-triangle\" type=\"warn\" message=\"The `:latest` tag will run InfluxDB V2! This guide was written for v1.8. Change the tag to `:1.8.4` for it to work!\" eckosc\\_status\\_message title=\"Dont' use the latest tag\" icon=\"fa-exclamation-triangle\" type=\"warn\" message=\"The `:latest` tag will run InfluxDB V2! This guide was written for v1.8. Change the tag to `:1.8.4` for it to work!\"","title":"InfluxDB"},{"location":"blog/monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-2019-edition/#installing-the-container","text":"eckosc\\_status\\_message title=\"Note\" icon=\"fa-exclamation-triangle\" type=\"info\" message=\"You need to activate the apcupsd daemon to be able to show any statistics. Go to Settings -> UPS Settings and set Start APC UPS daemon: to Yes. Then Click `Apply`\" eckosc\\_status\\_message title=\"Note\" icon=\"fa-exclamation-triangle\" type=\"info\" message=\"You need to activate the apcupsd daemon to be able to show any statistics. Go to Settings -> UPS Settings and set Start APC UPS daemon: to Yes. Then Click `Apply`\" Search for apcupsd in CA and click install. Fill out the different container variables to match your setup. Remember to click on Show more settings... to see the rest of the variables. [eckosc_status_message title=\"Warning\" icon=\"fa-exclamation-triangle\" type=\"error\" message=\"If your UPS has the NOMPOWER metric you need to remove this variable as it may interfere with how it reports the watts usage\"] You can see if it reports it by going to the dashboard and look at the stats or run the apcaccess command. apcaccess | grep NOMPOWER The INFLUXDB_HOST and APCUPSD_HOST will most likely be your Unraid IP and INFLUXDB_PORT is the port for your InfluxDB http service. Default it will be 8086 . You can leave user and password blank if you don't have a specific user you want to use in your InfluxDB instance. The database will be created at the launch of the apcupsd container, so you don't need to create it manually. If you're using the php script from my previous post I recommend using a different database as the intervals are not the same and the queries in the first dashboard wont work. If you want to change the interval you can add the INTERVAL variable set your desired value. Default is 10(seconds) eckosc\\_status\\_message title=\"Note\" icon=\"\" type=\"info\" message=\"If you change the interval you need to update the queries on the dashboard to reflect the change. The default is 360 values per hour (6 intervals per minute \\* 60 minutes)\" eckosc\\_status\\_message title=\"Note\" icon=\"\" type=\"info\" message=\"If you change the interval you need to update the queries on the dashboard to reflect the change. The default is 360 values per hour (6 intervals per minute \\* 60 minutes)\" eckosc\\_full\\_width\\_block eckosc\\_full\\_width\\_block /eckosc\\_full\\_width\\_block /eckosc\\_full\\_width\\_block","title":"Installing the container"},{"location":"blog/monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-2019-edition/#ups-dashboard","text":"After you have installed the apcupsd container add the datasource in Grafana and use the database name you chose above. Next import my new UPS dashboard and select the correct datasource in the drop down menu at the top. Link to dashboard: https://grafana.com/grafana/dashboards/10615 And that's it! Enjoy your new and improved UPS stats! [eckosc_full_width_block] /eckosc\\_full\\_width\\_block /eckosc\\_full\\_width\\_block The custom theme for Grafana can be found here: https://github.com/gilbN/theme.park","title":"UPS Dashboard"},{"location":"blog/monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-2019-edition/#if-you-need-any-extra-help-join-the-discord-server","text":"","title":"If you need any extra help join the Discord server!"},{"location":"blog/monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-2019-edition/#_1","text":"","title":""},{"location":"blog/monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-nut-edition/","text":"Monitoring your UPS stats and cost with InfluxDB and Grafana on Unraid \u2013 NUT Edition \u00b6 This quick guide will explain how to setup Grafana and InfluxDB to monitor your UPS power usage using the NUT plugin and maihai/nut-influxdb-exporter docker container on Unraid. This pretty much just a rewrite of this article but for the NUT plugin. Grafana \u00b6 If you haven't installed or used Grafana and InfluxDB, I recommend reading this post first. You can skip the Telegraf part but that's no fun :) InfluxDB \u00b6 Dont' use the latest tag The :latest tag will run InfluxDB V2! This guide was written for v1.8. Change the tag to :1.8.4 for it to work! Installing the container \u00b6 Search for nut influx exporter in CA and click install. Fill out the different container variables to match your setup. Remember to click on Show more settings... to see the rest of the variables. If your UPS reports the WATTS/Nominal Power metric you can remove this variable. You can see if it reports it by going to the dashboard and look at the stats or run the upsc ups command. The INFLUXDB_HOST and NUT_HOST will most likely be your Unraid IP and INFLUXDB_PORT is the port for your InfluxDB http service. Default it will be 8086 . You can leave user and password blank if you don't have a specific user you want to use in your InfluxDB instance. And the same for the NUT port, username and password. The database will be created at the launch of the container, so you don't need to create it manually. The default interval is set to 20 seconds, and if I recall correctly that is the max for NUT. I tried setting it to 10 seconds using the INTERVAL variable but when I did that it reported the same metric twice all the time. eckosc\\_full\\_width\\_block eckosc\\_full\\_width\\_block /eckosc\\_full\\_width\\_block /eckosc\\_full\\_width\\_block UPS Dashboard \u00b6 After you have installed the apcupsd container add the datasource in Grafana and use the database name you chose above. Next import my new UPS dashboard and select the correct datasource in the drop down menu at the top. Link to dashboard: https://grafana.com/grafana/dashboards/10914 And that's it! Enjoy your new and improved UPS stats! [eckosc_full_width_block] /eckosc\\_full\\_width\\_block /eckosc\\_full\\_width\\_block The custom theme for Grafana can be found here: https://github.com/gilbN/theme.park If you need any extra help join the Discord server! \u00b6 \u00b6","title":"Monitoring your UPS stats and cost with InfluxDB and Grafana on Unraid - NUT Edition"},{"location":"blog/monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-nut-edition/#monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-nut-edition","text":"This quick guide will explain how to setup Grafana and InfluxDB to monitor your UPS power usage using the NUT plugin and maihai/nut-influxdb-exporter docker container on Unraid. This pretty much just a rewrite of this article but for the NUT plugin.","title":"Monitoring your UPS stats and cost with InfluxDB and Grafana on Unraid \u2013 NUT Edition"},{"location":"blog/monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-nut-edition/#grafana","text":"If you haven't installed or used Grafana and InfluxDB, I recommend reading this post first. You can skip the Telegraf part but that's no fun :)","title":"Grafana"},{"location":"blog/monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-nut-edition/#influxdb","text":"Dont' use the latest tag The :latest tag will run InfluxDB V2! This guide was written for v1.8. Change the tag to :1.8.4 for it to work!","title":"InfluxDB"},{"location":"blog/monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-nut-edition/#installing-the-container","text":"Search for nut influx exporter in CA and click install. Fill out the different container variables to match your setup. Remember to click on Show more settings... to see the rest of the variables. If your UPS reports the WATTS/Nominal Power metric you can remove this variable. You can see if it reports it by going to the dashboard and look at the stats or run the upsc ups command. The INFLUXDB_HOST and NUT_HOST will most likely be your Unraid IP and INFLUXDB_PORT is the port for your InfluxDB http service. Default it will be 8086 . You can leave user and password blank if you don't have a specific user you want to use in your InfluxDB instance. And the same for the NUT port, username and password. The database will be created at the launch of the container, so you don't need to create it manually. The default interval is set to 20 seconds, and if I recall correctly that is the max for NUT. I tried setting it to 10 seconds using the INTERVAL variable but when I did that it reported the same metric twice all the time. eckosc\\_full\\_width\\_block eckosc\\_full\\_width\\_block /eckosc\\_full\\_width\\_block /eckosc\\_full\\_width\\_block","title":"Installing the container"},{"location":"blog/monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-nut-edition/#ups-dashboard","text":"After you have installed the apcupsd container add the datasource in Grafana and use the database name you chose above. Next import my new UPS dashboard and select the correct datasource in the drop down menu at the top. Link to dashboard: https://grafana.com/grafana/dashboards/10914 And that's it! Enjoy your new and improved UPS stats! [eckosc_full_width_block] /eckosc\\_full\\_width\\_block /eckosc\\_full\\_width\\_block The custom theme for Grafana can be found here: https://github.com/gilbN/theme.park","title":"UPS Dashboard"},{"location":"blog/monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-nut-edition/#if-you-need-any-extra-help-join-the-discord-server","text":"","title":"If you need any extra help join the Discord server!"},{"location":"blog/monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-nut-edition/#_1","text":"","title":""},{"location":"blog/monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-telegraf-edition/","text":"Monitoring your UPS stats and cost with InfluxDB and Grafana on Unraid \u2013 Telegraf Edition \u00b6 So.. I just found out that Telegraf recently added Apcupsd as a plugin . So naturally I created a dashboard for it :) I promise, this is the last UPS stats blog post for a while! Installing InfluxDB \u00b6 Just skip down to the plugin part if you're already up and running. Search for influxdb in Community Apps and install it using the default template. Select your appdata path and host ports if the default ones are taken. There is no other setup than just installing the container. Note Dont' use the latest tag\" icon=\"fa-exclamation-triangle\" type=\"warn\" message=\"The :latest tag will run InfluxDB V2! This guide was written for v1.8. Change the tag to :1.8.4 for it to work! Installing Telegraf \u00b6 Again, you can just skip this step if telegraf is already setup :) Warning This container wont start unless the telegraf.conf file already exists on the host. (Host path 7) Do not install the container before you follow the steps below! Download the file and place it in the location you want the telegraf appdata to be. e.g. /mnt/cache/appdata/telegraf/telegraf.conf The default config file can be downloaded here: https://github.com/influxdata/telegraf/blob/master/etc/telegraf.conf Next you need to edit the telegraf.conf file. Go to the location you saved the file and scroll down to OUTPUT PLUGINS which should be around line 90-103.Uncomment (Remove #) the http url line for InfluxDB like so: # urls = [\"unix:///var/run/influxdb.sock\"] # urls = [\"udp://127.0.0.1:8089\"] urls = [ \"http://192.168.1.34:8086\" ] 192.168.1.34 is the IP address to my Unraid server and 8086 is the default InfluxDB port that runs the InfluxDB HTTP service. Adding the plugin \u00b6 If you already have telegraf installed you can simply add or uncomment the plugin line [[inputs.apcupsd]] like so: # # Monitor APC UPSes connected to apcupsd [[ inputs.apcupsd ]] # # A list of running apcupsd server to connect to. # # If not provided will default to tcp://127.0.0.1:3551 # servers = [\"tcp://127.0.0.1:3551\"] # # ## Timeout for dialing server. # timeout = \"5s\" If the config file is up to date the it should be around line 1783. If it's not just add it to the config file. If you want to add more plugins check out this post: How to setup Grafana, InfluxDB and Telegraf to monitor your unRAID system. Note You need to activate the apcupsd daemon to be able to show any statistics. Go to Settings -> UPS Settings and setStart APC UPS daemon: to Yes. Then Click Apply Installing Grafana \u00b6 Installing Grafana is also quite simple. Chose your host port for the webUI and add your unraid URL and admin password to the container settings. Configuring Grafana \u00b6 After the installation is finished go to the WebUI. http://unraidIP:3000 and log in with username admin and the password you chose. You should then see this on you screen: Click on Add data source and select InfluxDB. Next give the data source a name, add the URL to InfluxDB, enter the database to use ( telegraf ) and click Save & Test If all your settings are correct you should see this message. Adding the dashboard \u00b6 Next import the dashboard by hovering over the + icon and selecting Import Paste the dashboard ID 10977 and click Load Give it a name and UID, and click Import . Next add your kWh price, max watt and select the Telegraf datasource. You should now see the panels starting to populate! The custom theme for Grafana can be found here: https://github.com/gilbN/theme.park If you need any extra help join the Discord server \u00b6 \u00b6 Sources: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/apcupsd https://github.com/influxdata/telegraf/blob/master/etc/telegraf.conf","title":"Monitoring your UPS stats and cost with InfluxDB and Grafana on Unraid - Telegraf Edition"},{"location":"blog/monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-telegraf-edition/#monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-telegraf-edition","text":"So.. I just found out that Telegraf recently added Apcupsd as a plugin . So naturally I created a dashboard for it :) I promise, this is the last UPS stats blog post for a while!","title":"Monitoring your UPS stats and cost with InfluxDB and Grafana on Unraid \u2013 Telegraf Edition"},{"location":"blog/monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-telegraf-edition/#installing-influxdb","text":"Just skip down to the plugin part if you're already up and running. Search for influxdb in Community Apps and install it using the default template. Select your appdata path and host ports if the default ones are taken. There is no other setup than just installing the container. Note Dont' use the latest tag\" icon=\"fa-exclamation-triangle\" type=\"warn\" message=\"The :latest tag will run InfluxDB V2! This guide was written for v1.8. Change the tag to :1.8.4 for it to work!","title":"Installing InfluxDB"},{"location":"blog/monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-telegraf-edition/#installing-telegraf","text":"Again, you can just skip this step if telegraf is already setup :) Warning This container wont start unless the telegraf.conf file already exists on the host. (Host path 7) Do not install the container before you follow the steps below! Download the file and place it in the location you want the telegraf appdata to be. e.g. /mnt/cache/appdata/telegraf/telegraf.conf The default config file can be downloaded here: https://github.com/influxdata/telegraf/blob/master/etc/telegraf.conf Next you need to edit the telegraf.conf file. Go to the location you saved the file and scroll down to OUTPUT PLUGINS which should be around line 90-103.Uncomment (Remove #) the http url line for InfluxDB like so: # urls = [\"unix:///var/run/influxdb.sock\"] # urls = [\"udp://127.0.0.1:8089\"] urls = [ \"http://192.168.1.34:8086\" ] 192.168.1.34 is the IP address to my Unraid server and 8086 is the default InfluxDB port that runs the InfluxDB HTTP service.","title":"Installing Telegraf"},{"location":"blog/monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-telegraf-edition/#adding-the-plugin","text":"If you already have telegraf installed you can simply add or uncomment the plugin line [[inputs.apcupsd]] like so: # # Monitor APC UPSes connected to apcupsd [[ inputs.apcupsd ]] # # A list of running apcupsd server to connect to. # # If not provided will default to tcp://127.0.0.1:3551 # servers = [\"tcp://127.0.0.1:3551\"] # # ## Timeout for dialing server. # timeout = \"5s\" If the config file is up to date the it should be around line 1783. If it's not just add it to the config file. If you want to add more plugins check out this post: How to setup Grafana, InfluxDB and Telegraf to monitor your unRAID system. Note You need to activate the apcupsd daemon to be able to show any statistics. Go to Settings -> UPS Settings and setStart APC UPS daemon: to Yes. Then Click Apply","title":"Adding the plugin"},{"location":"blog/monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-telegraf-edition/#installing-grafana","text":"Installing Grafana is also quite simple. Chose your host port for the webUI and add your unraid URL and admin password to the container settings.","title":"Installing Grafana"},{"location":"blog/monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-telegraf-edition/#configuring-grafana","text":"After the installation is finished go to the WebUI. http://unraidIP:3000 and log in with username admin and the password you chose. You should then see this on you screen: Click on Add data source and select InfluxDB. Next give the data source a name, add the URL to InfluxDB, enter the database to use ( telegraf ) and click Save & Test If all your settings are correct you should see this message.","title":"Configuring Grafana"},{"location":"blog/monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-telegraf-edition/#adding-the-dashboard","text":"Next import the dashboard by hovering over the + icon and selecting Import Paste the dashboard ID 10977 and click Load Give it a name and UID, and click Import . Next add your kWh price, max watt and select the Telegraf datasource. You should now see the panels starting to populate! The custom theme for Grafana can be found here: https://github.com/gilbN/theme.park","title":"Adding the dashboard"},{"location":"blog/monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-telegraf-edition/#if-you-need-any-extra-help-join-the-discord-server","text":"","title":"If you need any extra help join the Discord server"},{"location":"blog/monitoring-your-ups-stats-and-cost-with-influxdb-and-grafana-on-unraid-telegraf-edition/#_1","text":"Sources: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/apcupsd https://github.com/influxdata/telegraf/blob/master/etc/telegraf.conf","title":""},{"location":"blog/my-unraid-server/","text":"My unRAID Server \u00b6 Since this blog will mostly be for my own sake. Just me writing down some guides on different things so I don't forget. I think it's appropriate that my first post will be about my server.. My current server exists mainly for serving myself and my familiy/friends plex content. Now since this is it's main purpose it is somewhat over powered. Specs: \u00b6 CPU: 2 x XEON E5-2670v1 - [16 cores / 32 threads @ 2.60 GHz/3.30 GHz ] CPU cooler: 2 x Noctua NH-U14S Motherboard: Supermicro X9DRL-iF RAM: Samsung ECC REG 64GB 8x8GB 1333mhz [M393B1K70DH0-YH9] PSU: Corsair RM850x 850W Case: Fractal Define R5 HDD's: 1 x Seagate Ironwolf 8TB [Parity drive] 2 x Seagate Ironwolf 4TB [Data drives] 4 x WD Red 4TB NAS Harddrive [Data drives] 2 x Crucial MX300 275GB SSD [Cache drives in RAID1] 1 x HyperX Fury 120GB 2.5\" SSD [Plex drive] OS drive: Kingston Datatraveler SE9 16GB USB drive Now up until Feb 2017 my server was my old i5-3570K gaming rig and a low power freenas setup, and because I wanted to lower the overall power usage so I bought all the equipment above to do exactly that.. Makes sense right? Not exactly.. \u00af (\u30c4) /\u00af Well.. after hanging out in the Plex Discord channel, things got a little overboard. Now, my server is not nearly as powerful as some people over at r/plex or r/homelab but with a 18K passmark score it can easily transcode up to 14 1080P streams on plex. Not that it will ever have to.. The server on my \"test bench\" with my old NAS, and yes I'm an Alien fan :) OS: \u00b6 Should be no surprise, but if you haven't figured it out yet, I run all this on LimeTech's unRAID OS 6 And coming from windows it has mostly been an easy ride. Now why unRAID? Simply put; Docker.. Now there's more to unRAID than docker containers. A lot more. But I wanted an \"all in one package\" that I could easily manage and expand. And unRAID does just that. Before unRAID I was running my NAS on Freenas 9.10 Freenas is an awesome free storage OS that is great for both home and business use as it uses the ZFS filesystem. I won't go into detail what ZFS is why it's great, but my biggest gripe with Freenas was that the app support wasn't the greatest. For just a storage OS it worked great. The main page on the unRAID GUI Use \u00b6 As I have stated, the main purpose of my server is to serve content via plex. But adding a couple of drives, install Plex and call it a day is way too boring. Especially when there are so many good tools and services that integrate with Plex. And the ease of using all of them alongside unRAID is definitively a bonus. Tools I run on my server to make my Plexperiance better: Organizr Tautulli Sonarr Radarr Ombi Letsencrypt container Jackett Deluge Netdata Sub-Zero UptimeRobot Lidarr SabNZBd Grafana InfluxDB Telegraf Varken ApacheGuacamole The dashboard that shows all your running containers / VM's Most of these are Docker Containers from the guys over at linuxserver.io. Except Sub-Zero that is a Plex plugin and Uptimerobot that is an external downtime service. My latest obsession has been getting Organizr to work with Letsencrypt/nginx and implementing all my services into that. For someone who didn't know what a web server even was a month ago, it has been quite a steep learning curve.. But that's what it's all about. My next post will be about setting up the letsencrypt docker and all the other services I run on you own domain. Stay tuned. For any questions you can find me here: \u00b6 \u00b6","title":"My unRAID Server"},{"location":"blog/my-unraid-server/#my-unraid-server","text":"Since this blog will mostly be for my own sake. Just me writing down some guides on different things so I don't forget. I think it's appropriate that my first post will be about my server.. My current server exists mainly for serving myself and my familiy/friends plex content. Now since this is it's main purpose it is somewhat over powered.","title":"My unRAID Server"},{"location":"blog/my-unraid-server/#specs","text":"CPU: 2 x XEON E5-2670v1 - [16 cores / 32 threads @ 2.60 GHz/3.30 GHz ] CPU cooler: 2 x Noctua NH-U14S Motherboard: Supermicro X9DRL-iF RAM: Samsung ECC REG 64GB 8x8GB 1333mhz [M393B1K70DH0-YH9] PSU: Corsair RM850x 850W Case: Fractal Define R5 HDD's: 1 x Seagate Ironwolf 8TB [Parity drive] 2 x Seagate Ironwolf 4TB [Data drives] 4 x WD Red 4TB NAS Harddrive [Data drives] 2 x Crucial MX300 275GB SSD [Cache drives in RAID1] 1 x HyperX Fury 120GB 2.5\" SSD [Plex drive] OS drive: Kingston Datatraveler SE9 16GB USB drive Now up until Feb 2017 my server was my old i5-3570K gaming rig and a low power freenas setup, and because I wanted to lower the overall power usage so I bought all the equipment above to do exactly that.. Makes sense right? Not exactly.. \u00af (\u30c4) /\u00af Well.. after hanging out in the Plex Discord channel, things got a little overboard. Now, my server is not nearly as powerful as some people over at r/plex or r/homelab but with a 18K passmark score it can easily transcode up to 14 1080P streams on plex. Not that it will ever have to.. The server on my \"test bench\" with my old NAS, and yes I'm an Alien fan :)","title":"Specs:"},{"location":"blog/my-unraid-server/#os","text":"Should be no surprise, but if you haven't figured it out yet, I run all this on LimeTech's unRAID OS 6 And coming from windows it has mostly been an easy ride. Now why unRAID? Simply put; Docker.. Now there's more to unRAID than docker containers. A lot more. But I wanted an \"all in one package\" that I could easily manage and expand. And unRAID does just that. Before unRAID I was running my NAS on Freenas 9.10 Freenas is an awesome free storage OS that is great for both home and business use as it uses the ZFS filesystem. I won't go into detail what ZFS is why it's great, but my biggest gripe with Freenas was that the app support wasn't the greatest. For just a storage OS it worked great. The main page on the unRAID GUI","title":"OS:"},{"location":"blog/my-unraid-server/#use","text":"As I have stated, the main purpose of my server is to serve content via plex. But adding a couple of drives, install Plex and call it a day is way too boring. Especially when there are so many good tools and services that integrate with Plex. And the ease of using all of them alongside unRAID is definitively a bonus. Tools I run on my server to make my Plexperiance better: Organizr Tautulli Sonarr Radarr Ombi Letsencrypt container Jackett Deluge Netdata Sub-Zero UptimeRobot Lidarr SabNZBd Grafana InfluxDB Telegraf Varken ApacheGuacamole The dashboard that shows all your running containers / VM's Most of these are Docker Containers from the guys over at linuxserver.io. Except Sub-Zero that is a Plex plugin and Uptimerobot that is an external downtime service. My latest obsession has been getting Organizr to work with Letsencrypt/nginx and implementing all my services into that. For someone who didn't know what a web server even was a month ago, it has been quite a steep learning curve.. But that's what it's all about. My next post will be about setting up the letsencrypt docker and all the other services I run on you own domain. Stay tuned.","title":"Use"},{"location":"blog/my-unraid-server/#for-any-questions-you-can-find-me-here","text":"","title":"For any questions you can find me here:"},{"location":"blog/my-unraid-server/#_1","text":"","title":""},{"location":"blog/optimizing-php-fpm-to-get-faster-load-times-of-tabs-in-organizr/","text":"Optimizing PHP-FPM to get faster load times of tabs in Organizr \u00b6 For me this all started when I was setting up Logarr and opened the Organizr(v1) container php error log **/log/php/error.log** and saw that this error was repeating on an hourly basis: WARNING: [pool www] server reached pm.max_children setting (5), consider raising it[_timestamp_] This means that there are not enough PHP-FPM processes. In Organizr v2 I did not get this error in the php error log, but optimizing the child processes still got me faster load times of tabs in Organizr. Note that for this guide, it does not matter if you use Organizr V1 or V2. We need write-access to** /etc/php7/php-fpm.d/www.conf ** in order to optimize the following settings: pm pm.max_children pm.start_servers pm.min_spare_servers pm.max_spare_servers pm.max_requests Copying the www.conf file to /config/php \u00b6 We need to perform this step because the file must 'exist' before it can be mapped. First docker exec into your Organizr docker container. Assuming you are using a fairly new version of UnRaid, click your Organizr container icon and then click \"Console\". If not run docker exec -it [contrainername] bash in the console In the console window, run the command: cp /etc/php7/php-fpm.d/www.conf /config/php A copy of www.conf is now present in Organizr's php-folder. Linking the newly copied www.conf file to the original \u00b6 Create the following new path for your Organizr docker container in UnRaid: * Config Type: Path * Name: phpchildren * Container Path: /etc/php7/php-fpm.d/www.conf * Host Path: /mnt/cache/appdata/organizr-v2/php/www.conf * Access Mode: Read/Write * Description: Container Path: /etc/php7/php-fpm.d/www.conf The same is shown here: Calculate and change settings in www.conf \u00b6 Open the www.conf file with notepad++ or similar to edit the following values: pm \u00b6 **pm = dynamic** means that the number of servers specified in pm.start_servers will always be running in the PHP-FPM process, and more will be created if needed. pm = ondemand means that **pm.start_servers** is ignored and servers will be created if they are needed. Personally, I have decided to use the default** pm = dynamic ** because I have very much RAM compared how loaded my webserver is. If I always needed resources to be freed up, I would have chosen the ondemand setting. pm.max_children \u00b6 Open the terminal in UnRaid. Run the command ps -ylC php-fpm --sort:rss You will likely get a bunch of php-fpm processes like I do: The RSS column shows non-swapped physical memory usage by PHP-FPM processes in kilobytes. An appropriate value for pm.max_children can be calculated as: pm.max_children = Total RAM dedicated to the web server / Max child process size The max child process size for me is 19MB and my server-rig has 32GB of RAM. I decide that I want to use a maximum of, say, 20GB on PHP-FPM processes. Evaluating the formula with these values yields pm.max_children = 20000 / 19 = 1053 ~ 1000. Thus, Iset pm.max_children = 1000 . This is ridiculously high. But I have the RAM for it. For reference, in myshell's guide linked below, he concludes an appropriate pm.max_children = 72 with 8 GB ram installed, so the less RAM and more load you have on your server, the more important this calculation and setting becomes. pm.min_spare_servers \u00b6 Set pm.min_spare_servers = 1 pm.max_spare_servers \u00b6 An appropriate value for pm.max_spare_servers can be calculated as: pm.max_spare_servers = 2 x number of cores OR 4 x number of cores Personally I have 8 cores in my AMD Ryzen 1700 processor and start with using the 2x method. Evaluating the formula with these values yields pm.max_spare_servers = 2 x 8 = 16. Thus I set pm.max_spare_servers = 16 .But I could also try with pm.max_spare_servers = 32 and see if I get better performance with that. pm.start_servers \u00b6 An appropriate value for pm.start_servers can be calculated as: pm.start_servers = pm.max_spare_servers / 2 Evaluating this gives pm.start_servers = 16 / 2 = 8. Thus I set pm.start_servers = 8 . pm.max_requests \u00b6 Set pm.max_requests = 500 Concluding remarks \u00b6 Restart your Organizr docker container and enjoy an even faster Organizr experience. Of course YMMV , tweak the settings above to further optimize, as they depend very much on your server hardware, the PHP-FPM processes you are hosting, and the load on your webserver, i.e. the number of simultaneous users. Sources: https://myshell.co.uk/blog/2012/07/adjusting-child-processes-for-php-fpm-nginx/ https://ma.ttias.be/a-better-way-to-run-php-fpm/ https://stackoverflow.com/questions/25097179/warning-pool-www-seems-busy-you-may-need-to-increase-pm-start-servers-or-pm For any questions you can find me here: \u00b6 \u00b6","title":"Optimizing PHP-FPM to get faster load times of tabs in Organizr"},{"location":"blog/optimizing-php-fpm-to-get-faster-load-times-of-tabs-in-organizr/#optimizing-php-fpm-to-get-faster-load-times-of-tabs-in-organizr","text":"For me this all started when I was setting up Logarr and opened the Organizr(v1) container php error log **/log/php/error.log** and saw that this error was repeating on an hourly basis: WARNING: [pool www] server reached pm.max_children setting (5), consider raising it[_timestamp_] This means that there are not enough PHP-FPM processes. In Organizr v2 I did not get this error in the php error log, but optimizing the child processes still got me faster load times of tabs in Organizr. Note that for this guide, it does not matter if you use Organizr V1 or V2. We need write-access to** /etc/php7/php-fpm.d/www.conf ** in order to optimize the following settings: pm pm.max_children pm.start_servers pm.min_spare_servers pm.max_spare_servers pm.max_requests","title":"Optimizing PHP-FPM to get faster load times of tabs in Organizr"},{"location":"blog/optimizing-php-fpm-to-get-faster-load-times-of-tabs-in-organizr/#copying-the-wwwconf-file-to-configphp","text":"We need to perform this step because the file must 'exist' before it can be mapped. First docker exec into your Organizr docker container. Assuming you are using a fairly new version of UnRaid, click your Organizr container icon and then click \"Console\". If not run docker exec -it [contrainername] bash in the console In the console window, run the command: cp /etc/php7/php-fpm.d/www.conf /config/php A copy of www.conf is now present in Organizr's php-folder.","title":"Copying the www.conf file to /config/php"},{"location":"blog/optimizing-php-fpm-to-get-faster-load-times-of-tabs-in-organizr/#linking-the-newly-copied-wwwconf-file-to-the-original","text":"Create the following new path for your Organizr docker container in UnRaid: * Config Type: Path * Name: phpchildren * Container Path: /etc/php7/php-fpm.d/www.conf * Host Path: /mnt/cache/appdata/organizr-v2/php/www.conf * Access Mode: Read/Write * Description: Container Path: /etc/php7/php-fpm.d/www.conf The same is shown here:","title":"Linking the newly copied www.conf file to the original"},{"location":"blog/optimizing-php-fpm-to-get-faster-load-times-of-tabs-in-organizr/#calculate-and-change-settings-in-wwwconf","text":"Open the www.conf file with notepad++ or similar to edit the following values:","title":"Calculate and change settings in www.conf"},{"location":"blog/optimizing-php-fpm-to-get-faster-load-times-of-tabs-in-organizr/#pm","text":"**pm = dynamic** means that the number of servers specified in pm.start_servers will always be running in the PHP-FPM process, and more will be created if needed. pm = ondemand means that **pm.start_servers** is ignored and servers will be created if they are needed. Personally, I have decided to use the default** pm = dynamic ** because I have very much RAM compared how loaded my webserver is. If I always needed resources to be freed up, I would have chosen the ondemand setting.","title":"pm"},{"location":"blog/optimizing-php-fpm-to-get-faster-load-times-of-tabs-in-organizr/#pmmax_children","text":"Open the terminal in UnRaid. Run the command ps -ylC php-fpm --sort:rss You will likely get a bunch of php-fpm processes like I do: The RSS column shows non-swapped physical memory usage by PHP-FPM processes in kilobytes. An appropriate value for pm.max_children can be calculated as: pm.max_children = Total RAM dedicated to the web server / Max child process size The max child process size for me is 19MB and my server-rig has 32GB of RAM. I decide that I want to use a maximum of, say, 20GB on PHP-FPM processes. Evaluating the formula with these values yields pm.max_children = 20000 / 19 = 1053 ~ 1000. Thus, Iset pm.max_children = 1000 . This is ridiculously high. But I have the RAM for it. For reference, in myshell's guide linked below, he concludes an appropriate pm.max_children = 72 with 8 GB ram installed, so the less RAM and more load you have on your server, the more important this calculation and setting becomes.","title":"pm.max_children"},{"location":"blog/optimizing-php-fpm-to-get-faster-load-times-of-tabs-in-organizr/#pmmin_spare_servers","text":"Set pm.min_spare_servers = 1","title":"pm.min_spare_servers"},{"location":"blog/optimizing-php-fpm-to-get-faster-load-times-of-tabs-in-organizr/#pmmax_spare_servers","text":"An appropriate value for pm.max_spare_servers can be calculated as: pm.max_spare_servers = 2 x number of cores OR 4 x number of cores Personally I have 8 cores in my AMD Ryzen 1700 processor and start with using the 2x method. Evaluating the formula with these values yields pm.max_spare_servers = 2 x 8 = 16. Thus I set pm.max_spare_servers = 16 .But I could also try with pm.max_spare_servers = 32 and see if I get better performance with that.","title":"pm.max_spare_servers"},{"location":"blog/optimizing-php-fpm-to-get-faster-load-times-of-tabs-in-organizr/#pmstart_servers","text":"An appropriate value for pm.start_servers can be calculated as: pm.start_servers = pm.max_spare_servers / 2 Evaluating this gives pm.start_servers = 16 / 2 = 8. Thus I set pm.start_servers = 8 .","title":"pm.start_servers"},{"location":"blog/optimizing-php-fpm-to-get-faster-load-times-of-tabs-in-organizr/#pmmax_requests","text":"Set pm.max_requests = 500","title":"pm.max_requests"},{"location":"blog/optimizing-php-fpm-to-get-faster-load-times-of-tabs-in-organizr/#concluding-remarks","text":"Restart your Organizr docker container and enjoy an even faster Organizr experience. Of course YMMV , tweak the settings above to further optimize, as they depend very much on your server hardware, the PHP-FPM processes you are hosting, and the load on your webserver, i.e. the number of simultaneous users. Sources: https://myshell.co.uk/blog/2012/07/adjusting-child-processes-for-php-fpm-nginx/ https://ma.ttias.be/a-better-way-to-run-php-fpm/ https://stackoverflow.com/questions/25097179/warning-pool-www-seems-busy-you-may-need-to-increase-pm-start-servers-or-pm","title":"Concluding remarks"},{"location":"blog/optimizing-php-fpm-to-get-faster-load-times-of-tabs-in-organizr/#for-any-questions-you-can-find-me-here","text":"","title":"For any questions you can find me here:"},{"location":"blog/optimizing-php-fpm-to-get-faster-load-times-of-tabs-in-organizr/#_1","text":"","title":""},{"location":"blog/redirecting-visitors-to-a-403-forbidden-page-when-accessing-the-wordpress-admin-page/","text":"Redirecting visitors to a 403 forbidden page when accessing the Wordpress admin page \u00b6 So after my last post I woke up to around 40+ and counting notifications on IP's that fail2ban had banned over the night. They were all failed attempts to get past the basic auth prompt I have on my Wordpress admin page. So with the last post fresh in my mind I knew it was possible to have a Cloudflare worker load a different page for visitors based on their IP. This was my fail2ban channel on discord. If you want these kind of notifications check out my fail2ban post! So using the same resource as in the first Cloudflare worker post we can easily route visitors to a custom 403 Forbidden page. Now they can't even try to get passed the basic auth! Have a look here: https://technicalramblings.com/wp-admin eckosc\\_status\\_message title=\"Note\" icon=\"fa-exclamation-circle\" type=\"info\" message=\"If you have a dynamic ip that often changes, this might not be the best solution for you!\" eckosc\\_status\\_message title=\"Note\" icon=\"fa-exclamation-circle\" type=\"info\" message=\"If you have a dynamic ip that often changes, this might not be the best solution for you!\" Creating a worker \u00b6 On your Cloudflare dashboard click on Workers and go through the first time setup if you haven't done that yet. Next click on Manage Workers and Create a Worker Paste the script below. addEventListener(\"fetch\", event => { event.respondWith(fetchAndReplace(event.request)); }); async function fetchAndReplace(request) { let modifiedHeaders = new Headers(); modifiedHeaders.set('Content-Type', 'text/html'); modifiedHeaders.append('Pragma', 'no-cache'); //Return 403 page if you're not calling from a trusted IP const white_list = [ '1.1.1.1', '2.2.2.2' ]; if (white_list.indexOf(request.headers.get(\"cf-connecting-ip\")) > -1) //Fire all other requests directly to your WebServer return fetch(request); else { // Return modified response. return new Response(forbiddenPage, { headers: modifiedHeaders }); } } let forbiddenPage = ` <!DOCTYPE html> <title>nope...</title> <style> @import url('https://fonts.googleapis.com/css?family=Press+Start+2P'); html,body{ width: 100%; height: 100%; margin: 0; } *{ font-family: 'Press Start 2P', cursive; box-sizing: border-box; } #app{ padding: 1rem; background: black; display: flex; height: 100%; justify-content: center; align-items: center; color: #54FE55; text-shadow: 0px 0px 10px ; font-size: 6rem; flex-direction: column; .txt { font-size: 1.8rem; } } @keyframes blink { 0% {opacity: 0} 49% {opacity: 0} 50% {opacity: 1} 100% {opacity: 1} } .blink { animation-name: blink; animation-duration: 1s; animation-iteration-count: infinite; } </style> <body> <div id=\"app\"> <div>403</div> <div class=\"txt\"> Forbidden<span class=\"blink\">_</span> </div> </div> </body> `; Add your whitelisted IP's in this section: //Return 403 page if you're not calling from a trusted IP const white_list = [ '1.2.3.4', '5.6.7.8' ]; Save and deploy the worker. Go back to the main worker page and add your routes. The two routes I use are domain.com/wp-login* and domain.com/wp-admin* The page should now look like this when accessing from another IP than the white listed ones. eckosc\\_full\\_width\\_block eckosc\\_full\\_width\\_block /eckosc\\_full\\_width\\_block /eckosc\\_full\\_width\\_block Neat right! If you want a different page showing it's as simple as replacing the html. I just googled 403 forbidden template and found the one above on codepen. If you need any extra help join the Discord server! \u00b6 \u00b6 Source: https://codepen.io/lsgrrd/pen/BObbYY https://www.resdevops.com/2018/03/20/cloudflare-workers-maintenance-mode-static-page/","title":"Redirecting visitors to a 403 forbidden page when accessing the WordPress admin page"},{"location":"blog/redirecting-visitors-to-a-403-forbidden-page-when-accessing-the-wordpress-admin-page/#redirecting-visitors-to-a-403-forbidden-page-when-accessing-the-wordpress-admin-page","text":"So after my last post I woke up to around 40+ and counting notifications on IP's that fail2ban had banned over the night. They were all failed attempts to get past the basic auth prompt I have on my Wordpress admin page. So with the last post fresh in my mind I knew it was possible to have a Cloudflare worker load a different page for visitors based on their IP. This was my fail2ban channel on discord. If you want these kind of notifications check out my fail2ban post! So using the same resource as in the first Cloudflare worker post we can easily route visitors to a custom 403 Forbidden page. Now they can't even try to get passed the basic auth! Have a look here: https://technicalramblings.com/wp-admin eckosc\\_status\\_message title=\"Note\" icon=\"fa-exclamation-circle\" type=\"info\" message=\"If you have a dynamic ip that often changes, this might not be the best solution for you!\" eckosc\\_status\\_message title=\"Note\" icon=\"fa-exclamation-circle\" type=\"info\" message=\"If you have a dynamic ip that often changes, this might not be the best solution for you!\"","title":"Redirecting visitors to a 403 forbidden page when accessing the Wordpress admin page"},{"location":"blog/redirecting-visitors-to-a-403-forbidden-page-when-accessing-the-wordpress-admin-page/#creating-a-worker","text":"On your Cloudflare dashboard click on Workers and go through the first time setup if you haven't done that yet. Next click on Manage Workers and Create a Worker Paste the script below. addEventListener(\"fetch\", event => { event.respondWith(fetchAndReplace(event.request)); }); async function fetchAndReplace(request) { let modifiedHeaders = new Headers(); modifiedHeaders.set('Content-Type', 'text/html'); modifiedHeaders.append('Pragma', 'no-cache'); //Return 403 page if you're not calling from a trusted IP const white_list = [ '1.1.1.1', '2.2.2.2' ]; if (white_list.indexOf(request.headers.get(\"cf-connecting-ip\")) > -1) //Fire all other requests directly to your WebServer return fetch(request); else { // Return modified response. return new Response(forbiddenPage, { headers: modifiedHeaders }); } } let forbiddenPage = ` <!DOCTYPE html> <title>nope...</title> <style> @import url('https://fonts.googleapis.com/css?family=Press+Start+2P'); html,body{ width: 100%; height: 100%; margin: 0; } *{ font-family: 'Press Start 2P', cursive; box-sizing: border-box; } #app{ padding: 1rem; background: black; display: flex; height: 100%; justify-content: center; align-items: center; color: #54FE55; text-shadow: 0px 0px 10px ; font-size: 6rem; flex-direction: column; .txt { font-size: 1.8rem; } } @keyframes blink { 0% {opacity: 0} 49% {opacity: 0} 50% {opacity: 1} 100% {opacity: 1} } .blink { animation-name: blink; animation-duration: 1s; animation-iteration-count: infinite; } </style> <body> <div id=\"app\"> <div>403</div> <div class=\"txt\"> Forbidden<span class=\"blink\">_</span> </div> </div> </body> `; Add your whitelisted IP's in this section: //Return 403 page if you're not calling from a trusted IP const white_list = [ '1.2.3.4', '5.6.7.8' ]; Save and deploy the worker. Go back to the main worker page and add your routes. The two routes I use are domain.com/wp-login* and domain.com/wp-admin* The page should now look like this when accessing from another IP than the white listed ones. eckosc\\_full\\_width\\_block eckosc\\_full\\_width\\_block /eckosc\\_full\\_width\\_block /eckosc\\_full\\_width\\_block Neat right! If you want a different page showing it's as simple as replacing the html. I just googled 403 forbidden template and found the one above on codepen.","title":"Creating a worker"},{"location":"blog/redirecting-visitors-to-a-403-forbidden-page-when-accessing-the-wordpress-admin-page/#if-you-need-any-extra-help-join-the-discord-server","text":"","title":"If you need any extra help join the Discord server!"},{"location":"blog/redirecting-visitors-to-a-403-forbidden-page-when-accessing-the-wordpress-admin-page/#_1","text":"Source: https://codepen.io/lsgrrd/pen/BObbYY https://www.resdevops.com/2018/03/20/cloudflare-workers-maintenance-mode-static-page/","title":""},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/","text":"Remotely accessing the Unraid GUI with Guacamole and VNC Web Browser \u00b6 So.. you've finished installing and setting up all your docker containers, plugins ect. Radarr is doing its thing, Plex is chugging away... everything is just peachy! And now you want to be able to access the unraid GUI outside your network. The safest method you can do this is by setting up a VPN . You can do that by installing the OpenVPN container but that won't give you access if your server or the docker service crashes. So setting up the VPN on the router ect is much more recommended . BUT you're not always in a situation where you can connect to a VPN. For example your work computer. Be it you don't have the administrator rights to change your network settings or your company policy forbids it.. This is where Apache Guacamole is useful. By installing Apache Guacamole, centos-xfce-vncFirefox vnc and letsencrypt we can gain access to the unraid GUI externally. And by setting up fail2ban and geo-block we can protect our self from bruteforce attempts at gaining access! Installation \u00b6 \u00b6 Apache Guacamole \u00b6 I use the jasonbean/guacamole container. Nothing special you need to think about. Add your custom port and select your appdata location. The defaultusername and password is**guacadmin Note:** It isn't mentioned in the documentation but if you are installing the container using docker run or compose you need to add -e 'OPT_MYSQL'='Y' Firefox VNC Web Browser \u00b6 Search for **VNC Web Browser** in community applications and you will find a template bycheesemarathon for the consol/centos-xfce-vnc container. I have found that using the VNC Web Browser Container gives me constant connection errors and have switched to the Firefox container (jlesage/firefox) instead. Install the container and add your**VNC Password** if you want. Take note of the VNC port as you will need that later. Use the**VNC_PASSWORD** variable described here Do not add SSL in the container settings as it looks like Guacamole doesn't support VNC with encryption. \u00b6 Let's Encrypt \u00b6 To access all this we' ll use the linuxserver/letsencrypt container from linuxserver. This container sets up an Nginx web serverand reverse proxy with php support and a built-in letsencrypt client that automates free SSL server certificate generation and renewal processes. It also contains fail2ban for intrusion prevention. Before we start you need to acquire a domain. You can do that on duckdns or any other domain service.I\u2019m using https://domains.google/ and I\u2019m very happy with that. If you have a dynamic ip-address you can setup the captinsano DDclient container and have that update your synthetic record . If you don't want to pay for a custom domain, using the duckdns container will work just fine. Forward your domain to your public IP address. After you've done that add your different ANAME/CNAME records e.g guacamole.yourdomain.com or unraid.yourdomain.com @ = root domain (technicalramblings.com) and points to my external ip www = sub domain grafana = sub domain TTL: (Time to Live) How often a copy of the record stored in cache must be updated or discarded. Installation \u00b6 Container Port: 80 - Choose your desired host port. e.g**81** (You can't set this to 80 as the unRAID web GUI uses that. ) Container Port: 443 -Set this to 444 or something else (On update 6.4 unraid will use port 443 if you setup https and it\u2019s better to be ahead of time so it won\u2019t cause any issues) Enter you email Add your domain e.g yourdomain.com Add your different sub domains e.g **guacamole,guac** ect Validation: Select your validation type. http will work in most cases (Unless your ISP blocks port 80) _Container Path: /config_Install the container config to your desired location. I recommend using an SSD. Next is port forwarding . This is done on your router and you need to forward port**80** and 443 to the ports you chose in step 1 and 2. So if your servers IP is 192.168.1.2 and you have chosen that the container is on port 81, you need to forward all traffic on port 80 to port 81 on IP 192.168.1.2 And do the same for port 443 to 444. If you're unsure how to do this on your router check out: Portforward.com Next go to https://yourserverip:444 or http://yourserverip:81 If you now see the Nginx welcome page, it works. Also test if yourdomain.com redirects you to the nginx welcome page. Note: TTL **differs from each provider, some has a minimum 60 minutes before DNS propagates and others have 1 minute. So it might take a while before ** https://yourdomain.com works. Configuring Apache Guacamole \u00b6 Browse to the Apache guacamole container and login.You can add a new admin user if you want. The default username and password is guacadmin Go to Settings and click on Connections Click on New Connection Give the connection a name. I just called it Firefox. And Location is ROOT and Protocol is VNC Set your Maximum number of connections, I use 3 Scroll down to Parameters - Network. Add your Hostname: Your Unraid IP Add your Port: This is the VNC port to the **Firefox** container (default is 7914) For Authentication input the password you set for the **Firefox** container. Click Save You can now test the connection you have created. Click on your user name and select the connection. You should now be presented with the desktop of the VNC Web Browser container. Tip: If you want to go back to settings just press ctrl + shift + alt to open the side menu. Here you can also copy text that you have copied within the VNC connection! Here you can open Firefox and go to your unraid IP and log in. Windows 10 VM with RDP \u00b6 You can also easily add your Windows VM using RDP, this will also let you mount your shares so you can manage your files like you would at home. This is how I added my Windows 10 Pro VM: The 3389 port is the RDP port. \u00b6 Configuring Nginx \u00b6 Go to your letsencrypt appdata location. Find the nginx folder and then edit the file called default or add a new **.conf** file in the site-conf folder. I recommend using notepad++ If you want to use this on a subdomain I recommend creating a **guacamole.conf** file instead and adding the nginx config to that. Below is an nginx config that will giveyou A+ ratings on securityheaders.io and ssllabs.com **server_name guacamole.domain.com;** This is where you will add your domain name e.g guacamole.duckdns.org proxy_pass http://192.168.1.34:8089/; **This is your IP and port to the**Apache Guacamole container READ THE COMMENT ON add_header X-Frame-Options AND add_header Content-Security-Policy IF YOU USE THIS ON A SUBDOMAIN YOU WANT TO IFRAME! # GUACAMOLE CONTAINER server { listen 80; server_name guacamole.domain.com; return 301 https://$server_name$request_uri; } server { listen 443 ssl http2; server_name guacamole.domain.com; ##SSL SETTINGS ## READ THE COMMENT ON add_header X-Frame-Options AND add_header Content-Security-Policy IF YOU USE THIS ON A SUBDOMAIN YOU WANT TO IFRAME! ## Certificates from LE container placement ssl_certificate /config/keys/letsencrypt/fullchain.pem; ssl_certificate_key /config/keys/letsencrypt/privkey.pem; ## Strong Security recommended settings per cipherli.st ssl_dhparam /config/nginx/dhparams.pem; # Bit value: 4096 ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA384; ssl_ecdh_curve secp384r1; # Requires nginx >= 1.1.0 ssl_session_timeout 10m; ## NOTE: The add_header Content-Security-Policy won't work with duckdns since you don't own the root domain. Just buy a domain. It's cheap ## Settings to add strong security profile (A+ on securityheaders.io/ssllabs.com) add_header Strict-Transport-Security \"max-age=63072000; includeSubDomains; preload\"; add_header X-Content-Type-Options nosniff; add_header X-XSS-Protection \"1; mode=block\"; add_header X-Robots-Tag none; #SET THIS TO index IF YOU WANT GOOGLE TO INDEX YOU SITE! add_header Content-Security-Policy \"frame-ancestors https://*.DOMAIN.COM https://DOMAIN.COM https://$server_name\"; #Add your domains you want to enable iframing on add_header X-Frame-Options \"allow-from https://DOMAIN.COM https://$server_name\"; #Add your domains you want to enable iframing on. https://$server_name = sub.domain.com in this server block add_header Referrer-Policy \"strict-origin-when-cross-origin\"; add_header Feature-Policy \"geolocation none;midi none;notifications none;push none;sync-xhr none;microphone none;camera none;magnetometer none;gyroscope none;speaker self;vibrate none;fullscreen self;payment none;\"; #FEATURE POLICY: READ MORE HERE: https://scotthelme.co.uk/a-new-security-header-feature-policy/ proxy_cookie_path / \"/; HTTPOnly; Secure\"; ##NOTE: This may cause issues with unifi. Remove HTTPOnly; or create another ssl config for unifi. more_set_headers \"Server: Classified\"; more_clear_headers 'X-Powered-By'; ##END SSL SETTINGS location / { proxy_pass http://192.168.1.34:8089/; proxy_buffering off; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $http_connection; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_http_version 1.1; proxy_no_cache $cookie_session; } } \u00b6 Configuring fail2ban \u00b6 From github: Fail2Ban scans log files like **/var/log/auth.log** and bans IP addresses conducting too many failed login attempts. It does this by updating system firewall rules to reject new connections from those IP addresses, for a configurable amount of time. Fail2Ban comes out-of-the-box ready to read many standard log files, such as those for sshd and Apache, and is easily configured to read any log file of your choosing, for any error you wish. Luckily Fail2ban comes preinstalled with your letsencrypt container, so you only need to add the filter and edit the jail.local file! For this to work we need the letsencrypt container to be able to see the catalina.out **file in the **Apache Guacamole container. Open the letsencrypt container settings. Add a path from the letsencrypt container to the Apache Guacamole container. Name: guacamole fail2ban Container path: /guacamole or whatever you prefer Host path: Your path to the**Apache Guacamole /log ** folder e.g **/AppData/ApacheGuacamole/log/tomcat8** Access mode: Read only Description: fail2ban path intoguacamole /log folder jail.local \u00b6 Go to thefail2ban folder inside the letsencrypt appdata folder and edit the jail.local file. For my config I have set the bantime to 86400 seconds (24h) The findtime is 600 seconds and maxretry is 3 At the end of the jail.local file add the following: [guacamole-auth] enabled = true port = http,https filter = guacamole-auth logpath = /guacamole/catalina.out ignoreip = 192.168.1.0/24 The ignore IP is so that fail2ban won\u2019t ban your local IP. Check out https://www.aelius.com/njh/subnet_sheet.html if you are wondering what your** CIDRnotation is. Most often it will be /24**(netmask 255.255.255.0) To find your netmask run **ipconfig /all** on windows or** ifconfig | grep netmask **on linux. The logpath is the container path you created in step 2. And catalina.out the Guacamole log. Now, there is already a filter(guacamole.conf) for Guacamole in the **filter.d** folder inside the fail2ban folder. But that filter won't work unless we make a change to it. Copy the guacamole.conf file and rename it guacamole-auth.conf In the **guacamole-auth.conf** file change: failregex = ^.*\\nWARNING: Authentication attempt from for user \"[^\"]*\" failed\\.$ to failregex = \\bAuthentication attempt from \\[ (?:,.*)?\\] for user \".*\" failed\\. Restart the letsencrypt container. If you get the error below in the fail2ban.log file you can comment the 3 date pattern lines in the guacamole-auth.conf file. 2018-06-12 21:36:49,121 fail2ban.filter [351]: ERROR Error during seek to start time in \"/guacamole/catalina.out\" 2018-06-12 21:36:49,121 fail2ban.filterpoll [351]: ERROR Caught unhandled exception in main cycle: TypeError('an integer is required',) Comment these lines by adding # in front. datepattern = ^%%b %%d, %%ExY %%I:%%M:%%S %%p \u00b6 ^WARNING:()** \u00b6 {^LN-BEG} \u00b6 Remember to restart the container anytime you make a change in the conf file. Banned \u00b6 The fail2ban.log file should output something like this: 2018-06-12 21:39:07,529 fail2ban.jail [350]: INFO Jail 'guacamole-auth' started 2018-06-12 21:39:30,779 fail2ban.filter [350]: INFO [guacamole-auth] Ignore 192.168.1.1 by ip 2018-06-12 21:39:44,801 fail2ban.filter [350]: INFO [guacamole-auth] Found 77.16.72.179 - 2018-06-12 21:39:44 2018-06-12 21:39:57,420 fail2ban.filter [350]: INFO [guacamole-auth] Found 77.16.72.179 - 2018-06-12 21:39:57 2018-06-12 21:40:00,025 fail2ban.filter [350]: INFO [guacamole-auth] Found 77.16.72.179 - 2018-06-12 21:39:59 2018-06-12 21:40:00,196 fail2ban.actions [350]: NOTICE [guacamole-auth] Ban 77.16.72.179 Unbanning \u00b6 If you managed to ban yourself or a friend banned themself you can do this to unban. Bash into the container with: **docker exec -it letsencrypt bash** Enter fail2ban interactive mode: **fail2ban-client -i** Check the status of the jail: **status guacamole-auth** Output fail2ban> status guacamole-auth Status for the jail: guacamole-auth |- Filter | |- Currently failed: 0 | |- Total failed: 3 | `- File list: /guacamole/catalina.out `- Actions |- Currently banned: 1 |- Total banned: 1 `- Banned IP list: 77.16.72.179 unban with: set guacamole-auth unbanip 77.16.72.179 If you already know the IP you want to unban you can just type this: docker exec -it letsencrypt fail2ban-client set guacamole-auth unbanip 77.16.72.179 Adding geo-blocking \u00b6 Purpose \u00b6 Restrict access based on the user's geographical location Installation \u00b6 If you are using the letsencrypt container the nginx module is already installed. If not you can take a look at the howtoforge guide. That said the container doesn't come with the GeoIP database. The database can be found here: https://dev.maxmind.com/geoip/geoip2/geolite2/ and its the country database we'll be using for this guide. Download the database and extract the .mmdb file to the folder of you choice. I'll be using /config/geolite2/ for my setup. NGINX \u00b6 In your**nginx.conf** file add the following in the ** http { **block geoip2 /config/geolite2/GeoLite2-Country.mmdb { auto_reload 1d; $geoip2_data_country_code country iso_code; } # LOCAL IP ALLOW GEO BLOCK geo $lan-ip { default no; 192.168.1.0/24 yes; } # GEO IP BLOCK SITE 1 map $geoip2_data_country_code $allowed_country { default no; <YOUR-COUNTRY-CODE> yes; # e.g US for United States } Instead of \"YOUR-COUNTRY-CODE\" **add your own country code from ** this list. This will block all other countries than the one you choose. You can also add more than one country if you want. US yes; CA yes; GB yes; The** geo $lan-ip ** is for allowing you to access the domain on your LAN. Check out https://www.aelius.com/njh/subnet_sheet.html if you are wondering what your CIDRnotation is. Most often it will be /24 (netmask 255.255.255.0) To find your netmask run **ipconfig /all** on windows or** ifconfig | grep netmask ** on linux. Note: The** geo $lan-ip part is only needed if you set default to no ** For it to actually block you need to add this in your server block : # LOCAL IP ALLOW GEO BLOCK if ($lan-ip = yes) { set $allowed_country yes; } # COUNTRY GEO BLOCK if ($allowed_country = no) { return 444; } So if you created a guacamole.conf file in the nginx/site-confs folder you add it there. It will then look like this: # GUACAMOLE CONTAINER server { listen 80; server_name guacamole.domain.com; return 301 https://$server_name$request_uri; } server { listen 443 ssl http2; server_name guacamole.domain.com; ##GEOBLOCK # LOCAL IP ALLOW GEO BLOCK if ($lan-ip = yes) { set $allowed_country yes; } # COUNTRY GEO BLOCK if ($allowed_country = no) { return 444; } ##SSL SETTINGS ## READ THE COMMENT ON add_header X-Frame-Options AND add_header Content-Security-Policy IF YOU USE THIS ON A SUBDOMAIN YOU WANT TO IFRAME! ## Certificates from LE container placement ssl_certificate /config/keys/letsencrypt/fullchain.pem; ssl_certificate_key /config/keys/letsencrypt/privkey.pem; ## Strong Security recommended settings per cipherli.st ssl_dhparam /config/nginx/dhparams.pem; # Bit value: 4096 ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA384; ssl_ecdh_curve secp384r1; # Requires nginx >= 1.1.0 ssl_session_timeout 10m; ## NOTE: The add_header Content-Security-Policy won't work with duckdns since you don't own the root domain. Just buy a domain. It's cheap ## Settings to add strong security profile (A+ on securityheaders.io/ssllabs.com) add_header Strict-Transport-Security \"max-age=63072000; includeSubDomains; preload\"; add_header X-Content-Type-Options nosniff; add_header X-XSS-Protection \"1; mode=block\"; add_header X-Robots-Tag none; #SET THIS TO index IF YOU WANT GOOGLE TO INDEX YOU SITE! add_header Content-Security-Policy \"frame-ancestors https://*.$server_name https://$server_name\"; ## Use *.domain.com, not *.sub.domain.com (*.$server_name) when using this on a sub-domain that you want to iframe! add_header X-Frame-Options \"ALLOW-FROM https://*.$server_name\" always; ## Use *.domain.com, not *.sub.domain.com (*.$server_name) when using this on a sub-domain that you want to iframe! add_header Referrer-Policy \"strict-origin-when-cross-origin\"; proxy_cookie_path / \"/; HTTPOnly; Secure\"; ##NOTE: This may cause issues with unifi. Remove HTTPOnly; or create another ssl config for unifi. more_set_headers \"Server: Classified\"; more_clear_headers 'X-Powered-By'; ##END SSL SETTINGS location / { proxy_pass http://192.168.1.34:8089/; proxy_buffering off; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $http_connection; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_http_version 1.1; proxy_no_cache $cookie_session; } } Blocked \u00b6 You can test if it worked with a VPN or do a performance test from a location that is blocked here https://www.webpagetest.org/ Optional: Organizr \u00b6 Another security layer is using Organizr to block access to your guacamole.domain.com by having you to log into Organizr first! And you can even add a fail2ban filter on the Organizr login form! By using server authentication you will be shown a 401 Unauthorized page unless you log in first. [embed] https://technicalramblings.com/blog/fail2ban-with-organizr-and-let-sencrypt/ [/embed] Optional: Basic http auth \u00b6 Another security layer is using basic http auth . Linuxservers letsencrypt container is already be pre configured to ban failed http auths with fail2ban! <br /> <span data-mce-type=\"bookmark\" style=\"display: inline-block; width: 0px; overflow: hidden; line-height: 0;\" class=\"mce_SELRES_start\">\ufeff</span><!--//--><![CDATA[//><!-- !function(a,b){\"use strict\";function c(){if(!e){e=!0;var a,c,d,f,g=-1!==navigator.appVersion.indexOf(\"MSIE 10\"),h=!!navigator.userAgent.match(/Trident.*rv:11\\./),i=b.querySelectorAll(\"iframe.wp-embedded-content\");for(c=0;c<i.length;c++){if(d=i[c],!d.getAttribute(\"data-secret\"))f=Math.random().toString(36).substr(2,10),d.src+=\"#?secret=\"+f,d.setAttribute(\"data-secret\",f);if(g||h)a=d.cloneNode(!0),a.removeAttribute(\"security\"),d.parentNode.replaceChild(a,d)}}}var d=!1,e=!1;if(b.querySelector)if(a.addEventListener)d=!0;if(a.wp=a.wp||{},!a.wp.receiveEmbedMessage)if(a.wp.receiveEmbedMessage=function(c){var d=c.data;if(d.secret||d.message||d.value)if(!/[^a-zA-Z0-9]/.test(d.secret)){var e,f,g,h,i,j=b.querySelectorAll('iframe[data-secret=\"'+d.secret+'\"]'),k=b.querySelectorAll('blockquote[data-secret=\"'+d.secret+'\"]');for(e=0;e<k.length;e++)k[e].style.display=\"none\";for(e=0;e<j.length;e++)if(f=j[e],c.source===f.contentWindow){if(f.removeAttribute(\"style\"),\"height\"===d.message){if(g=parseInt(d.value,10),g><span data-mce-type=\"bookmark\" style=\"display: inline-block; width: 0px; overflow: hidden; line-height: 0;\" class=\"mce_SELRES_start\">\ufeff</span>1e3)g=1e3;else if(~~g<200)g=200;f.height=g}if(\"link\"===d.message)if(h=b.createElement(\"a\"),i=b.createElement(\"a\"),h.href=f.getAttribute(\"src\"),i.href=d.value,i.host===h.host)if(b.activeElement===f)a.top.location.href=d.value}else;}},d)a.addEventListener(\"message\",a.wp.receiveEmbedMessage,!1),b.addEventListener(\"DOMContentLoaded\",c,!1),a.addEventListener(\"load\",c,!1)}(window,document); //--><!]]><br /><span data-mce-type=\"bookmark\" style=\"display: inline-block; width: 0px; overflow: hidden; line-height: 0;\" class=\"mce_SELRES_end\">\ufeff</span> Sources: https://github.com/fail2ban/fail2ban/issues/1574 For any questions you can find me here: \u00b6 \u00b6","title":"Remotely accessing the Unraid GUI with Guacamole and VNC Web Browser"},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser","text":"So.. you've finished installing and setting up all your docker containers, plugins ect. Radarr is doing its thing, Plex is chugging away... everything is just peachy! And now you want to be able to access the unraid GUI outside your network. The safest method you can do this is by setting up a VPN . You can do that by installing the OpenVPN container but that won't give you access if your server or the docker service crashes. So setting up the VPN on the router ect is much more recommended . BUT you're not always in a situation where you can connect to a VPN. For example your work computer. Be it you don't have the administrator rights to change your network settings or your company policy forbids it.. This is where Apache Guacamole is useful. By installing Apache Guacamole, centos-xfce-vncFirefox vnc and letsencrypt we can gain access to the unraid GUI externally. And by setting up fail2ban and geo-block we can protect our self from bruteforce attempts at gaining access!","title":"Remotely accessing the Unraid GUI with Guacamole and VNC Web Browser"},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#installation","text":"","title":"Installation"},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#_1","text":"","title":""},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#apache-guacamole","text":"I use the jasonbean/guacamole container. Nothing special you need to think about. Add your custom port and select your appdata location. The defaultusername and password is**guacadmin Note:** It isn't mentioned in the documentation but if you are installing the container using docker run or compose you need to add -e 'OPT_MYSQL'='Y'","title":"Apache Guacamole"},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#firefox-vnc-web-browser","text":"Search for **VNC Web Browser** in community applications and you will find a template bycheesemarathon for the consol/centos-xfce-vnc container. I have found that using the VNC Web Browser Container gives me constant connection errors and have switched to the Firefox container (jlesage/firefox) instead. Install the container and add your**VNC Password** if you want. Take note of the VNC port as you will need that later. Use the**VNC_PASSWORD** variable described here Do not add SSL in the container settings as it looks like Guacamole doesn't support VNC with encryption.","title":"Firefox VNC Web Browser"},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#_2","text":"","title":""},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#lets-encrypt","text":"To access all this we' ll use the linuxserver/letsencrypt container from linuxserver. This container sets up an Nginx web serverand reverse proxy with php support and a built-in letsencrypt client that automates free SSL server certificate generation and renewal processes. It also contains fail2ban for intrusion prevention. Before we start you need to acquire a domain. You can do that on duckdns or any other domain service.I\u2019m using https://domains.google/ and I\u2019m very happy with that. If you have a dynamic ip-address you can setup the captinsano DDclient container and have that update your synthetic record . If you don't want to pay for a custom domain, using the duckdns container will work just fine. Forward your domain to your public IP address. After you've done that add your different ANAME/CNAME records e.g guacamole.yourdomain.com or unraid.yourdomain.com @ = root domain (technicalramblings.com) and points to my external ip www = sub domain grafana = sub domain TTL: (Time to Live) How often a copy of the record stored in cache must be updated or discarded.","title":"Let's Encrypt"},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#installation_1","text":"Container Port: 80 - Choose your desired host port. e.g**81** (You can't set this to 80 as the unRAID web GUI uses that. ) Container Port: 443 -Set this to 444 or something else (On update 6.4 unraid will use port 443 if you setup https and it\u2019s better to be ahead of time so it won\u2019t cause any issues) Enter you email Add your domain e.g yourdomain.com Add your different sub domains e.g **guacamole,guac** ect Validation: Select your validation type. http will work in most cases (Unless your ISP blocks port 80) _Container Path: /config_Install the container config to your desired location. I recommend using an SSD. Next is port forwarding . This is done on your router and you need to forward port**80** and 443 to the ports you chose in step 1 and 2. So if your servers IP is 192.168.1.2 and you have chosen that the container is on port 81, you need to forward all traffic on port 80 to port 81 on IP 192.168.1.2 And do the same for port 443 to 444. If you're unsure how to do this on your router check out: Portforward.com Next go to https://yourserverip:444 or http://yourserverip:81 If you now see the Nginx welcome page, it works. Also test if yourdomain.com redirects you to the nginx welcome page. Note: TTL **differs from each provider, some has a minimum 60 minutes before DNS propagates and others have 1 minute. So it might take a while before ** https://yourdomain.com works.","title":"Installation"},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#configuring-apache-guacamole","text":"Browse to the Apache guacamole container and login.You can add a new admin user if you want. The default username and password is guacadmin Go to Settings and click on Connections Click on New Connection Give the connection a name. I just called it Firefox. And Location is ROOT and Protocol is VNC Set your Maximum number of connections, I use 3 Scroll down to Parameters - Network. Add your Hostname: Your Unraid IP Add your Port: This is the VNC port to the **Firefox** container (default is 7914) For Authentication input the password you set for the **Firefox** container. Click Save You can now test the connection you have created. Click on your user name and select the connection. You should now be presented with the desktop of the VNC Web Browser container. Tip: If you want to go back to settings just press ctrl + shift + alt to open the side menu. Here you can also copy text that you have copied within the VNC connection! Here you can open Firefox and go to your unraid IP and log in.","title":"Configuring Apache Guacamole"},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#windows-10-vm-with-rdp","text":"You can also easily add your Windows VM using RDP, this will also let you mount your shares so you can manage your files like you would at home. This is how I added my Windows 10 Pro VM: The 3389 port is the RDP port.","title":"Windows 10 VM with RDP"},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#_3","text":"","title":""},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#configuring-nginx","text":"Go to your letsencrypt appdata location. Find the nginx folder and then edit the file called default or add a new **.conf** file in the site-conf folder. I recommend using notepad++ If you want to use this on a subdomain I recommend creating a **guacamole.conf** file instead and adding the nginx config to that. Below is an nginx config that will giveyou A+ ratings on securityheaders.io and ssllabs.com **server_name guacamole.domain.com;** This is where you will add your domain name e.g guacamole.duckdns.org proxy_pass http://192.168.1.34:8089/; **This is your IP and port to the**Apache Guacamole container READ THE COMMENT ON add_header X-Frame-Options AND add_header Content-Security-Policy IF YOU USE THIS ON A SUBDOMAIN YOU WANT TO IFRAME! # GUACAMOLE CONTAINER server { listen 80; server_name guacamole.domain.com; return 301 https://$server_name$request_uri; } server { listen 443 ssl http2; server_name guacamole.domain.com; ##SSL SETTINGS ## READ THE COMMENT ON add_header X-Frame-Options AND add_header Content-Security-Policy IF YOU USE THIS ON A SUBDOMAIN YOU WANT TO IFRAME! ## Certificates from LE container placement ssl_certificate /config/keys/letsencrypt/fullchain.pem; ssl_certificate_key /config/keys/letsencrypt/privkey.pem; ## Strong Security recommended settings per cipherli.st ssl_dhparam /config/nginx/dhparams.pem; # Bit value: 4096 ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA384; ssl_ecdh_curve secp384r1; # Requires nginx >= 1.1.0 ssl_session_timeout 10m; ## NOTE: The add_header Content-Security-Policy won't work with duckdns since you don't own the root domain. Just buy a domain. It's cheap ## Settings to add strong security profile (A+ on securityheaders.io/ssllabs.com) add_header Strict-Transport-Security \"max-age=63072000; includeSubDomains; preload\"; add_header X-Content-Type-Options nosniff; add_header X-XSS-Protection \"1; mode=block\"; add_header X-Robots-Tag none; #SET THIS TO index IF YOU WANT GOOGLE TO INDEX YOU SITE! add_header Content-Security-Policy \"frame-ancestors https://*.DOMAIN.COM https://DOMAIN.COM https://$server_name\"; #Add your domains you want to enable iframing on add_header X-Frame-Options \"allow-from https://DOMAIN.COM https://$server_name\"; #Add your domains you want to enable iframing on. https://$server_name = sub.domain.com in this server block add_header Referrer-Policy \"strict-origin-when-cross-origin\"; add_header Feature-Policy \"geolocation none;midi none;notifications none;push none;sync-xhr none;microphone none;camera none;magnetometer none;gyroscope none;speaker self;vibrate none;fullscreen self;payment none;\"; #FEATURE POLICY: READ MORE HERE: https://scotthelme.co.uk/a-new-security-header-feature-policy/ proxy_cookie_path / \"/; HTTPOnly; Secure\"; ##NOTE: This may cause issues with unifi. Remove HTTPOnly; or create another ssl config for unifi. more_set_headers \"Server: Classified\"; more_clear_headers 'X-Powered-By'; ##END SSL SETTINGS location / { proxy_pass http://192.168.1.34:8089/; proxy_buffering off; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $http_connection; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_http_version 1.1; proxy_no_cache $cookie_session; } }","title":"Configuring Nginx"},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#_4","text":"","title":""},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#configuring-fail2ban","text":"From github: Fail2Ban scans log files like **/var/log/auth.log** and bans IP addresses conducting too many failed login attempts. It does this by updating system firewall rules to reject new connections from those IP addresses, for a configurable amount of time. Fail2Ban comes out-of-the-box ready to read many standard log files, such as those for sshd and Apache, and is easily configured to read any log file of your choosing, for any error you wish. Luckily Fail2ban comes preinstalled with your letsencrypt container, so you only need to add the filter and edit the jail.local file! For this to work we need the letsencrypt container to be able to see the catalina.out **file in the **Apache Guacamole container. Open the letsencrypt container settings. Add a path from the letsencrypt container to the Apache Guacamole container. Name: guacamole fail2ban Container path: /guacamole or whatever you prefer Host path: Your path to the**Apache Guacamole /log ** folder e.g **/AppData/ApacheGuacamole/log/tomcat8** Access mode: Read only Description: fail2ban path intoguacamole /log folder","title":"Configuring fail2ban"},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#jaillocal","text":"Go to thefail2ban folder inside the letsencrypt appdata folder and edit the jail.local file. For my config I have set the bantime to 86400 seconds (24h) The findtime is 600 seconds and maxretry is 3 At the end of the jail.local file add the following: [guacamole-auth] enabled = true port = http,https filter = guacamole-auth logpath = /guacamole/catalina.out ignoreip = 192.168.1.0/24 The ignore IP is so that fail2ban won\u2019t ban your local IP. Check out https://www.aelius.com/njh/subnet_sheet.html if you are wondering what your** CIDRnotation is. Most often it will be /24**(netmask 255.255.255.0) To find your netmask run **ipconfig /all** on windows or** ifconfig | grep netmask **on linux. The logpath is the container path you created in step 2. And catalina.out the Guacamole log. Now, there is already a filter(guacamole.conf) for Guacamole in the **filter.d** folder inside the fail2ban folder. But that filter won't work unless we make a change to it. Copy the guacamole.conf file and rename it guacamole-auth.conf In the **guacamole-auth.conf** file change: failregex = ^.*\\nWARNING: Authentication attempt from for user \"[^\"]*\" failed\\.$ to failregex = \\bAuthentication attempt from \\[ (?:,.*)?\\] for user \".*\" failed\\. Restart the letsencrypt container. If you get the error below in the fail2ban.log file you can comment the 3 date pattern lines in the guacamole-auth.conf file. 2018-06-12 21:36:49,121 fail2ban.filter [351]: ERROR Error during seek to start time in \"/guacamole/catalina.out\" 2018-06-12 21:36:49,121 fail2ban.filterpoll [351]: ERROR Caught unhandled exception in main cycle: TypeError('an integer is required',) Comment these lines by adding # in front.","title":"jail.local"},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#datepattern-b-d-exy-ims-p","text":"","title":"datepattern = ^%%b %%d, %%ExY %%I:%%M:%%S %%p"},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#warning","text":"","title":"^WARNING:()**"},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#ln-beg","text":"Remember to restart the container anytime you make a change in the conf file.","title":"{^LN-BEG}"},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#banned","text":"The fail2ban.log file should output something like this: 2018-06-12 21:39:07,529 fail2ban.jail [350]: INFO Jail 'guacamole-auth' started 2018-06-12 21:39:30,779 fail2ban.filter [350]: INFO [guacamole-auth] Ignore 192.168.1.1 by ip 2018-06-12 21:39:44,801 fail2ban.filter [350]: INFO [guacamole-auth] Found 77.16.72.179 - 2018-06-12 21:39:44 2018-06-12 21:39:57,420 fail2ban.filter [350]: INFO [guacamole-auth] Found 77.16.72.179 - 2018-06-12 21:39:57 2018-06-12 21:40:00,025 fail2ban.filter [350]: INFO [guacamole-auth] Found 77.16.72.179 - 2018-06-12 21:39:59 2018-06-12 21:40:00,196 fail2ban.actions [350]: NOTICE [guacamole-auth] Ban 77.16.72.179","title":"Banned"},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#unbanning","text":"If you managed to ban yourself or a friend banned themself you can do this to unban. Bash into the container with: **docker exec -it letsencrypt bash** Enter fail2ban interactive mode: **fail2ban-client -i** Check the status of the jail: **status guacamole-auth** Output fail2ban> status guacamole-auth Status for the jail: guacamole-auth |- Filter | |- Currently failed: 0 | |- Total failed: 3 | `- File list: /guacamole/catalina.out `- Actions |- Currently banned: 1 |- Total banned: 1 `- Banned IP list: 77.16.72.179 unban with: set guacamole-auth unbanip 77.16.72.179 If you already know the IP you want to unban you can just type this: docker exec -it letsencrypt fail2ban-client set guacamole-auth unbanip 77.16.72.179","title":"Unbanning"},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#adding-geo-blocking","text":"","title":"Adding geo-blocking"},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#purpose","text":"Restrict access based on the user's geographical location","title":"Purpose"},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#installation_2","text":"If you are using the letsencrypt container the nginx module is already installed. If not you can take a look at the howtoforge guide. That said the container doesn't come with the GeoIP database. The database can be found here: https://dev.maxmind.com/geoip/geoip2/geolite2/ and its the country database we'll be using for this guide. Download the database and extract the .mmdb file to the folder of you choice. I'll be using /config/geolite2/ for my setup.","title":"Installation"},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#nginx","text":"In your**nginx.conf** file add the following in the ** http { **block geoip2 /config/geolite2/GeoLite2-Country.mmdb { auto_reload 1d; $geoip2_data_country_code country iso_code; } # LOCAL IP ALLOW GEO BLOCK geo $lan-ip { default no; 192.168.1.0/24 yes; } # GEO IP BLOCK SITE 1 map $geoip2_data_country_code $allowed_country { default no; <YOUR-COUNTRY-CODE> yes; # e.g US for United States } Instead of \"YOUR-COUNTRY-CODE\" **add your own country code from ** this list. This will block all other countries than the one you choose. You can also add more than one country if you want. US yes; CA yes; GB yes; The** geo $lan-ip ** is for allowing you to access the domain on your LAN. Check out https://www.aelius.com/njh/subnet_sheet.html if you are wondering what your CIDRnotation is. Most often it will be /24 (netmask 255.255.255.0) To find your netmask run **ipconfig /all** on windows or** ifconfig | grep netmask ** on linux. Note: The** geo $lan-ip part is only needed if you set default to no ** For it to actually block you need to add this in your server block : # LOCAL IP ALLOW GEO BLOCK if ($lan-ip = yes) { set $allowed_country yes; } # COUNTRY GEO BLOCK if ($allowed_country = no) { return 444; } So if you created a guacamole.conf file in the nginx/site-confs folder you add it there. It will then look like this: # GUACAMOLE CONTAINER server { listen 80; server_name guacamole.domain.com; return 301 https://$server_name$request_uri; } server { listen 443 ssl http2; server_name guacamole.domain.com; ##GEOBLOCK # LOCAL IP ALLOW GEO BLOCK if ($lan-ip = yes) { set $allowed_country yes; } # COUNTRY GEO BLOCK if ($allowed_country = no) { return 444; } ##SSL SETTINGS ## READ THE COMMENT ON add_header X-Frame-Options AND add_header Content-Security-Policy IF YOU USE THIS ON A SUBDOMAIN YOU WANT TO IFRAME! ## Certificates from LE container placement ssl_certificate /config/keys/letsencrypt/fullchain.pem; ssl_certificate_key /config/keys/letsencrypt/privkey.pem; ## Strong Security recommended settings per cipherli.st ssl_dhparam /config/nginx/dhparams.pem; # Bit value: 4096 ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA384; ssl_ecdh_curve secp384r1; # Requires nginx >= 1.1.0 ssl_session_timeout 10m; ## NOTE: The add_header Content-Security-Policy won't work with duckdns since you don't own the root domain. Just buy a domain. It's cheap ## Settings to add strong security profile (A+ on securityheaders.io/ssllabs.com) add_header Strict-Transport-Security \"max-age=63072000; includeSubDomains; preload\"; add_header X-Content-Type-Options nosniff; add_header X-XSS-Protection \"1; mode=block\"; add_header X-Robots-Tag none; #SET THIS TO index IF YOU WANT GOOGLE TO INDEX YOU SITE! add_header Content-Security-Policy \"frame-ancestors https://*.$server_name https://$server_name\"; ## Use *.domain.com, not *.sub.domain.com (*.$server_name) when using this on a sub-domain that you want to iframe! add_header X-Frame-Options \"ALLOW-FROM https://*.$server_name\" always; ## Use *.domain.com, not *.sub.domain.com (*.$server_name) when using this on a sub-domain that you want to iframe! add_header Referrer-Policy \"strict-origin-when-cross-origin\"; proxy_cookie_path / \"/; HTTPOnly; Secure\"; ##NOTE: This may cause issues with unifi. Remove HTTPOnly; or create another ssl config for unifi. more_set_headers \"Server: Classified\"; more_clear_headers 'X-Powered-By'; ##END SSL SETTINGS location / { proxy_pass http://192.168.1.34:8089/; proxy_buffering off; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $http_connection; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_http_version 1.1; proxy_no_cache $cookie_session; } }","title":"NGINX"},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#blocked","text":"You can test if it worked with a VPN or do a performance test from a location that is blocked here https://www.webpagetest.org/","title":"Blocked"},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#optional-organizr","text":"Another security layer is using Organizr to block access to your guacamole.domain.com by having you to log into Organizr first! And you can even add a fail2ban filter on the Organizr login form! By using server authentication you will be shown a 401 Unauthorized page unless you log in first. [embed] https://technicalramblings.com/blog/fail2ban-with-organizr-and-let-sencrypt/ [/embed]","title":"Optional: Organizr"},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#optional-basic-http-auth","text":"Another security layer is using basic http auth . Linuxservers letsencrypt container is already be pre configured to ban failed http auths with fail2ban! <br /> <span data-mce-type=\"bookmark\" style=\"display: inline-block; width: 0px; overflow: hidden; line-height: 0;\" class=\"mce_SELRES_start\">\ufeff</span><!--//--><![CDATA[//><!-- !function(a,b){\"use strict\";function c(){if(!e){e=!0;var a,c,d,f,g=-1!==navigator.appVersion.indexOf(\"MSIE 10\"),h=!!navigator.userAgent.match(/Trident.*rv:11\\./),i=b.querySelectorAll(\"iframe.wp-embedded-content\");for(c=0;c<i.length;c++){if(d=i[c],!d.getAttribute(\"data-secret\"))f=Math.random().toString(36).substr(2,10),d.src+=\"#?secret=\"+f,d.setAttribute(\"data-secret\",f);if(g||h)a=d.cloneNode(!0),a.removeAttribute(\"security\"),d.parentNode.replaceChild(a,d)}}}var d=!1,e=!1;if(b.querySelector)if(a.addEventListener)d=!0;if(a.wp=a.wp||{},!a.wp.receiveEmbedMessage)if(a.wp.receiveEmbedMessage=function(c){var d=c.data;if(d.secret||d.message||d.value)if(!/[^a-zA-Z0-9]/.test(d.secret)){var e,f,g,h,i,j=b.querySelectorAll('iframe[data-secret=\"'+d.secret+'\"]'),k=b.querySelectorAll('blockquote[data-secret=\"'+d.secret+'\"]');for(e=0;e<k.length;e++)k[e].style.display=\"none\";for(e=0;e<j.length;e++)if(f=j[e],c.source===f.contentWindow){if(f.removeAttribute(\"style\"),\"height\"===d.message){if(g=parseInt(d.value,10),g><span data-mce-type=\"bookmark\" style=\"display: inline-block; width: 0px; overflow: hidden; line-height: 0;\" class=\"mce_SELRES_start\">\ufeff</span>1e3)g=1e3;else if(~~g<200)g=200;f.height=g}if(\"link\"===d.message)if(h=b.createElement(\"a\"),i=b.createElement(\"a\"),h.href=f.getAttribute(\"src\"),i.href=d.value,i.host===h.host)if(b.activeElement===f)a.top.location.href=d.value}else;}},d)a.addEventListener(\"message\",a.wp.receiveEmbedMessage,!1),b.addEventListener(\"DOMContentLoaded\",c,!1),a.addEventListener(\"load\",c,!1)}(window,document); //--><!]]><br /><span data-mce-type=\"bookmark\" style=\"display: inline-block; width: 0px; overflow: hidden; line-height: 0;\" class=\"mce_SELRES_end\">\ufeff</span> Sources: https://github.com/fail2ban/fail2ban/issues/1574","title":"Optional: Basic http auth"},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#for-any-questions-you-can-find-me-here","text":"","title":"For any questions you can find me here:"},{"location":"blog/remotely-accessing-the-unraid-gui-with-guacamole-and-vnc-web-browser/#_5","text":"","title":""},{"location":"blog/spice-up-your-homepage/","text":"Spice up your homepage! \u00b6 Spice up your homepage! A HowTo on custom Netdata pages, embedding Discord and adding customer support chat! I'm going to integrate these applications into my Organizr homepage but this will pretty much work on any site of your choosing. Netdata \u00b6 First I'd recommend you to check out the Netdata wiki on custom dashboards as it explains**alot**. Preparation \u00b6 Note: This guide assumes you have already reverse proxied netdata. Before we can start we need some files from the Netdata /web folder. And since I'm using the docker I will have to get them using cli. The files we need are: dashboard.js bootstrap-slate-flat-3.3.7.css or bootstrap-3.3.7.css dashboard.slate.css or dashboard.css I will be using using the slate (dark) theme for this guide. Note-2: I've made it so that if you don't want to mess with the js or css files, you can use my Netdata theme and subfilter that with nginx. Scroll down to the theme.park part! The CSS files are located in the /css folder and the JS file is in the /web folder. Open a terminal and exec into the docker container with this command: docker exec -it Netdata bash Goto this location: cd usr/share/netdata/web/ Copy the files to your appdata config path: (Host path 1) cp dashboard.js dashboard.slate.css /etc/netdata/override Change directory with the cd command cd css/ Copy the bootstrap.css file. cp bootstrap-slate-flat-3.3.7.css /etc/netdata/override Tip: Use the** ls **command to list all files in a specific directory. Editing the files \u00b6 Copy the files to a new subdirectory in your nginx root folder (e.g appdata/letsencrypt/www/customnetdata) Create a new folder called css (e.g customnetdata/css) Copy bootstrap-slate-flat-3.3.7.css and dashboard.slate.css to the css folder I'm using the dark theme (slate) css but using the regular works just fine. Just remember to edit the your custom html to use the white theme. In the dashboard.js file, scroll down to** NETDATA.themes **and change it so it points to the files you have added in the css folder. Add css/ Before slate: { bootstrap_css: NETDATA.serverDefault + 'css/bootstrap-slate-flat-3.3.7.css?v20161229-1', dashboard_css: NETDATA.serverDefault + 'dashboard.slate.css?v20170725-1', After slate: { bootstrap_css: 'css/bootstrap-slate-flat-3.3.7.css?v20161229-1', dashboard_css: 'css/dashboard.slate.css?v20170725-1', Using the theme.park theme \u00b6 If you don't want to edit css or js files you can instead only copy the html code at the bottom and the make the necessary modifications to that file. In the html code, scroll down to this line: <script type=\"text/javascript\" src=\"dashboard.js\"></script> And add your Netdata domain, like so: <script type=\"text/javascript\" src=\"https://YOUR-DOMAIN.COM/netdata/dashboard.js\"></script> By doing this you can instead subfilter the CSS changes using nginx and my theme repository on github! (read more at the nginx part ) After that follow along the rest of the HTML instructions below. NOTE: If you get an error thatlib/jquery-2.2.4.min.js cant be found you can try and edit line [136] in dashboard.js that says **NETDATA.serverStatic =** **NETDATA.serverDefault;** to** NETDATA.serverStatic = \"https://yourdomain.com/netdata/\"; ** Creating the HTML \u00b6 Create your custom HTML. You can use the one I have added below and work off that. In this guide I have named it** custom.html ** In my example I have added a total CPU utilization dygraph and a disk I/O read-write dygraph. If you want a diffrent graph type change the** data-chart-library **See the Netdata wiki To make it work externally you need to add your external Netdata address in the html! (Netdata needs to be reverse proxied) If you add your local ip address you will get an error when trying to load it through HTTPS. // Set the default netdata server. // on charts without a 'data-host', this one will be used. // the default is the server that dashboard.js is downloaded from. var netdataServer = 'https://YOURNETDATADOMAIN.COM/'; e.g** https://yourdomain.com/netdata/ ** Note: The trailing slash onhttps://domain.com/netdata**/** is very important. If you dont add it you will get Strict MIME errors in your browser console, and it won't load properly. Custom HTML for total CPU utilization and Disk I/O \u00b6 <!DOCTYPE html> <html lang=\"en\"> <head> <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"> <meta charset=\"utf-8\"> <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\"> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"> <meta name=\"apple-mobile-web-app-capable\" content=\"yes\"> <meta name=\"apple-mobile-web-app-status-bar-style\" content=\"black-translucent\"> </head> <body> <center> <ul> </ul> <div style=\"width: 100%; display: inline-block;\"> <div data-netdata=\"system.cpu\" data-chart-library=\"dygraph\" data-width=\"100%\" data-height=\"140\" data-after=\"-300\" data-dt-element-name=\"time203\" ></div> <div style=\"width: 100%; display: inline-block;\"> <div data-netdata=\"system.io\" data-chart-library=\"dygraph\" data-width=\"100%\" data-height=\"120\" data-after=\"-300\" data-dt-element-name=\"time203\" data-colors=\"#FF5555 #44c442\" ></div> </center> </body> <script> // this section has to appear before loading dashboard.js // Select a theme. // uncomment on of the two themes: // var netdataTheme = 'default'; // this is white var netdataTheme = 'slate'; // this is dark // Set the default netdata server. // on charts without a 'data-host', this one will be used. // the default is the server that dashboard.js is downloaded from. var netdataServer = 'https://YOURNETDATADOMAIN.COM/'; </script> <!-- <script type=\"text/javascript\" src=\"/dashboard.js\"></script> --> <script type=\"text/javascript\" src=\"dashboard.js?v20170724-7\"></script> <script> // Set options for TV operation // This has to be done, after dashboard.js is loaded // destroy charts not shown (lowers memory on the browser) // NETDATA.options.current.destroy_on_hide = false; // set this to false, to always show all dimensions //NETDATA.options.current.eliminate_zero_dimensions = true; // lower the pressure on this browser NETDATA.options.current.concurrent_refreshes = false; // if the tv browser is too slow (a pi?) // set this to false //NETDATA.options.current.parallel_refresher = true; // always update the charts, even if focus is lost NETDATA.options.current.stop_updates_when_focus_is_lost = false; // Since you may render charts from many servers and any of them may // become offline for some time, the charts will break. // This will reload the page every RELOAD_EVERY minutes var RELOAD_EVERY = 1; setTimeout(function(){ location.reload(); }, RELOAD_EVERY * 60 * 1000); </script> </html> Nginx \u00b6 In your nginx config you can add this in your main server block to create a sub-directory. # CUSTOM NETDATA location /customnetdata { #auth_request /auth-user; root /config/www/; index custom.html; } Below is the location block you need to use for the theme.park theme. # CUSTOM NETDATA USING THEME.PARK CSS location /customnetdata { #auth_request /auth-user; root /config/www/; index custom.html; proxy_set_header Accept-Encoding \"\"; sub_filter '</head>' '<link rel=\"stylesheet\" type=\"text/css\" href=\"https://gilbn.github.io/theme.park/CSS/themes/netdata/organizr-dashboard.css\"> </head>'; sub_filter_once on; } By using ** https://gilbn.github.io/theme.park/CSS/themes/netdata/organizr-dashboard.css **it will match any theme Organizr is using as the background is transparent. Adding it to your Organizr homepage \u00b6 Adding it to your Org homepage is quite simple. Just add the code below and edit it to match your domain. Go to Settings \u2192 Edit Homepage \u2192 Custom HTML If you have added more graphs you'll need to change the height. <div style=\"overflow:hidden;height:282px;width:100%;position: relative;\"> <embed style=\"height:calc(100%);width:calc(100%)\" src='https://yourdomain.com/customnetdata/custom.html' /> </div> <ul> </ul> Customizing colors \u00b6 - For the blur theme, scroll down bootstrap-slate-flat-3.3.7.css \u00b6 Set the background-color to what you want. I set it to transparent so if I change my Org theme it will follow that. body { font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; font-size: 14px; line-height: 1.42857143; color: #c8c8c8; background-color: transparent; } dashboard.slate.css \u00b6 Next is changing the** .netdata-legend-value **The background-color is the legend percent bacground color. .netdata-legend-value { /*margin-left: 14px;*/ position: absolute; right: 10px; float: right; text-align: right; font-size: 11px; /* legend: dimension value size */ font-weight: bold; vertical-align: bottom; background-color: transparent; margin-top: 0px; z-index: 10; padding: 0px; padding-left: 15px; cursor: pointer; /* -webkit-font-smoothing: none; */ } background-color: transparent; ** color: #E5A00D; **I chose orange to match my Organizr theme. .netdata-legend-resize-handler { display: block; position: absolute; bottom: 0px; right: 0px; height: 15px; width: 30px; background-color: transparent; font-size: 12px; vertical-align: middle; line-height: 15px; cursor: ns-resize; color: #E5A00D; text-align: center; overflow: hidden; z-index: 20; padding: 0px; margin: 0px; } It's the same for the legend tool box, set it to transparent or what ever you like. .netdata-legend-toolbox { display: block; position: absolute; bottom: 0px; right: 30px; height: 15px; width: 110px; background-color: transparent; font-size: 12px; vertical-align: middle; line-height: 15px; color: #E5A00D; text-align: center; overflow: hidden; z-index: 20; padding: 0px; margin: 0px; } Repeat the steps. Set the background to transparent or what ever you like. Set color to the color you want the buttons to be. .netdata-legend-toolbox-button { display: inline-block; position: relative; height: 15px; width: 18px; background-color: transparent; font-size: 12px; vertical-align: middle; line-height: 15px; color: #E5A00D; text-align: center; overflow: hidden; z-index: 21; padding: 0px; margin: 0px; cursor: pointer; } To edit the text color change the html,body This will**not**change the graph text color html, body { /*font-family: Calibri,\"Segoe UI\",\"Helvetica Neue\",Helvetica,Arial,sans-serif;*/ font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; font-style: normal; font-variant: normal; color: #E5A00D; } The graph text color is changed with .dygraph-axis-label { color: #6c7075; } custom.html \u00b6 Changing the data chart colors is done in the custom HTML. <div data-netdata=\"unique.id\" data-colors=\"#AABBCC #DDEEFF ...\" ></div> dashboard.js \u00b6 If you want to change the grid and axis color you can do that in the NETDATA.themes section in the dashboard.js file. grid: '#283236', axis: '#283236', Blur theme \u00b6 If you want to make your custom Netdata html match the layer#Cake blur-theme you can do this: In** dashboard.slate.css **change this: Change the body text color to #FFFFFF html, body { /*font-family: Calibri,\"Segoe UI\",\"Helvetica Neue\",Helvetica,Arial,sans-serif;*/ font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; font-style: normal; font-variant: normal; color: #FFFFFF; } And set the other color options in the examples above to** (0, 0%, 100%, .45) ** For the grid and axis color set it to transparent in** dashboard.js ** grid: 'transparent', axis: 'transparent', In the** bootstrap-slate-flat-3.3.7.css ** Set the background color of the graph body to** rgba(0, 0, 0, .15); ** body { font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; font-size: 14px; line-height: 1.42857143; color: #c8c8c8; background-color: rgba(0, 0, 0, .15); } Discord Widgetbot \u00b6 First you'll need to create your own Discord Server. After you've done that head over to https://widgetbot.voakie.com/ an sign in with your Discord credentials. Setup \u00b6 Connect the WidgetBot with your user and choose your server in the \"Configurator\" Selct the channel you want to embed. If you want to change the colors of the widget you need to sign up to the patreon here: https://www.patreon.com/widgetbot Organizr html config \u00b6 Add this in the homepage HTML and edit the values to your liking. <div style=\"overflow:hidden;height:300px\"> <embed style=\"height:calc(100% + 115px)\" width='100%' src='URL TO YOUR WIDGET' /> </div> <ul> </ul> Custom chat with Tawk.to \u00b6 Go to https://www.tawk.to/ Create an account and add the widget code to the custom HTML. If you want the chat box to be on every page add the code to the custom CSS. You can also change the colors in the Widget Appearance settings! Bonus HTML for system overview \u00b6 <!DOCTYPE html> <html lang=\"en\"> <head> <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"> <meta charset=\"utf-8\"> <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\"> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"> <meta name=\"apple-mobile-web-app-capable\" content=\"yes\"> <meta name=\"apple-mobile-web-app-status-bar-style\" content=\"black-translucent\"> </head> <body> <center> <ul> </ul> <div style=\"display: inline-block; position: relative;\"> <div data-netdata=\"system.io\" data-dimensions=\"in\"' data-chart-library=\"easypiechart\" data-title=\"Disk Read\"' data-width=\"200\" data-height=\"200\" data-after=\"-300\" data-points=\"300\" data-dt-element-name=\"time701\" ></div> </div> <div style=\"display: inline-block; position: relative;\"> <div data-netdata=\"system.io\" data-dimensions=\"out\"' data-chart-library=\"easypiechart\" data-title=\"Disk Write\"' data-width=\"200\" data-height=\"200\" data-after=\"-300\" data-points=\"300\" data-dt-element-name=\"time701\" ></div> </div> <div style=\"display: inline-block; position: relative;\"> <div data-netdata=\"system.cpu\" data-chart-library=\"gauge\" data-title=\"CPU\" data-units=\"%\" data-gauge-max-value=\"100\" data-width=\"400\" data-height=\"200\" data-after=\"-300\" data-points=\"300\" data-colors=\"#22AA99\" data-dt-element-name=\"time701\" ></div> </div> <div style=\"display: inline-block; position: relative;\"> <div data-netdata=\"system.net\" data-dimensions=\"received\" data-chart-library=\"easypiechart\" data-title=\"IPv4 Inbound\" data-width=\"200\" data-height=\"200\" data-after=\"-300\" data-points=\"300\" data-dt-element-name=\"time701\" ></div> </div> <div style=\"display: inline-block; position: relative;\"> <div data-netdata=\"system.net\" data-dimensions=\"sent\" data-chart-library=\"easypiechart\" data-title=\"IPv4 Outbound\" data-width=\"200\" data-height=\"200\" data-after=\"-300\" data-points=\"300\" data-dt-element-name=\"time701\" ></div> </div> <div style=\"display: inline-block; position: relative;\"> <div data-netdata=\"system.ram\" data-dimensions=\"used|buffers|active|wired\" data-append-options=\"percentage\" data-chart-library=\"easypiechart\" data-title=\"Used RAM\" data-units=\"%\" data-easypiechart-max-value=\"100\" data-colors=\"#EE9911\" data-width=\"170\" data-height=\"170\" data-after=\"-300\" data-points=\"300\" data-dt-element-name=\"time701\" ></div> </div> </center> </body> <script> // this section has to appear before loading dashboard.js // Select a theme. // uncomment on of the two themes: // var netdataTheme = 'default'; // this is white var netdataTheme = 'slate'; // this is dark // Set the default netdata server. // on charts without a 'data-host', this one will be used. // the default is the server that dashboard.js is downloaded from. var netdataServer = 'https://YOURNETDATADOMAIN.COM/'; </script> <!-- <script type=\"text/javascript\" src=\"http://my.server:19999/dashboard.js\"></script> --> <script type=\"text/javascript\" src=\"dashboard.js?v20170105-7\"></script> <script> // Set options for TV operation // This has to be done, after dashboard.js is loaded // destroy charts not shown (lowers memory on the browser) NETDATA.options.current.destroy_on_hide = true; // set this to false, to always show all dimensions //NETDATA.options.current.eliminate_zero_dimensions = true; // lower the pressure on this browser //NETDATA.options.current.concurrent_refreshes = false; // if the tv browser is too slow (a pi?) // set this to false //NETDATA.options.current.parallel_refresher = true; // always update the charts, even if focus is lost NETDATA.options.current.stop_updates_when_focus_is_lost = false; // Since you may render charts from many servers and any of them may // become offline for some time, the charts will break. // This will reload the page every RELOAD_EVERY minutes var RELOAD_EVERY = 1; setTimeout(function(){ location.reload(); }, RELOAD_EVERY * 60 * 1000); </script> </html>","title":"Spice up your homepage!"},{"location":"blog/spice-up-your-homepage/#spice-up-your-homepage","text":"Spice up your homepage! A HowTo on custom Netdata pages, embedding Discord and adding customer support chat! I'm going to integrate these applications into my Organizr homepage but this will pretty much work on any site of your choosing.","title":"Spice up your homepage!"},{"location":"blog/spice-up-your-homepage/#netdata","text":"First I'd recommend you to check out the Netdata wiki on custom dashboards as it explains**alot**.","title":"Netdata"},{"location":"blog/spice-up-your-homepage/#preparation","text":"Note: This guide assumes you have already reverse proxied netdata. Before we can start we need some files from the Netdata /web folder. And since I'm using the docker I will have to get them using cli. The files we need are: dashboard.js bootstrap-slate-flat-3.3.7.css or bootstrap-3.3.7.css dashboard.slate.css or dashboard.css I will be using using the slate (dark) theme for this guide. Note-2: I've made it so that if you don't want to mess with the js or css files, you can use my Netdata theme and subfilter that with nginx. Scroll down to the theme.park part! The CSS files are located in the /css folder and the JS file is in the /web folder. Open a terminal and exec into the docker container with this command: docker exec -it Netdata bash Goto this location: cd usr/share/netdata/web/ Copy the files to your appdata config path: (Host path 1) cp dashboard.js dashboard.slate.css /etc/netdata/override Change directory with the cd command cd css/ Copy the bootstrap.css file. cp bootstrap-slate-flat-3.3.7.css /etc/netdata/override Tip: Use the** ls **command to list all files in a specific directory.","title":"Preparation"},{"location":"blog/spice-up-your-homepage/#editing-the-files","text":"Copy the files to a new subdirectory in your nginx root folder (e.g appdata/letsencrypt/www/customnetdata) Create a new folder called css (e.g customnetdata/css) Copy bootstrap-slate-flat-3.3.7.css and dashboard.slate.css to the css folder I'm using the dark theme (slate) css but using the regular works just fine. Just remember to edit the your custom html to use the white theme. In the dashboard.js file, scroll down to** NETDATA.themes **and change it so it points to the files you have added in the css folder. Add css/ Before slate: { bootstrap_css: NETDATA.serverDefault + 'css/bootstrap-slate-flat-3.3.7.css?v20161229-1', dashboard_css: NETDATA.serverDefault + 'dashboard.slate.css?v20170725-1', After slate: { bootstrap_css: 'css/bootstrap-slate-flat-3.3.7.css?v20161229-1', dashboard_css: 'css/dashboard.slate.css?v20170725-1',","title":"Editing the files"},{"location":"blog/spice-up-your-homepage/#using-the-themepark-theme","text":"If you don't want to edit css or js files you can instead only copy the html code at the bottom and the make the necessary modifications to that file. In the html code, scroll down to this line: <script type=\"text/javascript\" src=\"dashboard.js\"></script> And add your Netdata domain, like so: <script type=\"text/javascript\" src=\"https://YOUR-DOMAIN.COM/netdata/dashboard.js\"></script> By doing this you can instead subfilter the CSS changes using nginx and my theme repository on github! (read more at the nginx part ) After that follow along the rest of the HTML instructions below. NOTE: If you get an error thatlib/jquery-2.2.4.min.js cant be found you can try and edit line [136] in dashboard.js that says **NETDATA.serverStatic =** **NETDATA.serverDefault;** to** NETDATA.serverStatic = \"https://yourdomain.com/netdata/\"; **","title":"Using the theme.park theme"},{"location":"blog/spice-up-your-homepage/#creating-the-html","text":"Create your custom HTML. You can use the one I have added below and work off that. In this guide I have named it** custom.html ** In my example I have added a total CPU utilization dygraph and a disk I/O read-write dygraph. If you want a diffrent graph type change the** data-chart-library **See the Netdata wiki To make it work externally you need to add your external Netdata address in the html! (Netdata needs to be reverse proxied) If you add your local ip address you will get an error when trying to load it through HTTPS. // Set the default netdata server. // on charts without a 'data-host', this one will be used. // the default is the server that dashboard.js is downloaded from. var netdataServer = 'https://YOURNETDATADOMAIN.COM/'; e.g** https://yourdomain.com/netdata/ ** Note: The trailing slash onhttps://domain.com/netdata**/** is very important. If you dont add it you will get Strict MIME errors in your browser console, and it won't load properly.","title":"Creating the HTML"},{"location":"blog/spice-up-your-homepage/#custom-html-for-total-cpu-utilization-and-disk-io","text":"<!DOCTYPE html> <html lang=\"en\"> <head> <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"> <meta charset=\"utf-8\"> <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\"> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"> <meta name=\"apple-mobile-web-app-capable\" content=\"yes\"> <meta name=\"apple-mobile-web-app-status-bar-style\" content=\"black-translucent\"> </head> <body> <center> <ul> </ul> <div style=\"width: 100%; display: inline-block;\"> <div data-netdata=\"system.cpu\" data-chart-library=\"dygraph\" data-width=\"100%\" data-height=\"140\" data-after=\"-300\" data-dt-element-name=\"time203\" ></div> <div style=\"width: 100%; display: inline-block;\"> <div data-netdata=\"system.io\" data-chart-library=\"dygraph\" data-width=\"100%\" data-height=\"120\" data-after=\"-300\" data-dt-element-name=\"time203\" data-colors=\"#FF5555 #44c442\" ></div> </center> </body> <script> // this section has to appear before loading dashboard.js // Select a theme. // uncomment on of the two themes: // var netdataTheme = 'default'; // this is white var netdataTheme = 'slate'; // this is dark // Set the default netdata server. // on charts without a 'data-host', this one will be used. // the default is the server that dashboard.js is downloaded from. var netdataServer = 'https://YOURNETDATADOMAIN.COM/'; </script> <!-- <script type=\"text/javascript\" src=\"/dashboard.js\"></script> --> <script type=\"text/javascript\" src=\"dashboard.js?v20170724-7\"></script> <script> // Set options for TV operation // This has to be done, after dashboard.js is loaded // destroy charts not shown (lowers memory on the browser) // NETDATA.options.current.destroy_on_hide = false; // set this to false, to always show all dimensions //NETDATA.options.current.eliminate_zero_dimensions = true; // lower the pressure on this browser NETDATA.options.current.concurrent_refreshes = false; // if the tv browser is too slow (a pi?) // set this to false //NETDATA.options.current.parallel_refresher = true; // always update the charts, even if focus is lost NETDATA.options.current.stop_updates_when_focus_is_lost = false; // Since you may render charts from many servers and any of them may // become offline for some time, the charts will break. // This will reload the page every RELOAD_EVERY minutes var RELOAD_EVERY = 1; setTimeout(function(){ location.reload(); }, RELOAD_EVERY * 60 * 1000); </script> </html>","title":"Custom HTML for total CPU utilization and Disk I/O"},{"location":"blog/spice-up-your-homepage/#nginx","text":"In your nginx config you can add this in your main server block to create a sub-directory. # CUSTOM NETDATA location /customnetdata { #auth_request /auth-user; root /config/www/; index custom.html; } Below is the location block you need to use for the theme.park theme. # CUSTOM NETDATA USING THEME.PARK CSS location /customnetdata { #auth_request /auth-user; root /config/www/; index custom.html; proxy_set_header Accept-Encoding \"\"; sub_filter '</head>' '<link rel=\"stylesheet\" type=\"text/css\" href=\"https://gilbn.github.io/theme.park/CSS/themes/netdata/organizr-dashboard.css\"> </head>'; sub_filter_once on; } By using ** https://gilbn.github.io/theme.park/CSS/themes/netdata/organizr-dashboard.css **it will match any theme Organizr is using as the background is transparent.","title":"Nginx"},{"location":"blog/spice-up-your-homepage/#adding-it-to-your-organizr-homepage","text":"Adding it to your Org homepage is quite simple. Just add the code below and edit it to match your domain. Go to Settings \u2192 Edit Homepage \u2192 Custom HTML If you have added more graphs you'll need to change the height. <div style=\"overflow:hidden;height:282px;width:100%;position: relative;\"> <embed style=\"height:calc(100%);width:calc(100%)\" src='https://yourdomain.com/customnetdata/custom.html' /> </div> <ul> </ul>","title":"Adding it to your Organizr homepage"},{"location":"blog/spice-up-your-homepage/#customizing-colors","text":"- For the blur theme, scroll down","title":"Customizing colors"},{"location":"blog/spice-up-your-homepage/#bootstrap-slate-flat-337css","text":"Set the background-color to what you want. I set it to transparent so if I change my Org theme it will follow that. body { font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; font-size: 14px; line-height: 1.42857143; color: #c8c8c8; background-color: transparent; }","title":"bootstrap-slate-flat-3.3.7.css"},{"location":"blog/spice-up-your-homepage/#dashboardslatecss","text":"Next is changing the** .netdata-legend-value **The background-color is the legend percent bacground color. .netdata-legend-value { /*margin-left: 14px;*/ position: absolute; right: 10px; float: right; text-align: right; font-size: 11px; /* legend: dimension value size */ font-weight: bold; vertical-align: bottom; background-color: transparent; margin-top: 0px; z-index: 10; padding: 0px; padding-left: 15px; cursor: pointer; /* -webkit-font-smoothing: none; */ } background-color: transparent; ** color: #E5A00D; **I chose orange to match my Organizr theme. .netdata-legend-resize-handler { display: block; position: absolute; bottom: 0px; right: 0px; height: 15px; width: 30px; background-color: transparent; font-size: 12px; vertical-align: middle; line-height: 15px; cursor: ns-resize; color: #E5A00D; text-align: center; overflow: hidden; z-index: 20; padding: 0px; margin: 0px; } It's the same for the legend tool box, set it to transparent or what ever you like. .netdata-legend-toolbox { display: block; position: absolute; bottom: 0px; right: 30px; height: 15px; width: 110px; background-color: transparent; font-size: 12px; vertical-align: middle; line-height: 15px; color: #E5A00D; text-align: center; overflow: hidden; z-index: 20; padding: 0px; margin: 0px; } Repeat the steps. Set the background to transparent or what ever you like. Set color to the color you want the buttons to be. .netdata-legend-toolbox-button { display: inline-block; position: relative; height: 15px; width: 18px; background-color: transparent; font-size: 12px; vertical-align: middle; line-height: 15px; color: #E5A00D; text-align: center; overflow: hidden; z-index: 21; padding: 0px; margin: 0px; cursor: pointer; } To edit the text color change the html,body This will**not**change the graph text color html, body { /*font-family: Calibri,\"Segoe UI\",\"Helvetica Neue\",Helvetica,Arial,sans-serif;*/ font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; font-style: normal; font-variant: normal; color: #E5A00D; } The graph text color is changed with .dygraph-axis-label { color: #6c7075; }","title":"dashboard.slate.css"},{"location":"blog/spice-up-your-homepage/#customhtml","text":"Changing the data chart colors is done in the custom HTML. <div data-netdata=\"unique.id\" data-colors=\"#AABBCC #DDEEFF ...\" ></div>","title":"custom.html"},{"location":"blog/spice-up-your-homepage/#dashboardjs","text":"If you want to change the grid and axis color you can do that in the NETDATA.themes section in the dashboard.js file. grid: '#283236', axis: '#283236',","title":"dashboard.js"},{"location":"blog/spice-up-your-homepage/#blur-theme","text":"If you want to make your custom Netdata html match the layer#Cake blur-theme you can do this: In** dashboard.slate.css **change this: Change the body text color to #FFFFFF html, body { /*font-family: Calibri,\"Segoe UI\",\"Helvetica Neue\",Helvetica,Arial,sans-serif;*/ font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; font-style: normal; font-variant: normal; color: #FFFFFF; } And set the other color options in the examples above to** (0, 0%, 100%, .45) ** For the grid and axis color set it to transparent in** dashboard.js ** grid: 'transparent', axis: 'transparent', In the** bootstrap-slate-flat-3.3.7.css ** Set the background color of the graph body to** rgba(0, 0, 0, .15); ** body { font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; font-size: 14px; line-height: 1.42857143; color: #c8c8c8; background-color: rgba(0, 0, 0, .15); }","title":"Blur theme"},{"location":"blog/spice-up-your-homepage/#discord-widgetbot","text":"First you'll need to create your own Discord Server. After you've done that head over to https://widgetbot.voakie.com/ an sign in with your Discord credentials.","title":"Discord Widgetbot"},{"location":"blog/spice-up-your-homepage/#setup","text":"Connect the WidgetBot with your user and choose your server in the \"Configurator\" Selct the channel you want to embed. If you want to change the colors of the widget you need to sign up to the patreon here: https://www.patreon.com/widgetbot","title":"Setup"},{"location":"blog/spice-up-your-homepage/#organizr-html-config","text":"Add this in the homepage HTML and edit the values to your liking. <div style=\"overflow:hidden;height:300px\"> <embed style=\"height:calc(100% + 115px)\" width='100%' src='URL TO YOUR WIDGET' /> </div> <ul> </ul>","title":"Organizr html config"},{"location":"blog/spice-up-your-homepage/#custom-chat-with-tawkto","text":"Go to https://www.tawk.to/ Create an account and add the widget code to the custom HTML. If you want the chat box to be on every page add the code to the custom CSS. You can also change the colors in the Widget Appearance settings!","title":"Custom chat with Tawk.to"},{"location":"blog/spice-up-your-homepage/#bonus-html-for-system-overview","text":"<!DOCTYPE html> <html lang=\"en\"> <head> <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"> <meta charset=\"utf-8\"> <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\"> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"> <meta name=\"apple-mobile-web-app-capable\" content=\"yes\"> <meta name=\"apple-mobile-web-app-status-bar-style\" content=\"black-translucent\"> </head> <body> <center> <ul> </ul> <div style=\"display: inline-block; position: relative;\"> <div data-netdata=\"system.io\" data-dimensions=\"in\"' data-chart-library=\"easypiechart\" data-title=\"Disk Read\"' data-width=\"200\" data-height=\"200\" data-after=\"-300\" data-points=\"300\" data-dt-element-name=\"time701\" ></div> </div> <div style=\"display: inline-block; position: relative;\"> <div data-netdata=\"system.io\" data-dimensions=\"out\"' data-chart-library=\"easypiechart\" data-title=\"Disk Write\"' data-width=\"200\" data-height=\"200\" data-after=\"-300\" data-points=\"300\" data-dt-element-name=\"time701\" ></div> </div> <div style=\"display: inline-block; position: relative;\"> <div data-netdata=\"system.cpu\" data-chart-library=\"gauge\" data-title=\"CPU\" data-units=\"%\" data-gauge-max-value=\"100\" data-width=\"400\" data-height=\"200\" data-after=\"-300\" data-points=\"300\" data-colors=\"#22AA99\" data-dt-element-name=\"time701\" ></div> </div> <div style=\"display: inline-block; position: relative;\"> <div data-netdata=\"system.net\" data-dimensions=\"received\" data-chart-library=\"easypiechart\" data-title=\"IPv4 Inbound\" data-width=\"200\" data-height=\"200\" data-after=\"-300\" data-points=\"300\" data-dt-element-name=\"time701\" ></div> </div> <div style=\"display: inline-block; position: relative;\"> <div data-netdata=\"system.net\" data-dimensions=\"sent\" data-chart-library=\"easypiechart\" data-title=\"IPv4 Outbound\" data-width=\"200\" data-height=\"200\" data-after=\"-300\" data-points=\"300\" data-dt-element-name=\"time701\" ></div> </div> <div style=\"display: inline-block; position: relative;\"> <div data-netdata=\"system.ram\" data-dimensions=\"used|buffers|active|wired\" data-append-options=\"percentage\" data-chart-library=\"easypiechart\" data-title=\"Used RAM\" data-units=\"%\" data-easypiechart-max-value=\"100\" data-colors=\"#EE9911\" data-width=\"170\" data-height=\"170\" data-after=\"-300\" data-points=\"300\" data-dt-element-name=\"time701\" ></div> </div> </center> </body> <script> // this section has to appear before loading dashboard.js // Select a theme. // uncomment on of the two themes: // var netdataTheme = 'default'; // this is white var netdataTheme = 'slate'; // this is dark // Set the default netdata server. // on charts without a 'data-host', this one will be used. // the default is the server that dashboard.js is downloaded from. var netdataServer = 'https://YOURNETDATADOMAIN.COM/'; </script> <!-- <script type=\"text/javascript\" src=\"http://my.server:19999/dashboard.js\"></script> --> <script type=\"text/javascript\" src=\"dashboard.js?v20170105-7\"></script> <script> // Set options for TV operation // This has to be done, after dashboard.js is loaded // destroy charts not shown (lowers memory on the browser) NETDATA.options.current.destroy_on_hide = true; // set this to false, to always show all dimensions //NETDATA.options.current.eliminate_zero_dimensions = true; // lower the pressure on this browser //NETDATA.options.current.concurrent_refreshes = false; // if the tv browser is too slow (a pi?) // set this to false //NETDATA.options.current.parallel_refresher = true; // always update the charts, even if focus is lost NETDATA.options.current.stop_updates_when_focus_is_lost = false; // Since you may render charts from many servers and any of them may // become offline for some time, the charts will break. // This will reload the page every RELOAD_EVERY minutes var RELOAD_EVERY = 1; setTimeout(function(){ location.reload(); }, RELOAD_EVERY * 60 * 1000); </script> </html>","title":"Bonus HTML for system overview"},{"location":"blog/spice-up-your-homepage-part-ii/","text":"Spice up your homepage Part II \u00b6 I thought I'd make a follow up to the first post on customizing your Organizr homepage. This will tell you how to add Grafana panels, a custom Monitorr dashboard, custom buttons and links to tabs inside Organizr. Using Grafana and Varken to add more Plex stats on your Organizr homepage. \u00b6 With Grafana, InfluxDB and Varken we can add some cool plex stats to the dashboard using html and css. And if you install telegraf you can get some great host metrics also. Here is a screenshot of the stats I currently have on my Homepage. All the panels are data from InfluxDB sent by Varken. I'm running nightly so I can have Varken pull download and upload data from my Ubiquiti Unifi Security Gateway . However, if you don't use Unifi you can setup telegraf and that will give you the same stats from the host machine. Installing InfluxDB \u00b6 Installing influxdb from CA is dead simple. You only need to select the host path for /var/lib/influxdb and change the host port if its in use. Varken will automatically create the database for you. Installing Varken \u00b6 I'm using the docker container from the devs, and since it's not currently on the CA Appstore you will have to add it manually. EDIT 16.03.19: They have added it to the CA appstore! Search for Varken and click on Click Here To Get More Results From DockerHub If you can't see that link you need to enable additional dockerHub search results in CA Settings. Select **boerderij/varken** and add the PGID and PUID and mount the appdata folder to /config. Varken doesn't need a port as \"all\" it does is feed influxdb with data it pulls from Tautulli, Ombi, Sonarr, Radarr ect. Set PGID to 100 and PUID to 99 Setting up Varken is quite simple. Head over to your appdata folder and copy paste the varken.example.ini file and rename it varken.ini In that file you add the connection details to all the services you want it to pull data from. Read through the configuration wiki for setup details. Tip: don't use the scheme(http://) when adding the different IPs. And if any of your services uses base url you need to add that. Installing Grafana \u00b6 Follow the instructions and add your unraid/host ip and admin password. **GF_SERVER_ROOT_URL:**The url to which you will be navigating to get to the grafana dashboard. Typically your ip or hostname **GF_SECURITY_ADMIN_PASSWORD**Your password to use with the admin user. The default is user admin with password the password you chose. When Installing from CA you will need to add one variable to be able to view dashboards without logging in. Now you don't have to add it, but you will need to log into Grafana before you'll be able to see the stats of each panel on your Organizr homepage. First install the container without the variable as we need to mount the custom.ini file in our appdata, and the file needs to exist before we can mount it. After you've installed the container you need to add two plugins for the Varken dashboards. The dashboards will fail to load without them. Now, I'm only using the worldmap plugin on my homepage but you might as well install them both. Open terminal and run: **docker exec -i -t Grafana grafana-cli plugins install grafana-piechart-panel** and **docker exec -i -t Grafana grafana-cli plugins install grafana-worldmap-panel** Next go to you appdata location for Grafana and create the custom.ini file with the contents below: [auth.anonymous] enabled=true The variable you need to add is**GF_PATHS_CONFIG** and the value is **/var/lib/grafana/custom.ini** Like so: -e \"GF_PATHS_CONFIG=/var/lib/grafana/custom.ini\" Note: Any new dashboard you create will be visible to anyone when you add this, so beware. Protect your reverse proxy with Organizr server auth. You can also choose which dashboards are open in dashboard settings. (Remove viewer role in permissions) Tip: You can create different organizations in Grafana and set the organization that you want open without auth. Like this: [auth.anonymous] enabled=true org_name=<organization_name> Update : Grafana recently added iframe protection so you will need to disable that. It can be done in two ways. Editing the custom.ini or adding a header in your webserver. Add: [security] allow_embedding = true in custom.ini Or proxy_hide_header X-Frame-Options; in your reverse proxy. After you've added the variable log in to Grafana and add your datasource. Go to \"Configuration\" and click + Add data source. Choose type InfluxDB Call it Varken Add your URL to InfluxDB And add the database varken (lower case) Click Save & Test After you have finished setting it up you can head over here to find the Varken dashboards that you can import. Check the links below and paste in the dashboard ID and follow the steps on the screen. https://grafana.com/dashboards?search=Varken You can find the stream breakdown and daily play count panels here: https://grafana.com/dashboards/9684 Add the dashboards you want. If you're using my dashboards select the correct datasource in the drop down like below. https://grafana.com/grafana/dashboards/9558 After you've done that your should be able to see stats from the varken database. The way I have my dashboards setup is the main Varken dash is closed for \"visitors\" and I have a separate one for my Organizr homepage that is open. But it's not really open as it's behind Organizr server auth. So grafana.domain.com is only accessible to my Organizr users and me. Grafana will need to be reverse proxied as you can't access the local instance of Grafana when accessing Organizr through your domain. For a reverse proxy example of Grafana look here: https://github.com/gilbN/Nostromo/blob/master/Server/nginx/site-confs/grafana Organizr Homepage \u00b6 Below is the custom HTML that you can use add the different panels you want to the Organizr homepage. Replace the source of each HTML class on this line. src='https://grafana.domain.com/d-solo/bj0JnBMmz/org-dash?refresh=5s&orgId=1&panelId=22'/> The first six are the small \"widgets\" and the last three are the bigger ones. If you don't want the big widgets you can just delete everything between <!-- -------------------BIG WIDGET START------------------- --> and **<!-- -------------------BIG WIDGET END------------------- -->** And if you want fewer small widgets just delete everything between: <!-- -------------------WIDGET------------------- --> To find the correct URL of each panel you just have to click on the name of the panel and select share, then select the Embed tab. **Remember to remove the \"Current time range\" as that will break the stats. **Don't copy it all, we just need the iframe source. If you want to change the title of the custom html you can do so here: <!-- -------------------ADD TITLE HERE------------------- --> <div id=\"announcementRow\" class=\"row\"><h4 class=\"pull-left\"> <span>YOUR-TITLE-HERE</span></h4><hr class=\"hidden-xs\"></div> Each panel can link directly to a tab inside Organizr. For that to work you need to edit this line: <div class=\"iframe-link\" onclick=\"tabActions(event,'TAB-NAME-HERE',1);\" href=\"#\" title=\"TITLE-HERE\"></div> Replace** TAB-NAME-HERE with the actual tab name in Organizr. For the hover title, replace TITLE-HERE **or just remove it if you don't want the title attribute. If you don't want it to link to a tab simply remove the whole div. ` .flex { display: flex; flex-wrap: wrap; flex-direction: row; align-items: center; background: transparent; box-shadow: none !important; transition: all .4s ease-in-out; cursor: pointer }</p> <p>/* -------------------Small widget------------------- */ .flex-child { padding: 3px; flex-grow: 1; flex-basis: 0;}</p> <h1 calc_100_=\"calc(100%);\" calc_80px_=\"calc(80px);\" height:=\"height:\" id=\"grafanadwidget\" position:=\"position:\" relative_=\"relative;\" width:=\"width:\">grafanadwidget<a class=\"headerlink\" href=\"#grafanadwidget\" title=\"Permanent link\">&para;</a></h1> <p>/* -------------------Small widget------------------- */</p> <p>/* -------------------Big widget------------------- */ .flex-child-big { padding: 3px; flex-grow: 1; flex-basis: 0;}</p> <h1 calc_100_=\"calc(100%);\" calc_250px_=\"calc(250px);\" height:=\"height:\" id=\"grafanadwidget-big\" position:=\"position:\" relative_=\"relative;\" width:=\"width:\">grafanadwidget-big<a class=\"headerlink\" href=\"#grafanadwidget-big\" title=\"Permanent link\">&para;</a></h1> <p>/* -------------------Big widget------------------- */</p> <p>/* -------------------iFrame Link------------------- <em>/ .iframe-link { z-index:1; position:absolute; height: calc(80px); width: calc(100%); background-color: transparent; cursor: pointer} /</em> -------------------iFrame Link------------------- */</p> <h1 _important_=\"!important;\" background-color:transparent=\"background-color:transparent\" id=\"announcementrow\">announcementRow<a class=\"headerlink\" href=\"#announcementrow\" title=\"Permanent link\">&para;</a></h1> <h1 id=\"announcementrowh4\">announcementRow&gt;h4 {<a class=\"headerlink\" href=\"#announcementrowh4\" title=\"Permanent link\">&para;</a></h1> <div class=\"codehilite\"><pre><span></span><code><span class=\"nt\">padding-left</span><span class=\"o\">:</span> <span class=\"nt\">15px</span><span class=\"o\">;</span> <span class=\"nt\">font-family</span><span class=\"o\">:</span> <span class=\"nt\">Rubik</span><span class=\"o\">,</span><span class=\"nt\">sans-serif</span><span class=\"o\">;</span> <span class=\"nt\">margin</span><span class=\"o\">:</span> <span class=\"nt\">10px</span> <span class=\"nt\">0</span><span class=\"o\">;</span> <span class=\"nt\">font-weight</span><span class=\"o\">:</span> <span class=\"nt\">300</span> <span class=\"o\">!</span><span class=\"nt\">important</span><span class=\"o\">;</span> <span class=\"nt\">line-height</span><span class=\"o\">:</span> <span class=\"nt\">22px</span><span class=\"o\">;</span> <span class=\"nt\">font-size</span><span class=\"o\">:</span> <span class=\"nt\">18px</span><span class=\"o\">;</span> <span class=\"nt\">color</span><span class=\"o\">:</span> <span class=\"p\">#</span><span class=\"nn\">dce2ec</span><span class=\"o\">;</span> </code></pre></div> <p>} .overflowhider { height: 100%; overflow: hidden;} @media only screen and (max-width: 650px) {.flex-child-big {flex-basis: auto;min-width: auto !important;}} @media only screen and (max-width: 1125px) {.flex-child-big {flex-basis: auto;min-width: 600px;flex-basis: fit-content;}} @media only screen and (max-width: 1649px) {.flex-child {flex-basis: auto;}} Grafana <div class= \"content-box flex\" > <!-- -------------------WIDGET------------------- --> <div class= \"flex-child\" id= \"flex-grafanadwidget\" > <div class= \"overflowhider\" > <div class= \"iframe-link\" onclick= \"tabActions(event,'TAB-NAME-HERE',1);\" href= \"#\" title= \"TITLE-HERE\" ></div> <iframe class= \"iframe\" id= \"grafanadwidget\" frameborder= \"0\" src= \"ADD-URL-TO-GRAFANA-PANEL-HERE\" ></iframe> </div></div> <!-- -------------------WIDGET------------------- --> <div class= \"flex-child\" id= \"flex-grafanadwidget\" > <div class= \"overflowhider\" > <div class= \"iframe-link\" onclick= \"tabActions(event,'TAB-NAME-HERE',1);\" href= \"#\" title= \"TITLE-HERE\" ></div> <iframe class= \"iframe\" id= \"grafanadwidget\" frameborder= \"0\" src= \"ADD-URL-TO-GRAFANA-PANEL-HERE\" ></iframe> </div></div> <!-- -------------------WIDGET------------------- --> <div class= \"flex-child\" id= \"flex-grafanadwidget\" > <div class= \"overflowhider\" > <div class= \"iframe-link\" onclick= \"tabActions(event,'TAB-NAME-HERE',1);\" href= \"#\" title= \"TITLE-HERE\" ></div> <iframe class= \"iframe\" id= \"grafanadwidget\" frameborder= \"0\" src= \"ADD-URL-TO-GRAFANA-PANEL-HERE\" ></iframe> </div></div> <!-- -------------------WIDGET------------------- --> <div class= \"flex-child\" id= \"flex-grafanadwidget\" > <div class= \"overflowhider\" > <div class= \"iframe-link\" onclick= \"tabActions(event,'TAB-NAME-HERE',1);\" href= \"#\" title= \"TITLE-HERE\" ></div> <iframe class= \"iframe\" id= \"grafanadwidget\" frameborder= \"0\" src= \"ADD-URL-TO-GRAFANA-PANEL-HERE\" ></iframe> </div></div> <!-- -------------------WIDGET------------------- --> <div class= \"flex-child\" id= \"flex-grafanadwidget\" > <div class= \"overflowhider\" > <div class= \"iframe-link\" onclick= \"tabActions(event,'TAB-NAME-HERE',1);\" href= \"#\" title= \"TITLE-HERE\" ></div> <iframe class= \"iframe\" id= \"grafanadwidget\" frameborder= \"0\" src= \"ADD-URL-TO-GRAFANA-PANEL-HERE\" ></iframe> </div></div> <!-- -------------------WIDGET------------------- --> <div class= \"flex-child\" id= \"flex-grafanadwidget\" > <div class= \"overflowhider\" > <div class= \"iframe-link\" onclick= \"tabActions(event,'TAB-NAME-HERE',1);\" href= \"#\" title= \"TITLE-HERE\" ></div> <iframe class= \"flex\" id= \"grafanadwidget\" frameborder= \"0\" src= \"ADD-URL-TO-GRAFANA-PANEL-HERE\" ></iframe> </div></div> ` Custom CSS \u00b6 For the widgets to match the Organizr theme you need to use custom CSS. You can do that by checking out my themes here. https://github.com/gilbN/theme.park/blob/master/README.md#grafana-themes \u00b6 As Grafana doesn't support custom CSS you will need to use subfilter with nginx. Add this in you reverse proxy of Grafana: proxy_set_header Accept-Encoding \"\"; sub_filter '</head>' '<link rel=\"stylesheet\" type=\"text/css\" href=\"https://gilbn.github.io/theme.park/CSS/themes/grafana/dark.css\"> </head>'; sub_filter_once on; For the plex/aquamarine/hotline themes you can use the graforg-dashboard.css instead. For panel integration on the Organizr homepage you can use organizr-dashboard.css if you use any of the custom themes. The theme is an \"internal\" theme that is meant to be used in an Organizr iframe as the background is set to transparent. NOTE: When viewing Grafana in Organizr iframe using organizr-dashboard.css it will follow the Organizr theme. When viewing it outside of Organizr iframe the background will be white ect. If you don't want this you can create two reverse proxies. One for grafana organizr homepage integration and one for the regular grafana theme. Custom buttons \u00b6 Custom buttons is very easy to add. Just choose your flavor from the organizrTools repo and you're pretty much done! You can have buttons that link directly to tabs or buttons that uses Organizr built in functions like speed test or the request content function. You can even link to tabs through html links. <a onclick=\"tabActions(event,'TAB NAME',1);\" href=\"#\">CUSTOM LINK TEXT</a> https://github.com/organizrTools/orgv2 _custom_buttons I chose to edit the css a bit: .cbutton { border-radius: 3px; border: 4px solid; border-color: #e5a00d; padding: 0px; width: auto; height: auto; background-color: #e5a00d; position: relative; text-align: center; } Monitorr \u00b6 Monitorr is a live display over the status of any webapp or service. And with some custom CSS we can have it match the Organizr-theme much better than the original. By using my **dark.css** theme from my theme.park repo you get a theme that blends with Organizr and it will compress the tiles a little so you can have more services on display. If you use a custom theme with organizr I reccoment the organizr-dashboard.css This theme will mess with your Monitorr base theme. And it will hide the settings button. Go to /monitorr/settings.php for settings. It is created purely for use with \"minimum\" version of the index.php https://domain.com/monitorr/index.min.php for Organizr homepage integration. NOTE: When viewing monitorr in an Organizr iframe using organizr-dashboard.css it will follow the Organizr theme as the background is transparent. When viewing it outside of Organizr iframe the background will be white ect. If you don't want this you can create two reverse proxies. One for monitorr organizr homepage integration and one for the other monitorr themes. And use subfilter on both instead of adding @import \"https://gilbn.github.io/theme.park/CSS/themes/organizr-dashboard.css\"; in the monitorr custom css. Adding the theme with Nginx. \u00b6 Add this to your Montorr minimized reverse proxy: proxy_set_header Accept-Encoding \"\"; sub_filter '</head>' '<link rel=\"stylesheet\" type=\"text/css\" href=\"https://gilbn.github.io/theme.park/CSS/themes/monitorr/organizr-dashboard.css\"> </head>'; sub_filter_once on; And the** dark/aquamarine/hotline.css ** on your main Monitorr reverse proxy. Adding it to Organizr is as simple as pasting this in custom HTML and changing the domain. <div id=\"announcementRow\" class=\"row\"><h4 class=\"pull-left\"><span>Monitorr</span></h4><hr class=\"hidden-xs\"></div> <div style=\"overflow:hidden; height:260px; -webkit-overflow-scrolling: touch; overflow-y: scroll;\"> <iframe class=\"iframe\" frameborder=\"0\" src=\"https://monitorr.domain.com/index.min.php\"></iframe> </div> It's the** /index.min.php ** that will display the minimized version. If you want to hide the scroll bar you can change the div style to <div style=\"overflow:hidden; height:260px\"> (FYI This will disable scrolling) Or you can do <div style=\"overflow:hidden; height:260px; width: calc(100% + 42px); -webkit-overflow-scrolling: touch; overflow-y: scroll;\"> if you use Firefox or <div style=\"overflow:hidden; height:260px; width: calc(100% + 36px); -webkit-overflow-scrolling: touch; overflow-y: scroll;\"> if you use Chrome. Custom title \u00b6 If you want to add a custom title to your different customizations you can simply add this line above it and replace the** YOUR-CUSTOM-TITLE **text with what you want. <div id=\"announcementRow\" class=\"row\"><h4 class=\"pull-left\"><span>YOUR-CUSTOM-TITLE</span></h4><hr class=\"hidden-xs\"></div> If you have any other awesome homepage customization please let me know in the comments! Edit: Thank you CauseFX for the iFrame fix!\u2764\ufe0f If you need any extra help join the Discord server! \u00b6 \u00b6","title":"Spice up your homepage Part II"},{"location":"blog/spice-up-your-homepage-part-ii/#spice-up-your-homepage-part-ii","text":"I thought I'd make a follow up to the first post on customizing your Organizr homepage. This will tell you how to add Grafana panels, a custom Monitorr dashboard, custom buttons and links to tabs inside Organizr.","title":"Spice up your homepage Part II"},{"location":"blog/spice-up-your-homepage-part-ii/#using-grafana-and-varken-to-add-more-plex-stats-on-your-organizr-homepage","text":"With Grafana, InfluxDB and Varken we can add some cool plex stats to the dashboard using html and css. And if you install telegraf you can get some great host metrics also. Here is a screenshot of the stats I currently have on my Homepage. All the panels are data from InfluxDB sent by Varken. I'm running nightly so I can have Varken pull download and upload data from my Ubiquiti Unifi Security Gateway . However, if you don't use Unifi you can setup telegraf and that will give you the same stats from the host machine.","title":"Using Grafana and Varken to add more Plex stats on your Organizr homepage."},{"location":"blog/spice-up-your-homepage-part-ii/#installing-influxdb","text":"Installing influxdb from CA is dead simple. You only need to select the host path for /var/lib/influxdb and change the host port if its in use. Varken will automatically create the database for you.","title":"Installing InfluxDB"},{"location":"blog/spice-up-your-homepage-part-ii/#installing-varken","text":"I'm using the docker container from the devs, and since it's not currently on the CA Appstore you will have to add it manually. EDIT 16.03.19: They have added it to the CA appstore! Search for Varken and click on Click Here To Get More Results From DockerHub If you can't see that link you need to enable additional dockerHub search results in CA Settings. Select **boerderij/varken** and add the PGID and PUID and mount the appdata folder to /config. Varken doesn't need a port as \"all\" it does is feed influxdb with data it pulls from Tautulli, Ombi, Sonarr, Radarr ect. Set PGID to 100 and PUID to 99 Setting up Varken is quite simple. Head over to your appdata folder and copy paste the varken.example.ini file and rename it varken.ini In that file you add the connection details to all the services you want it to pull data from. Read through the configuration wiki for setup details. Tip: don't use the scheme(http://) when adding the different IPs. And if any of your services uses base url you need to add that.","title":"Installing Varken"},{"location":"blog/spice-up-your-homepage-part-ii/#installing-grafana","text":"Follow the instructions and add your unraid/host ip and admin password. **GF_SERVER_ROOT_URL:**The url to which you will be navigating to get to the grafana dashboard. Typically your ip or hostname **GF_SECURITY_ADMIN_PASSWORD**Your password to use with the admin user. The default is user admin with password the password you chose. When Installing from CA you will need to add one variable to be able to view dashboards without logging in. Now you don't have to add it, but you will need to log into Grafana before you'll be able to see the stats of each panel on your Organizr homepage. First install the container without the variable as we need to mount the custom.ini file in our appdata, and the file needs to exist before we can mount it. After you've installed the container you need to add two plugins for the Varken dashboards. The dashboards will fail to load without them. Now, I'm only using the worldmap plugin on my homepage but you might as well install them both. Open terminal and run: **docker exec -i -t Grafana grafana-cli plugins install grafana-piechart-panel** and **docker exec -i -t Grafana grafana-cli plugins install grafana-worldmap-panel** Next go to you appdata location for Grafana and create the custom.ini file with the contents below: [auth.anonymous] enabled=true The variable you need to add is**GF_PATHS_CONFIG** and the value is **/var/lib/grafana/custom.ini** Like so: -e \"GF_PATHS_CONFIG=/var/lib/grafana/custom.ini\" Note: Any new dashboard you create will be visible to anyone when you add this, so beware. Protect your reverse proxy with Organizr server auth. You can also choose which dashboards are open in dashboard settings. (Remove viewer role in permissions) Tip: You can create different organizations in Grafana and set the organization that you want open without auth. Like this: [auth.anonymous] enabled=true org_name=<organization_name> Update : Grafana recently added iframe protection so you will need to disable that. It can be done in two ways. Editing the custom.ini or adding a header in your webserver. Add: [security] allow_embedding = true in custom.ini Or proxy_hide_header X-Frame-Options; in your reverse proxy. After you've added the variable log in to Grafana and add your datasource. Go to \"Configuration\" and click + Add data source. Choose type InfluxDB Call it Varken Add your URL to InfluxDB And add the database varken (lower case) Click Save & Test After you have finished setting it up you can head over here to find the Varken dashboards that you can import. Check the links below and paste in the dashboard ID and follow the steps on the screen. https://grafana.com/dashboards?search=Varken You can find the stream breakdown and daily play count panels here: https://grafana.com/dashboards/9684 Add the dashboards you want. If you're using my dashboards select the correct datasource in the drop down like below. https://grafana.com/grafana/dashboards/9558 After you've done that your should be able to see stats from the varken database. The way I have my dashboards setup is the main Varken dash is closed for \"visitors\" and I have a separate one for my Organizr homepage that is open. But it's not really open as it's behind Organizr server auth. So grafana.domain.com is only accessible to my Organizr users and me. Grafana will need to be reverse proxied as you can't access the local instance of Grafana when accessing Organizr through your domain. For a reverse proxy example of Grafana look here: https://github.com/gilbN/Nostromo/blob/master/Server/nginx/site-confs/grafana","title":"Installing Grafana"},{"location":"blog/spice-up-your-homepage-part-ii/#organizr-homepage","text":"Below is the custom HTML that you can use add the different panels you want to the Organizr homepage. Replace the source of each HTML class on this line. src='https://grafana.domain.com/d-solo/bj0JnBMmz/org-dash?refresh=5s&orgId=1&panelId=22'/> The first six are the small \"widgets\" and the last three are the bigger ones. If you don't want the big widgets you can just delete everything between <!-- -------------------BIG WIDGET START------------------- --> and **<!-- -------------------BIG WIDGET END------------------- -->** And if you want fewer small widgets just delete everything between: <!-- -------------------WIDGET------------------- --> To find the correct URL of each panel you just have to click on the name of the panel and select share, then select the Embed tab. **Remember to remove the \"Current time range\" as that will break the stats. **Don't copy it all, we just need the iframe source. If you want to change the title of the custom html you can do so here: <!-- -------------------ADD TITLE HERE------------------- --> <div id=\"announcementRow\" class=\"row\"><h4 class=\"pull-left\"> <span>YOUR-TITLE-HERE</span></h4><hr class=\"hidden-xs\"></div> Each panel can link directly to a tab inside Organizr. For that to work you need to edit this line: <div class=\"iframe-link\" onclick=\"tabActions(event,'TAB-NAME-HERE',1);\" href=\"#\" title=\"TITLE-HERE\"></div> Replace** TAB-NAME-HERE with the actual tab name in Organizr. For the hover title, replace TITLE-HERE **or just remove it if you don't want the title attribute. If you don't want it to link to a tab simply remove the whole div. ` .flex { display: flex; flex-wrap: wrap; flex-direction: row; align-items: center; background: transparent; box-shadow: none !important; transition: all .4s ease-in-out; cursor: pointer }</p> <p>/* -------------------Small widget------------------- */ .flex-child { padding: 3px; flex-grow: 1; flex-basis: 0;}</p> <h1 calc_100_=\"calc(100%);\" calc_80px_=\"calc(80px);\" height:=\"height:\" id=\"grafanadwidget\" position:=\"position:\" relative_=\"relative;\" width:=\"width:\">grafanadwidget<a class=\"headerlink\" href=\"#grafanadwidget\" title=\"Permanent link\">&para;</a></h1> <p>/* -------------------Small widget------------------- */</p> <p>/* -------------------Big widget------------------- */ .flex-child-big { padding: 3px; flex-grow: 1; flex-basis: 0;}</p> <h1 calc_100_=\"calc(100%);\" calc_250px_=\"calc(250px);\" height:=\"height:\" id=\"grafanadwidget-big\" position:=\"position:\" relative_=\"relative;\" width:=\"width:\">grafanadwidget-big<a class=\"headerlink\" href=\"#grafanadwidget-big\" title=\"Permanent link\">&para;</a></h1> <p>/* -------------------Big widget------------------- */</p> <p>/* -------------------iFrame Link------------------- <em>/ .iframe-link { z-index:1; position:absolute; height: calc(80px); width: calc(100%); background-color: transparent; cursor: pointer} /</em> -------------------iFrame Link------------------- */</p> <h1 _important_=\"!important;\" background-color:transparent=\"background-color:transparent\" id=\"announcementrow\">announcementRow<a class=\"headerlink\" href=\"#announcementrow\" title=\"Permanent link\">&para;</a></h1> <h1 id=\"announcementrowh4\">announcementRow&gt;h4 {<a class=\"headerlink\" href=\"#announcementrowh4\" title=\"Permanent link\">&para;</a></h1> <div class=\"codehilite\"><pre><span></span><code><span class=\"nt\">padding-left</span><span class=\"o\">:</span> <span class=\"nt\">15px</span><span class=\"o\">;</span> <span class=\"nt\">font-family</span><span class=\"o\">:</span> <span class=\"nt\">Rubik</span><span class=\"o\">,</span><span class=\"nt\">sans-serif</span><span class=\"o\">;</span> <span class=\"nt\">margin</span><span class=\"o\">:</span> <span class=\"nt\">10px</span> <span class=\"nt\">0</span><span class=\"o\">;</span> <span class=\"nt\">font-weight</span><span class=\"o\">:</span> <span class=\"nt\">300</span> <span class=\"o\">!</span><span class=\"nt\">important</span><span class=\"o\">;</span> <span class=\"nt\">line-height</span><span class=\"o\">:</span> <span class=\"nt\">22px</span><span class=\"o\">;</span> <span class=\"nt\">font-size</span><span class=\"o\">:</span> <span class=\"nt\">18px</span><span class=\"o\">;</span> <span class=\"nt\">color</span><span class=\"o\">:</span> <span class=\"p\">#</span><span class=\"nn\">dce2ec</span><span class=\"o\">;</span> </code></pre></div> <p>} .overflowhider { height: 100%; overflow: hidden;} @media only screen and (max-width: 650px) {.flex-child-big {flex-basis: auto;min-width: auto !important;}} @media only screen and (max-width: 1125px) {.flex-child-big {flex-basis: auto;min-width: 600px;flex-basis: fit-content;}} @media only screen and (max-width: 1649px) {.flex-child {flex-basis: auto;}}","title":"Organizr Homepage"},{"location":"blog/spice-up-your-homepage-part-ii/#custom-css","text":"For the widgets to match the Organizr theme you need to use custom CSS. You can do that by checking out my themes here.","title":"Custom CSS"},{"location":"blog/spice-up-your-homepage-part-ii/#httpsgithubcomgilbnthemeparkblobmasterreadmemdgrafana-themes","text":"As Grafana doesn't support custom CSS you will need to use subfilter with nginx. Add this in you reverse proxy of Grafana: proxy_set_header Accept-Encoding \"\"; sub_filter '</head>' '<link rel=\"stylesheet\" type=\"text/css\" href=\"https://gilbn.github.io/theme.park/CSS/themes/grafana/dark.css\"> </head>'; sub_filter_once on; For the plex/aquamarine/hotline themes you can use the graforg-dashboard.css instead. For panel integration on the Organizr homepage you can use organizr-dashboard.css if you use any of the custom themes. The theme is an \"internal\" theme that is meant to be used in an Organizr iframe as the background is set to transparent. NOTE: When viewing Grafana in Organizr iframe using organizr-dashboard.css it will follow the Organizr theme. When viewing it outside of Organizr iframe the background will be white ect. If you don't want this you can create two reverse proxies. One for grafana organizr homepage integration and one for the regular grafana theme.","title":"https://github.com/gilbN/theme.park/blob/master/README.md#grafana-themes"},{"location":"blog/spice-up-your-homepage-part-ii/#custom-buttons","text":"Custom buttons is very easy to add. Just choose your flavor from the organizrTools repo and you're pretty much done! You can have buttons that link directly to tabs or buttons that uses Organizr built in functions like speed test or the request content function. You can even link to tabs through html links. <a onclick=\"tabActions(event,'TAB NAME',1);\" href=\"#\">CUSTOM LINK TEXT</a> https://github.com/organizrTools/orgv2 _custom_buttons I chose to edit the css a bit: .cbutton { border-radius: 3px; border: 4px solid; border-color: #e5a00d; padding: 0px; width: auto; height: auto; background-color: #e5a00d; position: relative; text-align: center; }","title":"Custom buttons"},{"location":"blog/spice-up-your-homepage-part-ii/#monitorr","text":"Monitorr is a live display over the status of any webapp or service. And with some custom CSS we can have it match the Organizr-theme much better than the original. By using my **dark.css** theme from my theme.park repo you get a theme that blends with Organizr and it will compress the tiles a little so you can have more services on display. If you use a custom theme with organizr I reccoment the organizr-dashboard.css This theme will mess with your Monitorr base theme. And it will hide the settings button. Go to /monitorr/settings.php for settings. It is created purely for use with \"minimum\" version of the index.php https://domain.com/monitorr/index.min.php for Organizr homepage integration. NOTE: When viewing monitorr in an Organizr iframe using organizr-dashboard.css it will follow the Organizr theme as the background is transparent. When viewing it outside of Organizr iframe the background will be white ect. If you don't want this you can create two reverse proxies. One for monitorr organizr homepage integration and one for the other monitorr themes. And use subfilter on both instead of adding @import \"https://gilbn.github.io/theme.park/CSS/themes/organizr-dashboard.css\"; in the monitorr custom css.","title":"Monitorr"},{"location":"blog/spice-up-your-homepage-part-ii/#adding-the-theme-with-nginx","text":"Add this to your Montorr minimized reverse proxy: proxy_set_header Accept-Encoding \"\"; sub_filter '</head>' '<link rel=\"stylesheet\" type=\"text/css\" href=\"https://gilbn.github.io/theme.park/CSS/themes/monitorr/organizr-dashboard.css\"> </head>'; sub_filter_once on; And the** dark/aquamarine/hotline.css ** on your main Monitorr reverse proxy. Adding it to Organizr is as simple as pasting this in custom HTML and changing the domain. <div id=\"announcementRow\" class=\"row\"><h4 class=\"pull-left\"><span>Monitorr</span></h4><hr class=\"hidden-xs\"></div> <div style=\"overflow:hidden; height:260px; -webkit-overflow-scrolling: touch; overflow-y: scroll;\"> <iframe class=\"iframe\" frameborder=\"0\" src=\"https://monitorr.domain.com/index.min.php\"></iframe> </div> It's the** /index.min.php ** that will display the minimized version. If you want to hide the scroll bar you can change the div style to <div style=\"overflow:hidden; height:260px\"> (FYI This will disable scrolling) Or you can do <div style=\"overflow:hidden; height:260px; width: calc(100% + 42px); -webkit-overflow-scrolling: touch; overflow-y: scroll;\"> if you use Firefox or <div style=\"overflow:hidden; height:260px; width: calc(100% + 36px); -webkit-overflow-scrolling: touch; overflow-y: scroll;\"> if you use Chrome.","title":"Adding the theme with Nginx."},{"location":"blog/spice-up-your-homepage-part-ii/#custom-title","text":"If you want to add a custom title to your different customizations you can simply add this line above it and replace the** YOUR-CUSTOM-TITLE **text with what you want. <div id=\"announcementRow\" class=\"row\"><h4 class=\"pull-left\"><span>YOUR-CUSTOM-TITLE</span></h4><hr class=\"hidden-xs\"></div> If you have any other awesome homepage customization please let me know in the comments! Edit: Thank you CauseFX for the iFrame fix!\u2764\ufe0f","title":"Custom title"},{"location":"blog/spice-up-your-homepage-part-ii/#if-you-need-any-extra-help-join-the-discord-server","text":"","title":"If you need any extra help join the Discord server!"},{"location":"blog/spice-up-your-homepage-part-ii/#_1","text":"","title":""},{"location":"blog/visualizing-nginx-geo-data-metrics-with-python-influxdb-and-grafana/","text":"Visualizing Nginx geo data metrics with Python, InfluxDB and Grafana \u00b6 A couple of weeks ago I saw someone posted an article on on the LinuxServer discord describing how to send geo data statistics from Nginx to InfluxDB. I have seen similar articles in the past and I always wanted to try it out, and because adding new dashboards to Grafana is always fun :) Note For people not using the letsencrypt/swag container, I've added a standalone container you can use here: https://github.com/gilbN/geoip2influx The article was a couple of years old so he was using the now deprecated maxmind geoip database. But the rest of the Nginx configs looked just fine. As for the sending of the geo data metrics to InfluxDB, he was using a python2 script. Having recently started using Roxedus's Fail2Ban docker mod for the linuxserver swag container, I thought that would be an excellent way of running it. So I looked at how Roxedus set up his mod and used that as a template for building mine. Getting the script to work was simple enough, I just needed to adapt it for python3 and change a couple of small things, like adding environment variables for use with docker. I also tried to get Telegraf to parse the Nginx logs like he did in his guide, but it only parsed the logs once and didn't continue to send new log lines to InfluxDB. So I decided to make python parse it instead. Adding the docker mod to the swag container \u00b6 Influx version Only InfluxDB v1.8.x supported! The mod is added using docker environment variables. The first one you need is -e DOCKER_MODS=linuxserver/mods:swag-geoip2influx Here is a link to the repo if you want to have a look: https://github.com/gilbN/lsio-docker-mods/blob/master/letsencrypt/geoip2-nginx-stats Update 06.09.2020: I made a PR on the official linuxserver/docker-mods repo, and it' now been added there. https://github.com/linuxserver/docker-mods/tree/swag-geoip2influx The python script has some default variables added already, so you only need to add the ones that's different for your system. The available and default variables are: -e NGINX_LOG_PATH=/config/log/nginx/access.log -e INFLUX_HOST=localhost -e INFLUX_HOST_PORT=8086 -e INFLUX_DATABASE=geoip2influx -e INFLUX_USER=root -e INFLUX_PASS=root -e INFLUX_RETENTION=7d -e INFLUX_SHARD=2d -e GEO_MEASUREMENT=geoip2influx -e LOG_MEASUREMENT=nginx_access_logs -e SEND_NGINX_LOGS=true -e GEOIP2INFLUX_LOG_LEVEL=INFO -e GEOIP2INFLUX_LOG_PATH=/config/log/geoip2influx/geoip2influx.log Most of them should be self explanatory, so I'll just add some comments on a couple of them. -e INFLUX_HOST=localhost Since you will be setting this up inside the swag container, the default value will not work unless you are running the container with host networking and InfluxDB is installed on the same host. So change this to your host IP/docker dns name. GEO_MEASUREMENT=geoip2influx and -e LOG_MEASUREMENT=nginx_access_logs These are just the measurement names that will be sent to InfluxDB. -e INFLUX_DATABASE=geoip2influx The database will be created automatically by the python script, so no need to create one beforehand. -e INFLUX_RETENTION and -e INFLUX_SHARD Update 06.06.20 : To try and mitigate max-values-per-tag limit exceeded errors I've added retention to the database. It will only add the retention policy if the database doesn't exist. Read more about retention policies here: https://www.influxdata.com/blog/influxdb-shards-retention-policies/ and https://docs.influxdata.com/influxdb/v1.2/concepts/key_concepts/#retention-policy -e MAXMINDDB_LICENSE_KEY=<license-key> Update 15.05.20 : The swag container now natively supports downloading the geoip2 database with the use of the MAXMINDDB_LICENSE_KEY variable. Add your MaxMind Geoip2 license key and it will automatically download the latest database and update it weekly . The default download location is /config/geoip2db/GeoLite2-City.mmdb . If you're unsure how to obtain a licensekey, check out the first part of my geolite2 guide . -e GEOIP2INFLUX_LOG_LEVEL=INFO The script will automatically create a log file in the directory that -e GEOIP2INFLUX_LOG_PATH is set to. Set this to DEBUG for troubleshooting. Nginx log metrics \u00b6 swag geolite2 instructions: https://technicalramblings.com/blog/blocking-countries-with-geolite2-using-the-letsencrypt-docker-container/ For python to be able to parse the nginx logs correctly you need to update your nginx configs with a couple of lines. Add the following in the http block in your nginx.conf file: geoip2 /config/geoip2db/GeoLite2-City.mmdb { auto_reload 5m ; $geoip2_data_country_iso_code country iso_code ; $geoip2_data_city_name city names en ; } log_format custom ' $remote_addr - $remote_user [ $time_local]' '\" $request\" $status $body_bytes_sent' '\" $http_referer\" $host \" $http_user_agent\"' '\" $request_time\" \" $upstream_connect_time\"' '\" $geoip2_data_city_name\" \" $geoip2_data_country_iso_code\"' ; Set the access log use the custom log format. access_log /config/log/nginx/access.log custom ; The first time the scripts starts it will try and parse the log for 1 minute and if the regex doesn't match it will disable the log metrics. So be sure to refresh your site a couple of times after adding the mod. Next add a new datasource to Grafana with the name of the database you chose and import the dashboard and you should start seeing the map getting populated! Multiple log files \u00b6 If you separate your nginx log files but want this mod to parse all of them you can do the following: As nginx can have multiple access log directives in a block, just add another one in the server block. Example access_log /config/log/nginx/technicalramblings/access.log custom ; access_log /config/log/nginx/access.log custom ; This will log the same lines to both files. Then use the /config/log/nginx/access.log file in the NGINX_LOG_PATH variable. Grafana dashboard \u00b6 Here is the link to the Grafana dashboard: https://grafana.com/grafana/dashboards/12268 Other statistics \u00b6 You can also add a Telegraf plugin for Nginx that gets some extra stats from the webserver. https://github.com/influxdata/telegraf/tree/master/plugins/inputs/nginx Location Block: location /nginx_status { stub_status on ; access_log off ; allow 192 .168.1.0/24 ; # Add the IP ranges you want to access. deny all ; } Sources: https://medium.com/faun/total-nginx-monitoring-with-application-performance-and-a-bit-more-using-8fc6d731051b https://geoip2.readthedocs.io/en/latest/ https://www.influxdata.com/blog/getting-started-python-influxdb/ https://grafana.com/grafana/dashboards/8522 https://www.geeksforgeeks.org/python-reading-last-n-lines-of-a-file/ If you need any extra help join the Discord server! \u00b6 \u00b6","title":"Visualizing Nginx geo data metrics  with Python, InfluxDB and Grafana"},{"location":"blog/visualizing-nginx-geo-data-metrics-with-python-influxdb-and-grafana/#visualizing-nginx-geo-data-metrics-with-python-influxdb-and-grafana","text":"A couple of weeks ago I saw someone posted an article on on the LinuxServer discord describing how to send geo data statistics from Nginx to InfluxDB. I have seen similar articles in the past and I always wanted to try it out, and because adding new dashboards to Grafana is always fun :) Note For people not using the letsencrypt/swag container, I've added a standalone container you can use here: https://github.com/gilbN/geoip2influx The article was a couple of years old so he was using the now deprecated maxmind geoip database. But the rest of the Nginx configs looked just fine. As for the sending of the geo data metrics to InfluxDB, he was using a python2 script. Having recently started using Roxedus's Fail2Ban docker mod for the linuxserver swag container, I thought that would be an excellent way of running it. So I looked at how Roxedus set up his mod and used that as a template for building mine. Getting the script to work was simple enough, I just needed to adapt it for python3 and change a couple of small things, like adding environment variables for use with docker. I also tried to get Telegraf to parse the Nginx logs like he did in his guide, but it only parsed the logs once and didn't continue to send new log lines to InfluxDB. So I decided to make python parse it instead.","title":"Visualizing Nginx geo data metrics  with Python, InfluxDB and Grafana"},{"location":"blog/visualizing-nginx-geo-data-metrics-with-python-influxdb-and-grafana/#adding-the-docker-mod-to-the-swag-container","text":"Influx version Only InfluxDB v1.8.x supported! The mod is added using docker environment variables. The first one you need is -e DOCKER_MODS=linuxserver/mods:swag-geoip2influx Here is a link to the repo if you want to have a look: https://github.com/gilbN/lsio-docker-mods/blob/master/letsencrypt/geoip2-nginx-stats Update 06.09.2020: I made a PR on the official linuxserver/docker-mods repo, and it' now been added there. https://github.com/linuxserver/docker-mods/tree/swag-geoip2influx The python script has some default variables added already, so you only need to add the ones that's different for your system. The available and default variables are: -e NGINX_LOG_PATH=/config/log/nginx/access.log -e INFLUX_HOST=localhost -e INFLUX_HOST_PORT=8086 -e INFLUX_DATABASE=geoip2influx -e INFLUX_USER=root -e INFLUX_PASS=root -e INFLUX_RETENTION=7d -e INFLUX_SHARD=2d -e GEO_MEASUREMENT=geoip2influx -e LOG_MEASUREMENT=nginx_access_logs -e SEND_NGINX_LOGS=true -e GEOIP2INFLUX_LOG_LEVEL=INFO -e GEOIP2INFLUX_LOG_PATH=/config/log/geoip2influx/geoip2influx.log Most of them should be self explanatory, so I'll just add some comments on a couple of them. -e INFLUX_HOST=localhost Since you will be setting this up inside the swag container, the default value will not work unless you are running the container with host networking and InfluxDB is installed on the same host. So change this to your host IP/docker dns name. GEO_MEASUREMENT=geoip2influx and -e LOG_MEASUREMENT=nginx_access_logs These are just the measurement names that will be sent to InfluxDB. -e INFLUX_DATABASE=geoip2influx The database will be created automatically by the python script, so no need to create one beforehand. -e INFLUX_RETENTION and -e INFLUX_SHARD Update 06.06.20 : To try and mitigate max-values-per-tag limit exceeded errors I've added retention to the database. It will only add the retention policy if the database doesn't exist. Read more about retention policies here: https://www.influxdata.com/blog/influxdb-shards-retention-policies/ and https://docs.influxdata.com/influxdb/v1.2/concepts/key_concepts/#retention-policy -e MAXMINDDB_LICENSE_KEY=<license-key> Update 15.05.20 : The swag container now natively supports downloading the geoip2 database with the use of the MAXMINDDB_LICENSE_KEY variable. Add your MaxMind Geoip2 license key and it will automatically download the latest database and update it weekly . The default download location is /config/geoip2db/GeoLite2-City.mmdb . If you're unsure how to obtain a licensekey, check out the first part of my geolite2 guide . -e GEOIP2INFLUX_LOG_LEVEL=INFO The script will automatically create a log file in the directory that -e GEOIP2INFLUX_LOG_PATH is set to. Set this to DEBUG for troubleshooting.","title":"Adding the docker mod to the swag container"},{"location":"blog/visualizing-nginx-geo-data-metrics-with-python-influxdb-and-grafana/#nginx-log-metrics","text":"swag geolite2 instructions: https://technicalramblings.com/blog/blocking-countries-with-geolite2-using-the-letsencrypt-docker-container/ For python to be able to parse the nginx logs correctly you need to update your nginx configs with a couple of lines. Add the following in the http block in your nginx.conf file: geoip2 /config/geoip2db/GeoLite2-City.mmdb { auto_reload 5m ; $geoip2_data_country_iso_code country iso_code ; $geoip2_data_city_name city names en ; } log_format custom ' $remote_addr - $remote_user [ $time_local]' '\" $request\" $status $body_bytes_sent' '\" $http_referer\" $host \" $http_user_agent\"' '\" $request_time\" \" $upstream_connect_time\"' '\" $geoip2_data_city_name\" \" $geoip2_data_country_iso_code\"' ; Set the access log use the custom log format. access_log /config/log/nginx/access.log custom ; The first time the scripts starts it will try and parse the log for 1 minute and if the regex doesn't match it will disable the log metrics. So be sure to refresh your site a couple of times after adding the mod. Next add a new datasource to Grafana with the name of the database you chose and import the dashboard and you should start seeing the map getting populated!","title":"Nginx log metrics"},{"location":"blog/visualizing-nginx-geo-data-metrics-with-python-influxdb-and-grafana/#multiple-log-files","text":"If you separate your nginx log files but want this mod to parse all of them you can do the following: As nginx can have multiple access log directives in a block, just add another one in the server block. Example access_log /config/log/nginx/technicalramblings/access.log custom ; access_log /config/log/nginx/access.log custom ; This will log the same lines to both files. Then use the /config/log/nginx/access.log file in the NGINX_LOG_PATH variable.","title":"Multiple log files"},{"location":"blog/visualizing-nginx-geo-data-metrics-with-python-influxdb-and-grafana/#grafana-dashboard","text":"Here is the link to the Grafana dashboard: https://grafana.com/grafana/dashboards/12268","title":"Grafana dashboard"},{"location":"blog/visualizing-nginx-geo-data-metrics-with-python-influxdb-and-grafana/#other-statistics","text":"You can also add a Telegraf plugin for Nginx that gets some extra stats from the webserver. https://github.com/influxdata/telegraf/tree/master/plugins/inputs/nginx Location Block: location /nginx_status { stub_status on ; access_log off ; allow 192 .168.1.0/24 ; # Add the IP ranges you want to access. deny all ; } Sources: https://medium.com/faun/total-nginx-monitoring-with-application-performance-and-a-bit-more-using-8fc6d731051b https://geoip2.readthedocs.io/en/latest/ https://www.influxdata.com/blog/getting-started-python-influxdb/ https://grafana.com/grafana/dashboards/8522 https://www.geeksforgeeks.org/python-reading-last-n-lines-of-a-file/","title":"Other statistics"},{"location":"blog/visualizing-nginx-geo-data-metrics-with-python-influxdb-and-grafana/#if-you-need-any-extra-help-join-the-discord-server","text":"","title":"If you need any extra help join the Discord server!"},{"location":"blog/visualizing-nginx-geo-data-metrics-with-python-influxdb-and-grafana/#_1","text":"","title":""}]}